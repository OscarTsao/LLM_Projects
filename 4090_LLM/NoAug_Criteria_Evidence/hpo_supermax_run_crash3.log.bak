[0;34m======================================================================
  Running Super-Max HPO for ALL Architectures Sequentially
======================================================================[0m 

[0;33mSequence: Criteria â†’ Evidence â†’ Share â†’ Joint[0m 
[0;33mTotal trials: ~19,000 (5000+8000+3000+3000)[0m 
[0;33mEstimated time: ~80-120 hours with PAR=4[0m 

[0;32mStarting...[0m 

[0;34m[1/4] Running Criteria (5000 trials)...[0m 
make[1]: Entering directory '/media/user/SSD1/YuNing/NoAug_Criteria_Evidence'
[0;34mRunning SUPER-MAX HPO for Criteria...[0m 
Trials: 5000 | Parallel: 3 (reduced from 4 to prevent GPU OOM) | Epochs: 100 | Patience: 20
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python HPO_EPOCHS=100 HPO_PATIENCE=20 poetry run python scripts/tune_max.py \
	--agent criteria --study noaug-criteria-supermax \
	--n-trials 5000 --parallel 3 \
	--outdir ./_runs
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``group`` is an experimental feature. The interface can change in the future.
  warnings.warn(
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(
/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py:969: ExperimentalWarning: PatientPruner is experimental (supported from v2.8.0). The interface can change in the future.
  return PatientPruner(hb, patience=4)  # More patient (was 2)
[I 2025-10-29 01:09:12,045] Using an existing study with name 'noaug-criteria-supermax' instead of creating a new one.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
âœ“ Configuration validation passed
  Agent: criteria
  Epochs: 100 | Patience: 20
  Output: ./_runs
[HPO] agent=criteria epochs=100 storage=sqlite:////media/user/SSD1/YuNing/NoAug_Criteria_Evidence/_optuna/noaug.db
[HPO] Study 'noaug-criteria-supermax' is compatible. Resuming optimization.

================================================================================
TRIAL 1975 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 9.616395768528653e-06
  Dropout: 0.19254300758833834
================================================================================


================================================================================
TRIAL 1976 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 2.6289769404070232e-05
  Dropout: 0.35302636361786616
================================================================================


================================================================================
TRIAL 1977 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 2.497893275467928e-05
  Dropout: 0.3495238291777782
================================================================================

Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[I 2025-10-29 01:19:54,977] Trial 1975 pruned. Pruned at step 15 with metric 0.6200
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 1978 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 16
  Learning rate: 3.434843260273194e-05
  Dropout: 0.28020271622706416
================================================================================

[I 2025-10-29 01:20:04,364] Trial 1978 pruned. OOM: roberta-large bs=16 len=352
[W 2025-10-29 01:20:04,808] The parameter `tok.doc_stride` in Trial#1979 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.

[OOM] Trial 1978 exceeded GPU memory:
  Model: roberta-large
  Batch size: 16 (effective: 48 with grad_accum=3)
  Max length: 352
  Error: CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 62.69 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 1979 - Configuration:
  Model: {'name': 'xlm-roberta-base'}
  Batch size: 8
  Learning rate: 2.6553533665374236e-05
  Dropout: 0.3161644111803729
================================================================================

[I 2025-10-29 01:29:29,942] Trial 1976 finished with value: 0.739090909090909 and parameters: {'seed': 50151, 'model.name': 'roberta-base', 'tok.max_length': 288, 'tok.doc_stride': 48, 'tok.use_fast': True, 'train.batch_size': 24, 'train.grad_accum': 3, 'optim.name': 'adamw', 'optim.lr': 2.6289769404070232e-05, 'optim.weight_decay': 0.1584149999971818, 'optim.beta1': 0.8894184544311395, 'optim.beta2': 0.969545471930773, 'optim.eps': 1.6061075681284886e-07, 'sched.name': 'cosine_restart', 'sched.warmup_ratio': 0.10580828906865937, 'sched.cosine_cycles': 2, 'train.clip_grad': 0.9682943721376349, 'model.dropout': 0.35302636361786616, 'model.attn_dropout': 0.28301434812108966, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.8553509189311153, 'head.pooling': 'cls', 'head.layers': 3, 'head.hidden': 512, 'head.activation': 'silu', 'head.dropout': 0.3768116100715676, 'loss.cls.type': 'focal', 'loss.cls.gamma': 1.0021742966478355, 'loss.cls.alpha': 0.27292082038342824, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 24 (patience=20)

================================================================================
TRIAL 1980 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 5.4833704677827165e-06
  Dropout: 0.25246015140328437
================================================================================

[I 2025-10-29 01:39:58,278] Trial 1980 pruned. Pruned at step 10 with metric 0.5878
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 1981 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 9.702723274232669e-05
  Dropout: 0.09283630786023209
================================================================================

[I 2025-10-29 01:48:11,728] Trial 1981 pruned. Pruned at step 16 with metric 0.5769
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 1982 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 3.95654195430909e-05
  Dropout: 0.30335549970168074
================================================================================

[I 2025-10-29 01:50:04,154] Trial 1977 finished with value: 0.6398429157049847 and parameters: {'seed': 45146, 'model.name': 'roberta-base', 'tok.max_length': 288, 'tok.doc_stride': 48, 'tok.use_fast': True, 'train.batch_size': 24, 'train.grad_accum': 3, 'optim.name': 'adamw', 'optim.lr': 2.497893275467928e-05, 'optim.weight_decay': 0.0005375107912942344, 'optim.beta1': 0.8402332862743417, 'optim.beta2': 0.981640610136976, 'optim.eps': 8.205592444314026e-09, 'sched.name': 'cosine_restart', 'sched.warmup_ratio': 0.16215081176808388, 'sched.cosine_cycles': 2, 'train.clip_grad': 0.6957212820654888, 'model.dropout': 0.3495238291777782, 'model.attn_dropout': 0.15932806477572808, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.8643853023355361, 'head.pooling': 'max', 'head.layers': 4, 'head.hidden': 768, 'head.activation': 'relu', 'head.dropout': 0.460082876157988, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.183631676231641, 'loss.cls.alpha': 0.5877954120421938, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 61 (patience=20)

================================================================================
TRIAL 1983 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 1.1588552269924987e-05
  Dropout: 0.4444433339564181
================================================================================

[I 2025-10-29 01:54:42,959] Trial 1983 pruned. Pruned at step 13 with metric 0.5283
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 1984 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 2.2172904566823257e-05
  Dropout: 0.32453287068864384
================================================================================

[I 2025-10-29 01:59:55,222] Trial 1984 pruned. Pruned at step 9 with metric 0.6250
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 1985 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 24
  Learning rate: 3.5449425907757784e-05
  Dropout: 0.01894973484624711
================================================================================

[I 2025-10-29 02:00:01,718] Trial 1979 pruned. OOM: xlm-roberta-base bs=8 len=128

[OOM] Trial 1979 exceeded GPU memory:
  Model: xlm-roberta-base
  Batch size: 8 (effective: 8 with grad_accum=1)
  Max length: 128
  Error: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 78.56 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proc
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 1986 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 64
  Learning rate: 1.9971243662748103e-05
  Dropout: 0.05954002760193175
================================================================================

[I 2025-10-29 02:00:06,005] Trial 1985 pruned. OOM: microsoft/deberta-v3-base bs=24 len=352
[I 2025-10-29 02:00:06,542] Trial 1987 pruned. Pruned: Large model with bsz=64, accum=3 (effective_batch=192) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 1985 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 24 (effective: 72 with grad_accum=3)
  Max length: 352
  Error: CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 94.88 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proc
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 1988 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 1.1125607866187181e-05
  Dropout: 0.17593503137728747
================================================================================

[I 2025-10-29 02:12:02,560] Trial 1986 pruned. Pruned at step 11 with metric 0.5847
[I 2025-10-29 02:12:02,986] Trial 1989 pruned. Pruned: Large model with bsz=24, accum=3 (effective_batch=72) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 1990 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 8
  Learning rate: 5.631175259850968e-06
  Dropout: 0.2099500535622043
================================================================================

[I 2025-10-29 02:14:22,995] Trial 1988 finished with value: 0.6776318585575247 and parameters: {'seed': 48700, 'model.name': 'roberta-base', 'tok.max_length': 288, 'tok.doc_stride': 48, 'tok.use_fast': True, 'train.batch_size': 24, 'train.grad_accum': 6, 'optim.name': 'adamw', 'optim.lr': 1.1125607866187181e-05, 'optim.weight_decay': 0.1046825541799329, 'optim.beta1': 0.9172946370086628, 'optim.beta2': 0.9588338409155257, 'optim.eps': 1.470035663626197e-07, 'sched.name': 'cosine_restart', 'sched.warmup_ratio': 0.08327652069338372, 'sched.cosine_cycles': 2, 'train.clip_grad': 0.8446020031055812, 'model.dropout': 0.17593503137728747, 'model.attn_dropout': 0.21610838866442414, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 3, 'optim.layerwise_lr_decay': 0.8355990877859313, 'head.pooling': 'cls', 'head.layers': 3, 'head.hidden': 512, 'head.activation': 'silu', 'head.dropout': 0.3539197407910345, 'loss.cls.type': 'focal', 'loss.cls.gamma': 1.2471891317286432, 'loss.cls.alpha': 0.3423241107553656, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
EarlyStopping triggered at epoch 26 (patience=20)

================================================================================
TRIAL 1991 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 64
  Learning rate: 2.4285120234198234e-05
  Dropout: 0.0018046205530143355
================================================================================

[I 2025-10-29 02:14:28,043] Trial 1991 pruned. OOM: microsoft/deberta-v3-base bs=64 len=224
[I 2025-10-29 02:14:28,569] Trial 1992 pruned. Pruned: Large model with bsz=48, accum=2 (effective_batch=96) likely causes OOM (24GB GPU limit)
[I 2025-10-29 02:14:29,566] Trial 1982 pruned. OOM: roberta-base bs=16 len=320

[OOM] Trial 1991 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 64 (effective: 192 with grad_accum=3)
  Max length: 224
  Error: CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 227.56 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this pro
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 1993 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 24
  Learning rate: 8.431212008377165e-06
  Dropout: 0.3550589029829895
================================================================================


[OOM] Trial 1982 exceeded GPU memory:
  Model: roberta-base
  Batch size: 16 (effective: 48 with grad_accum=3)
  Max length: 320
  Error: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 67.56 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 1994 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 7.164809523294764e-06
  Dropout: 0.2572477730259071
================================================================================

Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[I 2025-10-29 02:14:36,103] Trial 1994 pruned. OOM: roberta-base bs=24 len=288
[I 2025-10-29 02:14:36,852] Trial 1993 pruned. OOM: microsoft/deberta-v3-base bs=24 len=256
[I 2025-10-29 02:14:37,231] Trial 1995 pruned. Pruned: Large model with bsz=12, accum=8 (effective_batch=96) likely causes OOM (24GB GPU limit)
[I 2025-10-29 02:14:37,727] Trial 1996 pruned. Pruned: Large model with bsz=24, accum=3 (effective_batch=72) likely causes OOM (24GB GPU limit)
[I 2025-10-29 02:14:37,998] Trial 1997 pruned. Pruned: Large model with bsz=64, accum=3 (effective_batch=192) likely causes OOM (24GB GPU limit)
[I 2025-10-29 02:14:38,637] Trial 1990 pruned. OOM: roberta-large bs=8 len=224
[I 2025-10-29 02:14:39,357] Trial 1998 pruned. Pruned: Large model with bsz=32, accum=6 (effective_batch=192) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 1994 exceeded GPU memory:
  Model: roberta-base
  Batch size: 24 (effective: 72 with grad_accum=3)
  Max length: 288
  Error: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 77.56 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


[OOM] Trial 1993 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 24 (effective: 72 with grad_accum=3)
  Max length: 256
  Error: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 77.56 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


[OOM] Trial 1990 exceeded GPU memory:
  Model: roberta-large
  Batch size: 8 (effective: 8 with grad_accum=1)
  Max length: 224
  Error: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 77.56 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 1999 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 32
  Learning rate: 2.244867333446981e-05
  Dropout: 0.08661956084203006
================================================================================


================================================================================
TRIAL 2000 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 8
  Learning rate: 8.559295872857614e-06
  Dropout: 0.3058385158134517
================================================================================


================================================================================
TRIAL 2001 - Configuration:
  Model: {'name': 'bert-large-uncased'}
  Batch size: 8
  Learning rate: 2.4109034438752532e-05
  Dropout: 0.27666447682252315
================================================================================

[I 2025-10-29 02:22:04,913] Trial 1999 pruned. Pruned at step 19 with metric 0.6156
[W 2025-10-29 02:22:05,315] The parameter `tok.doc_stride` in Trial#2002 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.

================================================================================
TRIAL 2002 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 2.0319473831593597e-05
  Dropout: 0.3622658468055558
================================================================================

[I 2025-10-29 02:26:39,981] Trial 2002 pruned. Pruned at step 9 with metric 0.5451
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2003 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 9.695622431291676e-06
  Dropout: 0.1912974930479015
================================================================================

[I 2025-10-29 02:28:44,747] Trial 2001 pruned. Pruned at step 9 with metric 0.5746
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2004 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 16
  Learning rate: 7.22588204976378e-06
  Dropout: 0.2715760612003032
================================================================================

[I 2025-10-29 02:40:31,537] Trial 2004 pruned. Pruned at step 19 with metric 0.6297
[I 2025-10-29 02:40:32,023] Trial 2005 pruned. Pruned: Large model with bsz=24, accum=1 (effective_batch=24) likely causes OOM (24GB GPU limit)
[I 2025-10-29 02:40:32,410] Trial 2006 pruned. Pruned: Large model with bsz=24, accum=3 (effective_batch=72) likely causes OOM (24GB GPU limit)
[I 2025-10-29 02:40:32,811] Trial 2007 pruned. Pruned: Large model with bsz=48, accum=2 (effective_batch=96) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2008 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 6.010188317381876e-06
  Dropout: 0.4119767071747855
================================================================================

[I 2025-10-29 02:46:09,807] Trial 2008 pruned. Pruned at step 15 with metric 0.6484
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2009 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 12
  Learning rate: 6.625869478830699e-06
  Dropout: 0.23957664734435608
================================================================================

[I 2025-10-29 02:49:04,603] Trial 2009 pruned. Pruned at step 8 with metric 0.5582

================================================================================
TRIAL 2010 - Configuration:
  Model: {'name': 'bert-large-uncased'}
  Batch size: 16
  Learning rate: 1.2251894372857226e-05
  Dropout: 0.05778942087282213
================================================================================

[I 2025-10-29 03:01:10,258] Trial 2010 pruned. Pruned at step 15 with metric 0.5846
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2011 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 1.3498461330727554e-05
  Dropout: 0.3137312910656546
================================================================================

[I 2025-10-29 03:03:37,350] Trial 2011 pruned. Pruned at step 10 with metric 0.6009
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2012 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 1.0477560618677285e-05
  Dropout: 0.46108029214102214
================================================================================

[I 2025-10-29 03:06:34,468] Trial 2012 pruned. Pruned at step 8 with metric 0.5919
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2013 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-large'}
  Batch size: 16
  Learning rate: 4.703037503493998e-05
  Dropout: 0.3120158646868427
================================================================================

[I 2025-10-29 03:06:40,314] Trial 2013 pruned. OOM: microsoft/deberta-v3-large bs=16 len=288
[I 2025-10-29 03:06:40,852] Trial 2014 pruned. Pruned: Large model with bsz=32, accum=3 (effective_batch=96) likely causes OOM (24GB GPU limit)
[I 2025-10-29 03:06:41,282] Trial 2015 pruned. Pruned: Large model with bsz=48, accum=1 (effective_batch=48) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2013 exceeded GPU memory:
  Model: microsoft/deberta-v3-large
  Batch size: 16 (effective: 64 with grad_accum=4)
  Max length: 288
  Error: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 70.25 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2016 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 7.778733570853668e-06
  Dropout: 0.35893585380880494
================================================================================

[I 2025-10-29 03:11:33,424] Trial 2016 pruned. Pruned at step 14 with metric 0.6428

================================================================================
TRIAL 2017 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 64
  Learning rate: 5.854989898128485e-06
  Dropout: 0.4200224740299584
================================================================================

[I 2025-10-29 03:15:47,982] Trial 2017 pruned. Pruned at step 27 with metric 0.5839

================================================================================
TRIAL 2018 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 8
  Learning rate: 7.85015569144326e-06
  Dropout: 0.33598662620393205
================================================================================

[I 2025-10-29 03:23:23,241] Trial 2018 pruned. Pruned at step 15 with metric 0.5878
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2019 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 12
  Learning rate: 7.513076666049597e-06
  Dropout: 0.36777063339441063
================================================================================

[I 2025-10-29 03:33:27,570] Trial 2000 finished with value: 0.6769618657421999 and parameters: {'seed': 44687, 'model.name': 'bert-base-uncased', 'tok.max_length': 224, 'tok.doc_stride': 48, 'tok.use_fast': False, 'train.batch_size': 8, 'train.grad_accum': 1, 'optim.name': 'adamw', 'optim.lr': 8.559295872857614e-06, 'optim.weight_decay': 0.0006480193013044963, 'optim.beta1': 0.8091944809412762, 'optim.beta2': 0.9656360691678814, 'optim.eps': 6.779112747785268e-09, 'sched.name': 'linear', 'sched.warmup_ratio': 0.19340194801444066, 'train.clip_grad': 0.7602907092213966, 'model.dropout': 0.3058385158134517, 'model.attn_dropout': 0.13230292082382505, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 6, 'optim.layerwise_lr_decay': 0.9069562906385353, 'head.pooling': 'max', 'head.layers': 4, 'head.hidden': 768, 'head.activation': 'relu', 'head.dropout': 0.43547044351562475, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.9702575495908805, 'loss.cls.alpha': 0.5476170455918171, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 23 (patience=20)

================================================================================
TRIAL 2020 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 8
  Learning rate: 2.4688426344125204e-05
  Dropout: 0.4908457457143607
================================================================================

[I 2025-10-29 03:40:53,513] Trial 2003 finished with value: 0.6731665440274712 and parameters: {'seed': 46783, 'model.name': 'microsoft/deberta-v3-base', 'tok.max_length': 128, 'tok.doc_stride': 32, 'tok.use_fast': False, 'train.batch_size': 8, 'train.grad_accum': 6, 'optim.name': 'adamw', 'optim.lr': 9.695622431291676e-06, 'optim.weight_decay': 0.02242568598508859, 'optim.beta1': 0.9042256103161473, 'optim.beta2': 0.9734558157968978, 'optim.eps': 2.561579593324868e-09, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.14763939004963758, 'sched.poly_power': 0.9598540809661649, 'train.clip_grad': 0.6511694876060816, 'model.dropout': 0.1912974930479015, 'model.attn_dropout': 0.21191899284030516, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 4, 'optim.layerwise_lr_decay': 0.920156060495893, 'head.pooling': 'cls', 'head.layers': 2, 'head.hidden': 2048, 'head.activation': 'relu', 'head.dropout': 0.21131684262645176, 'loss.cls.type': 'focal', 'loss.cls.gamma': 1.8663497428001903, 'loss.cls.alpha': 0.21195863632959594, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
[I 2025-10-29 03:40:53,923] Trial 2021 pruned. Pruned: Large model with bsz=24, accum=2 (effective_batch=48) likely causes OOM (24GB GPU limit)
EarlyStopping triggered at epoch 27 (patience=20)

================================================================================
TRIAL 2022 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 8
  Learning rate: 1.0454055589849096e-05
  Dropout: 0.4228598614258344
================================================================================

[I 2025-10-29 03:48:52,388] Trial 2019 pruned. Pruned at step 27 with metric 0.6315
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2023 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 0.00013735421394565735
  Dropout: 0.13083430051627482
================================================================================

[I 2025-10-29 04:01:50,922] Trial 2022 pruned. Pruned at step 15 with metric 0.5451
[I 2025-10-29 04:01:51,357] Trial 2024 pruned. Pruned: Large model with bsz=64, accum=3 (effective_batch=192) likely causes OOM (24GB GPU limit)

================================================================================
TRIAL 2025 - Configuration:
  Model: {'name': 'xlm-roberta-base'}
  Batch size: 12
  Learning rate: 9.560690569575e-06
  Dropout: 0.3024645569544919
================================================================================

[I 2025-10-29 04:02:39,017] Trial 2023 finished with value: 0.4474393530997305 and parameters: {'seed': 52773, 'model.name': 'roberta-base', 'tok.max_length': 160, 'tok.doc_stride': 48, 'tok.use_fast': False, 'train.batch_size': 8, 'train.grad_accum': 3, 'optim.name': 'adamw', 'optim.lr': 0.00013735421394565735, 'optim.weight_decay': 0.012071475695308755, 'optim.beta1': 0.9417606997254795, 'optim.beta2': 0.9927097318387605, 'optim.eps': 1.1597575398210667e-09, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.10891383782189387, 'sched.poly_power': 0.786488661038694, 'train.clip_grad': 1.2378531246581685, 'model.dropout': 0.13083430051627482, 'model.attn_dropout': 0.2646607547857554, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 1, 'optim.layerwise_lr_decay': 0.8380166066159397, 'head.pooling': 'attn', 'head.layers': 3, 'head.hidden': 768, 'head.activation': 'relu', 'head.dropout': 0.309390076908174, 'loss.cls.type': 'ce', 'loss.cls.label_smoothing': 0.06768453170343594, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2026 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 1.4671527116443812e-05
  Dropout: 0.01893619099125063
================================================================================

[I 2025-10-29 04:05:07,296] Trial 2026 pruned. Pruned at step 9 with metric 0.6121

================================================================================
TRIAL 2027 - Configuration:
  Model: {'name': 'xlm-roberta-base'}
  Batch size: 16
  Learning rate: 9.853625514825055e-06
  Dropout: 0.4252831363712245
================================================================================

[I 2025-10-29 04:16:19,847] Trial 2025 pruned. Pruned at step 10 with metric 0.5734
[I 2025-10-29 04:16:20,585] Trial 2028 pruned. Pruned: Large model with bsz=24, accum=3 (effective_batch=72) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2029 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 8.838501389725839e-06
  Dropout: 0.1867325759872305
================================================================================

[I 2025-10-29 04:16:26,431] Trial 2027 pruned. OOM: xlm-roberta-base bs=16 len=160
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2027 exceeded GPU memory:
  Model: xlm-roberta-base
  Batch size: 16 (effective: 48 with grad_accum=3)
  Max length: 160
  Error: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 648.88 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this pro
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2030 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 7.773356490921145e-06
  Dropout: 0.31499109133293424
================================================================================

[I 2025-10-29 04:26:23,064] Trial 2029 finished with value: 0.7239429033126852 and parameters: {'seed': 45639, 'model.name': 'roberta-base', 'tok.max_length': 224, 'tok.doc_stride': 64, 'tok.use_fast': False, 'train.batch_size': 64, 'train.grad_accum': 1, 'optim.name': 'adamw', 'optim.lr': 8.838501389725839e-06, 'optim.weight_decay': 0.00012912510483437085, 'optim.beta1': 0.9195042974883448, 'optim.beta2': 0.9583638635331398, 'optim.eps': 1.3917537572550862e-09, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.1400772347086146, 'sched.poly_power': 0.9469500079724777, 'train.clip_grad': 0.48156891314081907, 'model.dropout': 0.1867325759872305, 'model.attn_dropout': 0.1949984747703661, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 6, 'optim.layerwise_lr_decay': 0.807606499202854, 'head.pooling': 'cls', 'head.layers': 3, 'head.hidden': 1536, 'head.activation': 'relu', 'head.dropout': 0.16102215248898571, 'loss.cls.type': 'focal', 'loss.cls.gamma': 1.0336527608211221, 'loss.cls.alpha': 0.3073561905399575, 'loss.cls.balance': 'weighted'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 31 (patience=20)

================================================================================
TRIAL 2031 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 3.8781778771002553e-05
  Dropout: 0.009515871277873154
================================================================================

[I 2025-10-29 04:30:26,491] Trial 2031 pruned. Pruned at step 14 with metric 0.6298
[I 2025-10-29 04:30:26,929] Trial 2032 pruned. Pruned: Large model with bsz=64, accum=3 (effective_batch=192) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2033 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 6.5040721836368905e-06
  Dropout: 0.07752468622821443
================================================================================

[I 2025-10-29 04:47:48,149] Trial 2030 pruned. Pruned at step 27 with metric 0.6082

================================================================================
TRIAL 2034 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 1.3771625145339675e-05
  Dropout: 0.35551749038976754
================================================================================

[I 2025-10-29 04:53:56,022] Trial 2034 pruned. Pruned at step 10 with metric 0.6383
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2035 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 7.281051704103935e-06
  Dropout: 0.2190794997884456
================================================================================

[I 2025-10-29 05:13:34,714] Trial 2033 finished with value: 0.7254298642533936 and parameters: {'seed': 61022, 'model.name': 'roberta-base', 'tok.max_length': 352, 'tok.doc_stride': 48, 'tok.use_fast': True, 'train.batch_size': 8, 'train.grad_accum': 3, 'optim.name': 'adamw', 'optim.lr': 6.5040721836368905e-06, 'optim.weight_decay': 0.018310302619238043, 'optim.beta1': 0.8201314547949539, 'optim.beta2': 0.9774056164713766, 'optim.eps': 2.4516869251648543e-09, 'sched.name': 'cosine_restart', 'sched.warmup_ratio': 0.1313355079790891, 'sched.cosine_cycles': 2, 'train.clip_grad': 0.3865931309216116, 'model.dropout': 0.07752468622821443, 'model.attn_dropout': 0.18124071752557414, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 6, 'optim.layerwise_lr_decay': 0.9127075690115337, 'head.pooling': 'cls', 'head.layers': 3, 'head.hidden': 1536, 'head.activation': 'relu', 'head.dropout': 0.1270718703422902, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.9158044273628407, 'loss.cls.alpha': 0.5450754617681784, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 27 (patience=20)

================================================================================
TRIAL 2036 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 6.439056595059752e-06
  Dropout: 0.20220718181169645
================================================================================

[I 2025-10-29 05:13:38,841] Trial 2020 pruned. OOM: roberta-large bs=8 len=320
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2020 exceeded GPU memory:
  Model: roberta-large
  Batch size: 8 (effective: 32 with grad_accum=4)
  Max length: 320
  Error: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 45.88 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2037 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 8.910740321366e-06
  Dropout: 0.3110084779435176
================================================================================

[I 2025-10-29 05:24:21,831] Trial 2036 pruned. Pruned at step 27 with metric 0.6027
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2038 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 16
  Learning rate: 2.3823948648261506e-05
  Dropout: 0.4659741159258578
================================================================================

[I 2025-10-29 05:33:31,875] Trial 2038 pruned. Pruned at step 10 with metric 0.6428
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2039 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 8.253858984820423e-06
  Dropout: 0.11435097309201807
================================================================================

[I 2025-10-29 05:38:33,333] Trial 2039 pruned. Pruned at step 8 with metric 0.5731
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2040 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 5.3832181150235375e-06
  Dropout: 0.2581458885535234
================================================================================

[I 2025-10-29 05:42:23,888] Trial 2037 pruned. Pruned at step 7 with metric 0.6315
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2041 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 8
  Learning rate: 1.0645027702659127e-05
  Dropout: 0.001124414195526488
================================================================================

[I 2025-10-29 05:45:43,434] Trial 2035 finished with value: 0.7270128942154666 and parameters: {'seed': 55861, 'model.name': 'microsoft/deberta-v3-base', 'tok.max_length': 128, 'tok.doc_stride': 32, 'tok.use_fast': True, 'train.batch_size': 8, 'train.grad_accum': 1, 'optim.name': 'adamw', 'optim.lr': 7.281051704103935e-06, 'optim.weight_decay': 0.026040119967130078, 'optim.beta1': 0.9067183455780967, 'optim.beta2': 0.9936986113745382, 'optim.eps': 3.2910772893381805e-09, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.0317352488460548, 'sched.poly_power': 1.1403770369423074, 'train.clip_grad': 0.7960318787833132, 'model.dropout': 0.2190794997884456, 'model.attn_dropout': 0.05916188734941664, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 2, 'optim.layerwise_lr_decay': 0.950444090099822, 'head.pooling': 'max', 'head.layers': 2, 'head.hidden': 768, 'head.activation': 'relu', 'head.dropout': 0.07337330195235926, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.16044840249519, 'loss.cls.alpha': 0.5057142069160087, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
EarlyStopping triggered at epoch 30 (patience=20)

================================================================================
TRIAL 2042 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 1.1273910975775072e-05
  Dropout: 0.229800617534744
================================================================================

[I 2025-10-29 05:55:38,220] Trial 2040 pruned. Pruned at step 8 with metric 0.5261
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2043 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 5.698770862634851e-06
  Dropout: 0.12344260887354633
================================================================================

[I 2025-10-29 05:56:20,760] Trial 2042 pruned. Pruned at step 9 with metric 0.5916
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2044 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 4.3779987761159584e-05
  Dropout: 0.3117700639390828
================================================================================

[I 2025-10-29 06:07:07,692] Trial 2044 pruned. Pruned at step 10 with metric 0.6155
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2045 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 6.15318014895567e-06
  Dropout: 0.2478022531852376
================================================================================

[I 2025-10-29 06:12:46,517] Trial 2045 pruned. Pruned at step 21 with metric 0.5615
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2046 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 64
  Learning rate: 1.5526884255091485e-05
  Dropout: 0.0006630225459997099
================================================================================

[I 2025-10-29 06:12:52,043] Trial 2046 pruned. OOM: microsoft/deberta-v3-base bs=64 len=128
[I 2025-10-29 06:12:53,477] Trial 2043 pruned. OOM: microsoft/deberta-v3-base bs=8 len=128
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2046 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 64 (effective: 64 with grad_accum=1)
  Max length: 128
  Error: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 38.25 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


[OOM] Trial 2043 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 8 (effective: 8 with grad_accum=1)
  Max length: 128
  Error: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 38.25 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2047 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 5.561322704666315e-06
  Dropout: 0.265054778202753
================================================================================


================================================================================
TRIAL 2048 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 8.660374677604658e-06
  Dropout: 0.23828324532234058
================================================================================

[I 2025-10-29 06:12:56,003] Trial 2041 pruned. OOM: roberta-large bs=8 len=192
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2041 exceeded GPU memory:
  Model: roberta-large
  Batch size: 8 (effective: 32 with grad_accum=4)
  Max length: 192
  Error: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 38.25 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.

Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2049 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 6.801168908978528e-06
  Dropout: 0.23930777560882574
================================================================================

[I 2025-10-29 06:13:00,349] Trial 2047 pruned. OOM: roberta-base bs=64 len=224
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2047 exceeded GPU memory:
  Model: roberta-base
  Batch size: 64 (effective: 256 with grad_accum=4)
  Max length: 224
  Error: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 149.56 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this pro
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2050 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 1.6548516466984723e-05
  Dropout: 0.03993780027025273
================================================================================

[I 2025-10-29 06:18:10,183] Trial 2050 pruned. Pruned at step 8 with metric 0.6027
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2051 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 1.7356916916830394e-05
  Dropout: 0.03144874795855429
================================================================================

[I 2025-10-29 06:21:07,859] Trial 2049 pruned. Pruned at step 11 with metric 0.4416

================================================================================
TRIAL 2052 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 64
  Learning rate: 7.776647188511438e-06
  Dropout: 0.20023687538882246
================================================================================

[I 2025-10-29 06:30:32,223] Trial 2048 finished with value: 0.7143710191082803 and parameters: {'seed': 56936, 'model.name': 'roberta-base', 'tok.max_length': 288, 'tok.doc_stride': 64, 'tok.use_fast': True, 'train.batch_size': 24, 'train.grad_accum': 8, 'optim.name': 'adamw', 'optim.lr': 8.660374677604658e-06, 'optim.weight_decay': 0.0006771996291320909, 'optim.beta1': 0.9138561739985457, 'optim.beta2': 0.9679697992389439, 'optim.eps': 3.2298905032874214e-09, 'sched.name': 'one_cycle', 'sched.warmup_ratio': 0.18835361794691377, 'sched.cosine_cycles': 2, 'train.clip_grad': 0.829193115637433, 'model.dropout': 0.23828324532234058, 'model.attn_dropout': 0.08523469312778084, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.8771871796397837, 'head.pooling': 'cls', 'head.layers': 3, 'head.hidden': 256, 'head.activation': 'relu', 'head.dropout': 0.23588989659926723, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.518752386621009, 'loss.cls.alpha': 0.526161202102766, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
EarlyStopping triggered at epoch 24 (patience=20)

================================================================================
TRIAL 2053 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 24
  Learning rate: 5.405477220700781e-06
  Dropout: 0.38863199904076245
================================================================================

[I 2025-10-29 06:32:40,386] Trial 2052 pruned. Pruned at step 27 with metric 0.6384
[W 2025-10-29 06:32:40,784] The parameter `tok.doc_stride` in Trial#2054 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.
[I 2025-10-29 06:32:40,833] Trial 2054 pruned. Pruned: Large model with bsz=48, accum=1 (effective_batch=48) likely causes OOM (24GB GPU limit)
[I 2025-10-29 06:32:41,286] Trial 2055 pruned. Pruned: Large model with bsz=12, accum=6 (effective_batch=72) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2056 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 32
  Learning rate: 6.483475871279605e-05
  Dropout: 0.20264646084232493
================================================================================

[I 2025-10-29 06:36:46,622] Trial 2053 pruned. Pruned at step 9 with metric 0.5474
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2057 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 48
  Learning rate: 7.833839561851541e-06
  Dropout: 0.16261710854007244
================================================================================

[I 2025-10-29 06:44:55,149] Trial 2057 pruned. Pruned at step 22 with metric 0.6210
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2058 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 7.51021318350782e-06
  Dropout: 0.24734482143695669
================================================================================

[I 2025-10-29 06:48:52,307] Trial 2056 pruned. Pruned at step 15 with metric 0.5783

================================================================================
TRIAL 2059 - Configuration:
  Model: {'name': 'bert-large-uncased'}
  Batch size: 8
  Learning rate: 3.446050984025796e-05
  Dropout: 0.04900013323255117
================================================================================

[I 2025-10-29 06:58:39,170] Trial 2058 finished with value: 0.7245857590685176 and parameters: {'seed': 36409, 'model.name': 'roberta-base', 'tok.max_length': 288, 'tok.doc_stride': 48, 'tok.use_fast': False, 'train.batch_size': 24, 'train.grad_accum': 8, 'optim.name': 'adamw', 'optim.lr': 7.51021318350782e-06, 'optim.weight_decay': 0.0001569875689261513, 'optim.beta1': 0.8823506578659663, 'optim.beta2': 0.9884699126541833, 'optim.eps': 7.260836718804598e-08, 'sched.name': 'cosine', 'sched.warmup_ratio': 0.17193704083759057, 'train.clip_grad': 0.5992255203443753, 'model.dropout': 0.24734482143695669, 'model.attn_dropout': 0.1316907394052384, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 3, 'optim.layerwise_lr_decay': 0.9141996779918984, 'head.pooling': 'max', 'head.layers': 3, 'head.hidden': 768, 'head.activation': 'gelu', 'head.dropout': 0.3372354367461946, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.220245547146584, 'loss.cls.alpha': 0.529697430383911, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
EarlyStopping triggered at epoch 28 (patience=20)

================================================================================
TRIAL 2060 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 2.5385729187559318e-05
  Dropout: 0.2439483908073501
================================================================================

[I 2025-10-29 07:06:31,104] Trial 2051 finished with value: 0.7348940914158306 and parameters: {'seed': 43498, 'model.name': 'microsoft/deberta-v3-base', 'tok.max_length': 128, 'tok.doc_stride': 32, 'tok.use_fast': True, 'train.batch_size': 8, 'train.grad_accum': 1, 'optim.name': 'adamw', 'optim.lr': 1.7356916916830394e-05, 'optim.weight_decay': 0.0942984841361138, 'optim.beta1': 0.9370749036373563, 'optim.beta2': 0.9582927029709407, 'optim.eps': 3.1246251346437135e-08, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.1520260703135987, 'sched.poly_power': 1.1479418148421945, 'train.clip_grad': 1.0792109692810445, 'model.dropout': 0.03144874795855429, 'model.attn_dropout': 0.24411036032513547, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.8038179430040663, 'head.pooling': 'mean', 'head.layers': 2, 'head.hidden': 512, 'head.activation': 'gelu', 'head.dropout': 0.3944539483760261, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.0380568960256, 'loss.cls.alpha': 0.43967712199029635, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
EarlyStopping triggered at epoch 26 (patience=20)

================================================================================
TRIAL 2061 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 48
  Learning rate: 3.1766766593001935e-05
  Dropout: 0.13615290232062421
================================================================================

[I 2025-10-29 07:10:09,814] Trial 2061 pruned. Pruned at step 12 with metric 0.6285
[W 2025-10-29 07:10:10,262] The parameter `tok.doc_stride` in Trial#2062 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2062 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 12
  Learning rate: 1.5416797852094528e-05
  Dropout: 0.11141287782505684
================================================================================

[I 2025-10-29 07:15:26,130] Trial 2062 pruned. Pruned at step 13 with metric 0.6027
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2063 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 2.6693388813914597e-05
  Dropout: 0.315913980694149
================================================================================

[I 2025-10-29 07:22:16,619] Trial 2060 pruned. Pruned at step 11 with metric 0.5417
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2064 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 8.289120469985898e-06
  Dropout: 0.20085925470215155
================================================================================

[I 2025-10-29 07:25:21,501] Trial 2063 pruned. Pruned at step 9 with metric 0.5919
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2065 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 8.435003966448855e-06
  Dropout: 0.391571812608308
================================================================================

[I 2025-10-29 07:36:20,501] Trial 2065 pruned. Pruned at step 10 with metric 0.6616
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2066 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 16
  Learning rate: 3.3687960244428796e-05
  Dropout: 0.022634975762947093
================================================================================

[I 2025-10-29 07:41:40,983] Trial 2066 pruned. Pruned at step 8 with metric 0.6297
[I 2025-10-29 07:41:41,509] Trial 2067 pruned. Pruned: Large model with bsz=12, accum=8 (effective_batch=96) likely causes OOM (24GB GPU limit)
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2068 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 2.9690442943320252e-05
  Dropout: 0.3616756574642251
================================================================================

[I 2025-10-29 07:47:17,158] Trial 2064 pruned. Pruned at step 12 with metric 0.6083

================================================================================
TRIAL 2069 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 6.643120950723146e-06
  Dropout: 0.31161251513767874
================================================================================

[I 2025-10-29 07:55:58,013] Trial 2069 pruned. Pruned at step 17 with metric 0.6231
[W 2025-10-29 07:55:58,392] The parameter `tok.doc_stride` in Trial#2070 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2070 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 12
  Learning rate: 5.7377298552714224e-05
  Dropout: 0.4486600010773636
================================================================================

[I 2025-10-29 07:58:05,171] Trial 2068 pruned. Pruned at step 10 with metric 0.5531

================================================================================
TRIAL 2071 - Configuration:
  Model: {'name': 'bert-large-uncased'}
  Batch size: 16
  Learning rate: 1.3340489155884354e-05
  Dropout: 0.3492982028216788
================================================================================

[I 2025-10-29 08:15:41,580] Trial 2071 pruned. Pruned at step 15 with metric 0.5769
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2072 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 32
  Learning rate: 1.2319957232682844e-05
  Dropout: 0.09182485706309669
================================================================================

[I 2025-10-29 08:17:12,268] Trial 2059 pruned. OOM: bert-large-uncased bs=8 len=160
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2059 exceeded GPU memory:
  Model: bert-large-uncased
  Batch size: 8 (effective: 48 with grad_accum=6)
  Max length: 160
  Error: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 39.25 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2073 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 12
  Learning rate: 6.883926603714893e-05
  Dropout: 0.05376620344759299
================================================================================

[I 2025-10-29 08:20:53,293] Trial 2072 pruned. Pruned at step 9 with metric 0.6359
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2074 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 32
  Learning rate: 3.207819637785194e-05
  Dropout: 0.3489780697595503
================================================================================

[I 2025-10-29 08:24:31,659] Trial 2074 pruned. Pruned at step 9 with metric 0.6093

================================================================================
TRIAL 2075 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 3.754883901929699e-05
  Dropout: 0.035351361397158484
================================================================================

[I 2025-10-29 08:28:30,424] Trial 2075 pruned. Pruned at step 7 with metric 0.6093
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2076 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 1.0576277863901816e-05
  Dropout: 0.40289583797594714
================================================================================

[I 2025-10-29 08:35:48,084] Trial 2070 finished with value: 0.44594594594594594 and parameters: {'seed': 50461, 'model.name': 'roberta-large', 'tok.max_length': 160, 'tok.doc_stride': 64, 'tok.use_fast': False, 'train.batch_size': 12, 'train.grad_accum': 4, 'optim.name': 'adamw', 'optim.lr': 5.7377298552714224e-05, 'optim.weight_decay': 0.13954137555316246, 'optim.beta1': 0.8957939936649439, 'optim.beta2': 0.9697844645762304, 'optim.eps': 8.649721171243742e-07, 'sched.name': 'cosine_restart', 'sched.warmup_ratio': 0.048325244245782634, 'sched.cosine_cycles': 2, 'train.clip_grad': 0.900705141477388, 'model.dropout': 0.4486600010773636, 'model.attn_dropout': 0.24518971003388315, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 4, 'optim.layerwise_lr_decay': 0.8909277613354507, 'head.pooling': 'cls', 'head.layers': 4, 'head.hidden': 512, 'head.activation': 'silu', 'head.dropout': 0.3691541803773184, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.551296079617234, 'loss.cls.alpha': 0.6555725307311994, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2077 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 12
  Learning rate: 1.741469816262369e-05
  Dropout: 0.13632601592257496
================================================================================

[I 2025-10-29 08:52:41,127] Trial 2077 pruned. Pruned at step 13 with metric 0.6383
[I 2025-10-29 08:52:41,550] Trial 2078 pruned. Pruned: Large model with bsz=12, accum=6 (effective_batch=72) likely causes OOM (24GB GPU limit)
[I 2025-10-29 08:52:41,951] Trial 2079 pruned. Pruned: Large model with bsz=32, accum=8 (effective_batch=256) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2080 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 5.496493982219523e-06
  Dropout: 0.3547113895575023
================================================================================

[I 2025-10-29 08:54:49,577] Trial 2076 pruned. Pruned at step 14 with metric 0.5742
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2081 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 24
  Learning rate: 2.2563871447684136e-05
  Dropout: 0.09423360488041872
================================================================================

[I 2025-10-29 08:54:55,475] Trial 2080 pruned. OOM: roberta-base bs=64 len=192
[I 2025-10-29 08:54:55,630] Trial 2081 pruned. OOM: microsoft/deberta-v3-base bs=24 len=384
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2081 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 24 (effective: 24 with grad_accum=1)
  Max length: 384
  Error: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 75.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proc
  Pruning trial to allow Optuna to learn memory constraints.


[OOM] Trial 2080 exceeded GPU memory:
  Model: roberta-base
  Batch size: 64 (effective: 256 with grad_accum=4)
  Max length: 192
  Error: CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 75.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proc
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2083 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 8
  Learning rate: 5.354009192461628e-06
  Dropout: 0.1556226486335366
================================================================================


================================================================================
TRIAL 2082 - Configuration:
  Model: {'name': 'bert-large-uncased'}
  Batch size: 16
  Learning rate: 1.1668999767877385e-05
  Dropout: 0.12242217607263706
================================================================================

[I 2025-10-29 08:55:00,268] Trial 2082 pruned. OOM: bert-large-uncased bs=16 len=288
[I 2025-10-29 08:55:00,768] Trial 2084 pruned. Pruned: Large model with bsz=32, accum=2 (effective_batch=64) likely causes OOM (24GB GPU limit)

[OOM] Trial 2082 exceeded GPU memory:
  Model: bert-large-uncased
  Batch size: 16 (effective: 48 with grad_accum=3)
  Max length: 288
  Error: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 79.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2085 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 5.3431651431904674e-06
  Dropout: 0.34646455117550146
================================================================================

[I 2025-10-29 09:10:55,473] Trial 2083 pruned. Pruned at step 11 with metric 0.6583

================================================================================
TRIAL 2086 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 48
  Learning rate: 4.104989123955936e-05
  Dropout: 0.016444040769614185
================================================================================

[I 2025-10-29 09:13:18,497] Trial 2086 pruned. Pruned at step 7 with metric 0.6117
[I 2025-10-29 09:13:18,919] Trial 2087 pruned. Pruned: Large model with bsz=64, accum=4 (effective_batch=256) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2088 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 32
  Learning rate: 9.887689222053667e-06
  Dropout: 0.24959170881949566
================================================================================

[I 2025-10-29 09:18:52,507] Trial 2088 pruned. Pruned at step 11 with metric 0.6083
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2089 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 1.075559419816667e-05
  Dropout: 0.4591005223893072
================================================================================

[I 2025-10-29 09:18:55,870] Trial 2089 pruned. OOM: roberta-base bs=64 len=384
[W 2025-10-29 09:18:56,311] The parameter `tok.doc_stride` in Trial#2090 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.
[I 2025-10-29 09:18:57,665] Trial 2085 pruned. OOM: microsoft/deberta-v3-base bs=8 len=192

[OOM] Trial 2089 exceeded GPU memory:
  Model: roberta-base
  Batch size: 64 (effective: 384 with grad_accum=6)
  Max length: 384
  Error: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 37.31 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2090 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 8.09274598945388e-06
  Dropout: 0.0336260100891502
================================================================================


[OOM] Trial 2085 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 8 (effective: 32 with grad_accum=4)
  Max length: 192
  Error: CUDA out of memory. Tried to allocate 376.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 377.31 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this pro
  Pruning trial to allow Optuna to learn memory constraints.

[W 2025-10-29 09:18:58,465] The parameter `tok.doc_stride` in Trial#2091 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.
[I 2025-10-29 09:18:58,534] Trial 2091 pruned. Pruned: Large model with bsz=24, accum=4 (effective_batch=96) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2092 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 6.494562283175596e-06
  Dropout: 0.1164906953463181
================================================================================

[I 2025-10-29 09:22:58,117] Trial 2090 pruned. Pruned at step 9 with metric 0.5615
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2093 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 32
  Learning rate: 1.390613913513737e-05
  Dropout: 0.33667800909971457
================================================================================

[I 2025-10-29 09:23:13,722] Trial 2073 finished with value: 0.43213296398891965 and parameters: {'seed': 64702, 'model.name': 'roberta-base', 'tok.max_length': 224, 'tok.doc_stride': 64, 'tok.use_fast': True, 'train.batch_size': 12, 'train.grad_accum': 1, 'optim.name': 'adamw', 'optim.lr': 6.883926603714893e-05, 'optim.weight_decay': 0.0028690258231881156, 'optim.beta1': 0.9379913683103074, 'optim.beta2': 0.9749684698682544, 'optim.eps': 1.8373024916893168e-09, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.08522628408755313, 'sched.poly_power': 1.194663764454757, 'train.clip_grad': 1.0298015043729862, 'model.dropout': 0.05376620344759299, 'model.attn_dropout': 0.1422257386735194, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 2, 'optim.layerwise_lr_decay': 0.8407340816540108, 'head.pooling': 'attn', 'head.layers': 4, 'head.hidden': 768, 'head.activation': 'relu', 'head.dropout': 0.36834726693317743, 'loss.cls.type': 'ce_label_smooth', 'loss.cls.label_smoothing': 0.13762370539043578, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2094 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 1.1569672872207416e-05
  Dropout: 0.0960092978585132
================================================================================

[I 2025-10-29 09:25:33,760] Trial 2092 pruned. Pruned at step 9 with metric 0.6107

================================================================================
TRIAL 2095 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 48
  Learning rate: 5.576261042293253e-05
  Dropout: 0.04883460288002277
================================================================================

[I 2025-10-29 09:27:45,402] Trial 2095 pruned. Pruned at step 6 with metric 0.5819
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2096 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 2.0856722875650443e-05
  Dropout: 0.11228193013169124
================================================================================

[I 2025-10-29 09:34:59,282] Trial 2093 pruned. Pruned at step 19 with metric 0.6210

================================================================================
TRIAL 2097 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 8.25584731892142e-06
  Dropout: 0.08146331582803315
================================================================================

[I 2025-10-29 09:47:44,696] Trial 2097 pruned. Pruned at step 9 with metric 0.5154
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2098 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 3.410308646283717e-05
  Dropout: 0.2636550581526368
================================================================================

[I 2025-10-29 10:01:23,072] Trial 2096 finished with value: 0.7256109220237867 and parameters: {'seed': 50892, 'model.name': 'roberta-base', 'tok.max_length': 352, 'tok.doc_stride': 48, 'tok.use_fast': True, 'train.batch_size': 24, 'train.grad_accum': 1, 'optim.name': 'adamw', 'optim.lr': 2.0856722875650443e-05, 'optim.weight_decay': 0.005458583869219613, 'optim.beta1': 0.9340158684169172, 'optim.beta2': 0.9608951925853403, 'optim.eps': 8.043701102112397e-09, 'sched.name': 'one_cycle', 'sched.warmup_ratio': 0.15044797199059526, 'sched.cosine_cycles': 2, 'train.clip_grad': 0.7223061680526114, 'model.dropout': 0.11228193013169124, 'model.attn_dropout': 0.27792155405054086, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.8193151121012671, 'head.pooling': 'mean', 'head.layers': 2, 'head.hidden': 384, 'head.activation': 'gelu', 'head.dropout': 0.3624077860581452, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.999382976184467, 'loss.cls.alpha': 0.5377195896918516, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
EarlyStopping triggered at epoch 54 (patience=20)

================================================================================
TRIAL 2099 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 48
  Learning rate: 1.6695146028979065e-05
  Dropout: 0.3299173493736119
================================================================================

[I 2025-10-29 10:03:40,438] Trial 2098 pruned. Pruned at step 12 with metric 0.5927
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2100 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-large'}
  Batch size: 8
  Learning rate: 1.3590003874334029e-05
  Dropout: 0.14849055236420117
================================================================================

[I 2025-10-29 10:08:58,387] Trial 2099 pruned. Pruned at step 20 with metric 0.5615
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2101 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 12
  Learning rate: 2.9211814155152867e-05
  Dropout: 0.4140239160431476
================================================================================

[I 2025-10-29 10:17:49,993] Trial 2101 pruned. Pruned at step 15 with metric 0.6601
[I 2025-10-29 10:17:50,432] Trial 2102 pruned. Pruned: Large model with bsz=32, accum=2 (effective_batch=64) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2103 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 8.870125679702047e-05
  Dropout: 0.11175581907574487
================================================================================

[I 2025-10-29 10:25:28,120] Trial 2103 finished with value: 0.4474393530997305 and parameters: {'seed': 38392, 'model.name': 'roberta-base', 'tok.max_length': 256, 'tok.doc_stride': 48, 'tok.use_fast': True, 'train.batch_size': 24, 'train.grad_accum': 3, 'optim.name': 'adamw', 'optim.lr': 8.870125679702047e-05, 'optim.weight_decay': 0.02591420251633004, 'optim.beta1': 0.8257573048333597, 'optim.beta2': 0.9758936179346972, 'optim.eps': 6.870161639970167e-07, 'sched.name': 'cosine', 'sched.warmup_ratio': 0.17531183862211874, 'train.clip_grad': 0.5692105496266975, 'model.dropout': 0.11175581907574487, 'model.attn_dropout': 0.2996795913979773, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 3, 'optim.layerwise_lr_decay': 0.8565898402831523, 'head.pooling': 'max', 'head.layers': 4, 'head.hidden': 512, 'head.activation': 'silu', 'head.dropout': 0.15036129707365317, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.87388489970352, 'loss.cls.alpha': 0.5009465021532377, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2104 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 16
  Learning rate: 2.2700980414038555e-05
  Dropout: 0.2787304781822587
================================================================================

[I 2025-10-29 10:31:12,888] Trial 2104 pruned. Pruned at step 17 with metric 0.5807
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2105 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 3.157188359328342e-05
  Dropout: 0.19158530233714344
================================================================================

[I 2025-10-29 10:33:56,108] Trial 2105 pruned. Pruned at step 8 with metric 0.6254
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2106 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 5.620743884187065e-06
  Dropout: 0.2903633637266501
================================================================================

[I 2025-10-29 10:39:25,755] Trial 2106 pruned. Pruned at step 13 with metric 0.6112
[I 2025-10-29 10:39:26,171] Trial 2107 pruned. Pruned: Large model with bsz=64, accum=3 (effective_batch=192) likely causes OOM (24GB GPU limit)
[I 2025-10-29 10:39:26,576] Trial 2108 pruned. Pruned: Large model with bsz=24, accum=2 (effective_batch=48) likely causes OOM (24GB GPU limit)
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2109 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 32
  Learning rate: 7.6000149792697405e-06
  Dropout: 0.20845568534065878
================================================================================

[I 2025-10-29 10:43:17,129] Trial 2109 pruned. Pruned at step 10 with metric 0.5629
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2110 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 48
  Learning rate: 9.923714190394558e-06
  Dropout: 0.15243290653249011
================================================================================

[I 2025-10-29 10:48:58,045] Trial 2110 pruned. Pruned at step 18 with metric 0.6462

================================================================================
TRIAL 2111 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 16
  Learning rate: 6.260819217578321e-06
  Dropout: 0.19486719172487635
================================================================================

[I 2025-10-29 10:51:52,569] Trial 2111 pruned. Pruned at step 8 with metric 0.5515
[I 2025-10-29 10:51:53,029] Trial 2112 pruned. Pruned: Large model with bsz=24, accum=4 (effective_batch=96) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2113 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 4.0898531489989105e-05
  Dropout: 0.42247196148038607
================================================================================

[I 2025-10-29 11:02:51,514] Trial 2113 finished with value: 0.4305555555555556 and parameters: {'seed': 16467, 'model.name': 'roberta-base', 'tok.max_length': 192, 'tok.doc_stride': 96, 'tok.use_fast': False, 'train.batch_size': 8, 'train.grad_accum': 8, 'optim.name': 'adamw', 'optim.lr': 4.0898531489989105e-05, 'optim.weight_decay': 0.1803254212725691, 'optim.beta1': 0.8930435712273568, 'optim.beta2': 0.9700709163116478, 'optim.eps': 1.9457121684056073e-07, 'sched.name': 'cosine_restart', 'sched.warmup_ratio': 0.13552190941039052, 'sched.cosine_cycles': 2, 'train.clip_grad': 0.7789840909317438, 'model.dropout': 0.42247196148038607, 'model.attn_dropout': 0.2579844469800914, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 4, 'optim.layerwise_lr_decay': 0.8672339713697366, 'head.pooling': 'cls', 'head.layers': 3, 'head.hidden': 768, 'head.activation': 'silu', 'head.dropout': 0.2489561694919716, 'loss.cls.type': 'ce_label_smooth', 'loss.cls.label_smoothing': 0.11911116363914266, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2114 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 48
  Learning rate: 1.0682533941274655e-05
  Dropout: 0.4608077641563926
================================================================================

[I 2025-10-29 11:02:55,370] Trial 2114 pruned. OOM: roberta-base bs=48 len=352
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2114 exceeded GPU memory:
  Model: roberta-base
  Batch size: 48 (effective: 144 with grad_accum=3)
  Max length: 352
  Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 52.12 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2115 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 1.4877856716837495e-05
  Dropout: 0.0587427855188905
================================================================================

[I 2025-10-29 11:02:59,279] Trial 2115 pruned. OOM: roberta-base bs=64 len=288
[I 2025-10-29 11:02:59,727] Trial 2116 pruned. Pruned: Large model with bsz=24, accum=8 (effective_batch=192) likely causes OOM (24GB GPU limit)
[I 2025-10-29 11:03:00,135] Trial 2117 pruned. Pruned: Large model with bsz=24, accum=3 (effective_batch=72) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2115 exceeded GPU memory:
  Model: roberta-base
  Batch size: 64 (effective: 64 with grad_accum=1)
  Max length: 288
  Error: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 114.12 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this pro
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2118 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 8.070861670450916e-06
  Dropout: 0.10874477307980547
================================================================================

[I 2025-10-29 11:06:36,936] Trial 2118 pruned. Pruned at step 10 with metric 0.5763

================================================================================
TRIAL 2119 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 4.416981268065901e-05
  Dropout: 0.26662829052716164
================================================================================

[I 2025-10-29 11:09:18,253] Trial 2119 pruned. Pruned at step 7 with metric 0.5962

================================================================================
TRIAL 2120 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 64
  Learning rate: 2.4310633176848185e-05
  Dropout: 0.28979093973779796
================================================================================

[I 2025-10-29 11:09:22,570] Trial 2120 pruned. OOM: bert-base-uncased bs=64 len=256
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2120 exceeded GPU memory:
  Model: bert-base-uncased
  Batch size: 64 (effective: 64 with grad_accum=1)
  Max length: 256
  Error: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 207.12 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this pro
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2121 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 4.2480445795896725e-05
  Dropout: 0.1259540384139216
================================================================================

[I 2025-10-29 11:09:25,862] Trial 2121 pruned. OOM: roberta-base bs=64 len=288
[I 2025-10-29 11:09:26,301] Trial 2122 pruned. Pruned: Large model with bsz=24, accum=3 (effective_batch=72) likely causes OOM (24GB GPU limit)
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

[OOM] Trial 2121 exceeded GPU memory:
  Model: roberta-base
  Batch size: 64 (effective: 256 with grad_accum=4)
  Max length: 288
  Error: CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 60.12 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2123 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-large'}
  Batch size: 8
  Learning rate: 1.43656603997997e-05
  Dropout: 0.07973870394492527
================================================================================

[I 2025-10-29 11:09:32,253] Trial 2123 pruned. OOM: microsoft/deberta-v3-large bs=8 len=384
[I 2025-10-29 11:09:32,780] Trial 2124 pruned. Pruned: Large model with bsz=64, accum=8 (effective_batch=512) likely causes OOM (24GB GPU limit)

[OOM] Trial 2123 exceeded GPU memory:
  Model: microsoft/deberta-v3-large
  Batch size: 8 (effective: 48 with grad_accum=6)
  Max length: 384
  Error: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 84.12 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2125 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 8
  Learning rate: 3.332432230575748e-05
  Dropout: 0.1190265567725886
================================================================================

[I 2025-10-29 11:20:50,425] Trial 2094 pruned. Pruned at step 22 with metric 0.5944
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2126 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 1.9741247285936817e-05
  Dropout: 0.04589016212341182
================================================================================

[I 2025-10-29 11:20:55,972] Trial 2126 pruned. OOM: roberta-base bs=64 len=256
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2126 exceeded GPU memory:
  Model: roberta-base
  Batch size: 64 (effective: 384 with grad_accum=6)
  Max length: 256
  Error: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 150.75 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this pro
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2127 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 12
  Learning rate: 1.3040855005520425e-05
  Dropout: 0.03826027899919597
================================================================================

[I 2025-10-29 11:23:01,904] Trial 2125 pruned. Pruned at step 27 with metric 0.4972
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2128 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 8.726999192984526e-06
  Dropout: 0.12899029763082287
================================================================================

[I 2025-10-29 11:48:44,682] Trial 2128 pruned. Pruned at step 27 with metric 0.5917
[I 2025-10-29 11:48:45,185] Trial 2129 pruned. Pruned: Large model with bsz=64, accum=6 (effective_batch=384) likely causes OOM (24GB GPU limit)

================================================================================
TRIAL 2130 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 5.197888463552662e-05
  Dropout: 0.2848450792660132
================================================================================

[I 2025-10-29 11:54:18,901] Trial 2130 pruned. Pruned at step 10 with metric 0.6343

================================================================================
TRIAL 2131 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 32
  Learning rate: 4.323817117908585e-05
  Dropout: 0.36228326286325885
================================================================================

[I 2025-10-29 11:56:59,325] Trial 2131 pruned. Pruned at step 9 with metric 0.5615
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2132 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 8
  Learning rate: 1.1188476268958642e-05
  Dropout: 0.23047414863291782
================================================================================

[I 2025-10-29 11:58:05,091] Trial 2100 finished with value: 0.6963371936439537 and parameters: {'seed': 56269, 'model.name': 'microsoft/deberta-v3-large', 'tok.max_length': 128, 'tok.doc_stride': 32, 'tok.use_fast': True, 'train.batch_size': 8, 'train.grad_accum': 1, 'optim.name': 'adamw', 'optim.lr': 1.3590003874334029e-05, 'optim.weight_decay': 0.027795284191547826, 'optim.beta1': 0.9087499928520708, 'optim.beta2': 0.9724638047524808, 'optim.eps': 3.14533899800309e-08, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.1831981099938778, 'sched.poly_power': 1.271107941605379, 'train.clip_grad': 1.0203796577012163, 'model.dropout': 0.14849055236420117, 'model.attn_dropout': 0.24668106161805625, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 4, 'optim.layerwise_lr_decay': 0.8231575231562144, 'head.pooling': 'mean', 'head.layers': 3, 'head.hidden': 512, 'head.activation': 'gelu', 'head.dropout': 0.38706127417021857, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.942518011246023, 'loss.cls.alpha': 0.43432919982698476, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
[I 2025-10-29 11:58:05,526] Trial 2133 pruned. Pruned: Large model with bsz=48, accum=1 (effective_batch=48) likely causes OOM (24GB GPU limit)
[I 2025-10-29 11:58:05,945] Trial 2134 pruned. Pruned: Large model with bsz=64, accum=1 (effective_batch=64) likely causes OOM (24GB GPU limit)
[I 2025-10-29 11:58:06,365] Trial 2135 pruned. Pruned: Large model with bsz=24, accum=4 (effective_batch=96) likely causes OOM (24GB GPU limit)
EarlyStopping triggered at epoch 25 (patience=20)

================================================================================
TRIAL 2136 - Configuration:
  Model: {'name': 'xlm-roberta-base'}
  Batch size: 8
  Learning rate: 8.353546248947723e-06
  Dropout: 0.26849028781812456
================================================================================

[I 2025-10-29 12:05:01,410] Trial 2127 finished with value: 0.6521493212669683 and parameters: {'seed': 61731, 'model.name': 'roberta-base', 'tok.max_length': 192, 'tok.doc_stride': 32, 'tok.use_fast': False, 'train.batch_size': 12, 'train.grad_accum': 2, 'optim.name': 'adamw', 'optim.lr': 1.3040855005520425e-05, 'optim.weight_decay': 0.18047599623519403, 'optim.beta1': 0.8334516919718212, 'optim.beta2': 0.9756701442546147, 'optim.eps': 7.601105683513302e-08, 'sched.name': 'cosine', 'sched.warmup_ratio': 0.09400420314513586, 'train.clip_grad': 0.7682270071299997, 'model.dropout': 0.03826027899919597, 'model.attn_dropout': 0.21727401276634084, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 2, 'optim.layerwise_lr_decay': 0.8195143242684773, 'head.pooling': 'max', 'head.layers': 3, 'head.hidden': 256, 'head.activation': 'silu', 'head.dropout': 0.10144669191375691, 'loss.cls.type': 'ce', 'loss.cls.label_smoothing': 0.09973316168926288, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 23 (patience=20)

================================================================================
TRIAL 2137 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 7.329703808895809e-06
  Dropout: 0.36093928007557
================================================================================

[I 2025-10-29 12:12:35,832] Trial 2132 pruned. Pruned at step 11 with metric 0.6564

================================================================================
TRIAL 2138 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 64
  Learning rate: 4.9569044285399674e-05
  Dropout: 0.013074692296904153
================================================================================

[I 2025-10-29 12:20:41,420] Trial 2138 pruned. Pruned at step 27 with metric 0.6199
[I 2025-10-29 12:20:41,851] Trial 2139 pruned. Pruned: Large model with bsz=32, accum=2 (effective_batch=64) likely causes OOM (24GB GPU limit)
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2140 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 16
  Learning rate: 2.802451449979804e-05
  Dropout: 0.2834710123975604
================================================================================

[I 2025-10-29 12:48:09,672] Trial 2140 pruned. Pruned at step 27 with metric 0.6537
[I 2025-10-29 12:48:10,184] Trial 2141 pruned. Pruned: Large model with bsz=64, accum=1 (effective_batch=64) likely causes OOM (24GB GPU limit)
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2142 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 32
  Learning rate: 6.706803648433681e-06
  Dropout: 0.08187750949689182
================================================================================

[I 2025-10-29 12:54:12,627] Trial 2142 pruned. Pruned at step 12 with metric 0.5796
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2143 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 9.359669893086618e-06
  Dropout: 0.3593152810253289
================================================================================

[I 2025-10-29 13:07:38,542] Trial 2143 finished with value: 0.7536457825846894 and parameters: {'seed': 62399, 'model.name': 'roberta-base', 'tok.max_length': 224, 'tok.doc_stride': 64, 'tok.use_fast': False, 'train.batch_size': 16, 'train.grad_accum': 8, 'optim.name': 'adamw', 'optim.lr': 9.359669893086618e-06, 'optim.weight_decay': 0.014711628709990274, 'optim.beta1': 0.8997738827571674, 'optim.beta2': 0.9652886148547652, 'optim.eps': 1.2327267628876577e-08, 'sched.name': 'cosine_restart', 'sched.warmup_ratio': 0.05786631374734218, 'sched.cosine_cycles': 1, 'train.clip_grad': 1.3185915080148203, 'model.dropout': 0.3593152810253289, 'model.attn_dropout': 0.25910670427094296, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.8655193104382489, 'head.pooling': 'cls', 'head.layers': 2, 'head.hidden': 768, 'head.activation': 'silu', 'head.dropout': 0.36669844216484204, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.569461241703629, 'loss.cls.alpha': 0.8048914513721434, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 32 (patience=20)

================================================================================
TRIAL 2144 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 6.394910949408731e-06
  Dropout: 0.13767632950563666
================================================================================

[I 2025-10-29 13:13:05,885] Trial 2144 pruned. Pruned at step 11 with metric 0.6189
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2145 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 6.5377811816677835e-06
  Dropout: 0.4384230923902218
================================================================================

[I 2025-10-29 13:17:34,973] Trial 2145 pruned. Pruned at step 16 with metric 0.6207
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2146 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 2.531751938377759e-05
  Dropout: 0.4139095684787001
================================================================================

[I 2025-10-29 13:22:39,002] Trial 2146 pruned. Pruned at step 11 with metric 0.5954

================================================================================
TRIAL 2147 - Configuration:
  Model: {'name': 'xlm-roberta-base'}
  Batch size: 8
  Learning rate: 1.538024457292694e-05
  Dropout: 0.373497505016017
================================================================================

[I 2025-10-29 13:28:30,830] Trial 2147 pruned. Pruned at step 9 with metric 0.5763

================================================================================
TRIAL 2148 - Configuration:
  Model: {'name': 'bert-large-uncased'}
  Batch size: 16
  Learning rate: 3.124876995520325e-05
  Dropout: 0.3775082905107963
================================================================================

[I 2025-10-29 13:51:36,717] Trial 2136 finished with value: 0.6692183571616195 and parameters: {'seed': 49260, 'model.name': 'xlm-roberta-base', 'tok.max_length': 192, 'tok.doc_stride': 80, 'tok.use_fast': True, 'train.batch_size': 8, 'train.grad_accum': 6, 'optim.name': 'adamw', 'optim.lr': 8.353546248947723e-06, 'optim.weight_decay': 0.012052867810994843, 'optim.beta1': 0.879621138515522, 'optim.beta2': 0.9522080968863782, 'optim.eps': 1.5187121916677395e-09, 'sched.name': 'one_cycle', 'sched.warmup_ratio': 0.10820153570995765, 'sched.cosine_cycles': 2, 'train.clip_grad': 0.3260219307765879, 'model.dropout': 0.26849028781812456, 'model.attn_dropout': 0.22679526625314034, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.925429637753048, 'head.pooling': 'attn', 'head.layers': 2, 'head.hidden': 1024, 'head.activation': 'relu', 'head.dropout': 0.10784548924663874, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.8685651586471987, 'loss.cls.alpha': 0.5645712321436586, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 63 (patience=20)

================================================================================
TRIAL 2149 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 32
  Learning rate: 2.013779862740939e-05
  Dropout: 0.4038486802893118
================================================================================

[I 2025-10-29 13:56:17,306] Trial 2148 finished with value: 0.4368131868131868 and parameters: {'seed': 63190, 'model.name': 'bert-large-uncased', 'tok.max_length': 288, 'tok.doc_stride': 32, 'tok.use_fast': False, 'train.batch_size': 16, 'train.grad_accum': 1, 'optim.name': 'adamw', 'optim.lr': 3.124876995520325e-05, 'optim.weight_decay': 0.012780438777760009, 'optim.beta1': 0.8560327916978536, 'optim.beta2': 0.9580589208342285, 'optim.eps': 5.3845606501288363e-08, 'sched.name': 'cosine_restart', 'sched.warmup_ratio': 0.14508642076147324, 'sched.cosine_cycles': 1, 'train.clip_grad': 0.8410948493719675, 'model.dropout': 0.3775082905107963, 'model.attn_dropout': 0.29591488881185607, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 6, 'optim.layerwise_lr_decay': 0.8314928813934219, 'head.pooling': 'cls', 'head.layers': 3, 'head.hidden': 2048, 'head.activation': 'silu', 'head.dropout': 0.25604085892189443, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.862304237740849, 'loss.cls.alpha': 0.7815026833085443, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2150 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 24
  Learning rate: 6.237977147939014e-06
  Dropout: 0.06269865640913679
================================================================================

[I 2025-10-29 14:03:23,873] Trial 2150 pruned. Pruned at step 9 with metric 0.6257
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2151 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 2.2281326245766427e-05
  Dropout: 0.19562383065590488
================================================================================

[I 2025-10-29 14:03:51,948] Trial 2149 finished with value: 0.6825806451612904 and parameters: {'seed': 50993, 'model.name': 'roberta-base', 'tok.max_length': 192, 'tok.doc_stride': 80, 'tok.use_fast': True, 'train.batch_size': 32, 'train.grad_accum': 3, 'optim.name': 'adamw', 'optim.lr': 2.013779862740939e-05, 'optim.weight_decay': 0.004434975877585879, 'optim.beta1': 0.8716955138820367, 'optim.beta2': 0.9613157013019531, 'optim.eps': 1.1747761174233844e-08, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.09558085531716062, 'sched.poly_power': 0.8768306882390513, 'train.clip_grad': 1.270054672601714, 'model.dropout': 0.4038486802893118, 'model.attn_dropout': 0.24785787463937792, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.8396750302080707, 'head.pooling': 'cls', 'head.layers': 2, 'head.hidden': 384, 'head.activation': 'silu', 'head.dropout': 0.43523213266708727, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.583424920673928, 'loss.cls.alpha': 0.8433529981313006, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
EarlyStopping triggered at epoch 24 (patience=20)
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2152 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-large'}
  Batch size: 12
  Learning rate: 7.064233537957644e-06
  Dropout: 0.3229284224961584
================================================================================

[I 2025-10-29 14:06:45,026] Trial 2151 pruned. Pruned at step 8 with metric 0.6085
[I 2025-10-29 14:06:45,470] Trial 2153 pruned. Pruned: Large model with bsz=24, accum=6 (effective_batch=144) likely causes OOM (24GB GPU limit)

================================================================================
TRIAL 2154 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 64
  Learning rate: 8.356110202831287e-06
  Dropout: 0.19654661179261684
================================================================================

[I 2025-10-29 14:06:49,049] Trial 2154 pruned. OOM: bert-base-uncased bs=64 len=128
[I 2025-10-29 14:06:50,188] Trial 2152 pruned. OOM: microsoft/deberta-v3-large bs=12 len=224
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

[OOM] Trial 2154 exceeded GPU memory:
  Model: bert-base-uncased
  Batch size: 64 (effective: 192 with grad_accum=3)
  Max length: 128
  Error: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 49.88 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2155 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 24
  Learning rate: 8.891823941747685e-06
  Dropout: 0.09977796188869945
================================================================================


[OOM] Trial 2152 exceeded GPU memory:
  Model: microsoft/deberta-v3-large
  Batch size: 12 (effective: 24 with grad_accum=2)
  Max length: 224
  Error: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 49.88 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2156 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 9.437400415973556e-06
  Dropout: 0.10311037584904549
================================================================================

Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[I 2025-10-29 14:20:13,703] Trial 2155 pruned. Pruned at step 27 with metric 0.6538
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2157 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 6.258282510221888e-06
  Dropout: 0.13550951445776527
================================================================================

[I 2025-10-29 14:26:30,738] Trial 2157 pruned. Pruned at step 11 with metric 0.6562
[W 2025-10-29 14:26:31,139] The parameter `tok.doc_stride` in Trial#2158 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2158 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 48
  Learning rate: 2.1419393407008036e-05
  Dropout: 0.07252709529832124
================================================================================

[I 2025-10-29 14:31:14,748] Trial 2158 pruned. Pruned at step 27 with metric 0.6338

================================================================================
TRIAL 2159 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 48
  Learning rate: 1.1364217288081728e-05
  Dropout: 0.3092934408981005
================================================================================

[I 2025-10-29 14:38:40,565] Trial 2159 pruned. Pruned at step 27 with metric 0.6469
[I 2025-10-29 14:38:41,011] Trial 2160 pruned. Pruned: Large model with bsz=64, accum=8 (effective_batch=512) likely causes OOM (24GB GPU limit)
[I 2025-10-29 14:38:41,433] Trial 2161 pruned. Pruned: Large model with bsz=32, accum=2 (effective_batch=64) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2162 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 9.262085678978992e-05
  Dropout: 0.1537340851203397
================================================================================

[I 2025-10-29 14:48:58,103] Trial 2156 pruned. Pruned at step 27 with metric 0.6472

================================================================================
TRIAL 2163 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 16
  Learning rate: 3.8341838567111825e-05
  Dropout: 0.39863454314672825
================================================================================

[I 2025-10-29 14:51:31,232] Trial 2162 finished with value: 0.45478723404255317 and parameters: {'seed': 63727, 'model.name': 'roberta-base', 'tok.max_length': 256, 'tok.doc_stride': 48, 'tok.use_fast': False, 'train.batch_size': 8, 'train.grad_accum': 3, 'optim.name': 'adamw', 'optim.lr': 9.262085678978992e-05, 'optim.weight_decay': 3.369976169917924e-05, 'optim.beta1': 0.9294218177260183, 'optim.beta2': 0.9954088312868067, 'optim.eps': 1.4020862963042868e-09, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.13642974836738755, 'sched.poly_power': 0.6334417978565937, 'train.clip_grad': 1.1128338044683121, 'model.dropout': 0.1537340851203397, 'model.attn_dropout': 0.14152694726371742, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 3, 'optim.layerwise_lr_decay': 0.8217959440734598, 'head.pooling': 'attn', 'head.layers': 4, 'head.hidden': 768, 'head.activation': 'relu', 'head.dropout': 0.46424724399663686, 'loss.cls.type': 'ce_label_smooth', 'loss.cls.label_smoothing': 0.12142404372462565, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
[W 2025-10-29 14:51:31,635] The parameter `tok.doc_stride` in Trial#2164 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2164 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 2.9239122596363067e-05
  Dropout: 0.13693551603053544
================================================================================

[I 2025-10-29 14:54:56,688] Trial 2164 pruned. Pruned at step 10 with metric 0.5997
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2165 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 2.1429959917396643e-05
  Dropout: 0.4110865023071122
================================================================================

[I 2025-10-29 15:00:51,578] Trial 2165 pruned. Pruned at step 16 with metric 0.6174

================================================================================
TRIAL 2166 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 32
  Learning rate: 8.461958967173183e-06
  Dropout: 0.02544339797942155
================================================================================

[I 2025-10-29 15:04:49,288] Trial 2166 pruned. Pruned at step 10 with metric 0.4842
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2167 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 48
  Learning rate: 6.359256430825291e-06
  Dropout: 0.2224222406272378
================================================================================

[I 2025-10-29 15:08:53,678] Trial 2167 pruned. Pruned at step 11 with metric 0.6189

================================================================================
TRIAL 2168 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 32
  Learning rate: 1.8994254763022268e-05
  Dropout: 0.00665408800371382
================================================================================

[I 2025-10-29 15:11:49,377] Trial 2168 pruned. Pruned at step 9 with metric 0.5957
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2169 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 12
  Learning rate: 1.3024657816644661e-05
  Dropout: 0.25788459035443595
================================================================================

[I 2025-10-29 15:12:29,767] Trial 2137 finished with value: 0.7204545454545455 and parameters: {'seed': 24541, 'model.name': 'roberta-base', 'tok.max_length': 128, 'tok.doc_stride': 32, 'tok.use_fast': True, 'train.batch_size': 8, 'train.grad_accum': 6, 'optim.name': 'adamw', 'optim.lr': 7.329703808895809e-06, 'optim.weight_decay': 1.256968559343751e-05, 'optim.beta1': 0.8646589697634963, 'optim.beta2': 0.9796447171050449, 'optim.eps': 2.797000129665686e-09, 'sched.name': 'cosine_restart', 'sched.warmup_ratio': 0.09822365118710397, 'sched.cosine_cycles': 2, 'train.clip_grad': 0.7459444542331372, 'model.dropout': 0.36093928007557, 'model.attn_dropout': 0.06245432272921583, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.9729338390660854, 'head.pooling': 'mean', 'head.layers': 4, 'head.hidden': 768, 'head.activation': 'relu', 'head.dropout': 0.49469028110695556, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.513605327839244, 'loss.cls.alpha': 0.5083029161383229, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 42 (patience=20)

================================================================================
TRIAL 2170 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 8.108658634438171e-06
  Dropout: 0.22290454175843005
================================================================================

[I 2025-10-29 15:21:57,471] Trial 2163 finished with value: 0.7143710191082803 and parameters: {'seed': 56576, 'model.name': 'bert-base-uncased', 'tok.max_length': 288, 'tok.doc_stride': 64, 'tok.use_fast': False, 'train.batch_size': 16, 'train.grad_accum': 6, 'optim.name': 'adamw', 'optim.lr': 3.8341838567111825e-05, 'optim.weight_decay': 0.04624601522388542, 'optim.beta1': 0.902129598388458, 'optim.beta2': 0.966708369877109, 'optim.eps': 8.481620226287901e-07, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.02714385856401346, 'sched.poly_power': 0.6446038028953947, 'train.clip_grad': 1.1529513024964644, 'model.dropout': 0.39863454314672825, 'model.attn_dropout': 0.25331689635455107, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.9130344099407876, 'head.pooling': 'cls', 'head.layers': 4, 'head.hidden': 1024, 'head.activation': 'silu', 'head.dropout': 0.4595074348741334, 'loss.cls.type': 'ce_label_smooth', 'loss.cls.label_smoothing': 0.17979603880562067, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
EarlyStopping triggered at epoch 31 (patience=20)

================================================================================
TRIAL 2171 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-large'}
  Batch size: 8
  Learning rate: 6.228902104170209e-06
  Dropout: 0.4003977505767532
================================================================================

[I 2025-10-29 15:22:04,288] Trial 2171 pruned. OOM: microsoft/deberta-v3-large bs=8 len=320
[I 2025-10-29 15:22:04,843] Trial 2172 pruned. Pruned: Large model with bsz=16, accum=8 (effective_batch=128) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2171 exceeded GPU memory:
  Model: microsoft/deberta-v3-large
  Batch size: 8 (effective: 24 with grad_accum=3)
  Max length: 320
  Error: CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 60.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2173 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 1.1403324981985452e-05
  Dropout: 0.41903308956147123
================================================================================

[I 2025-10-29 15:22:09,240] Trial 2173 pruned. OOM: roberta-base bs=64 len=192
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2173 exceeded GPU memory:
  Model: roberta-base
  Batch size: 64 (effective: 128 with grad_accum=2)
  Max length: 192
  Error: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 40.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2174 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 16
  Learning rate: 4.645679629945627e-05
  Dropout: 0.3199886063387093
================================================================================

[I 2025-10-29 15:22:14,759] Trial 2169 pruned. OOM: microsoft/deberta-v3-base bs=12 len=256

[OOM] Trial 2169 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 12 (effective: 96 with grad_accum=8)
  Max length: 256
  Error: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 102.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proc
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2175 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 1.0036589636772103e-05
  Dropout: 0.4081015352414146
================================================================================

[I 2025-10-29 15:31:06,897] Trial 2175 pruned. Pruned at step 16 with metric 0.6076

================================================================================
TRIAL 2176 - Configuration:
  Model: {'name': 'xlm-roberta-base'}
  Batch size: 16
  Learning rate: 2.1139531091459878e-05
  Dropout: 0.35707034110102615
================================================================================

[I 2025-10-29 15:33:01,842] Trial 2176 pruned. OOM: xlm-roberta-base bs=16 len=160
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2176 exceeded GPU memory:
  Model: xlm-roberta-base
  Batch size: 16 (effective: 64 with grad_accum=4)
  Max length: 160
  Error: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 770.19 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this pro
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2177 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 2.1401073794350178e-05
  Dropout: 0.28656263611683375
================================================================================

[I 2025-10-29 15:35:02,419] Trial 2170 pruned. Pruned at step 32 with metric 0.6338
[I 2025-10-29 15:35:02,872] Trial 2178 pruned. Pruned: Large model with bsz=24, accum=1 (effective_batch=24) likely causes OOM (24GB GPU limit)
[W 2025-10-29 15:35:03,253] The parameter `tok.doc_stride` in Trial#2179 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.

================================================================================
TRIAL 2179 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 1.0414956403912288e-05
  Dropout: 0.05801534585702877
================================================================================

[I 2025-10-29 15:57:21,449] Trial 2174 finished with value: 0.4562334217506631 and parameters: {'seed': 37342, 'model.name': 'roberta-large', 'tok.max_length': 192, 'tok.doc_stride': 32, 'tok.use_fast': True, 'train.batch_size': 16, 'train.grad_accum': 3, 'optim.name': 'adamw', 'optim.lr': 4.645679629945627e-05, 'optim.weight_decay': 0.06199728239492324, 'optim.beta1': 0.9300013807857611, 'optim.beta2': 0.9677442709876042, 'optim.eps': 1.300084566134126e-07, 'sched.name': 'cosine_restart', 'sched.warmup_ratio': 0.05133834169606735, 'sched.cosine_cycles': 1, 'train.clip_grad': 1.0013349243463885, 'model.dropout': 0.3199886063387093, 'model.attn_dropout': 0.2937744357893981, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.8521798298435097, 'head.pooling': 'cls', 'head.layers': 3, 'head.hidden': 384, 'head.activation': 'relu', 'head.dropout': 0.23780177930748683, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.710443592551256, 'loss.cls.alpha': 0.7672592296314127, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2180 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 32
  Learning rate: 4.2159976424396274e-05
  Dropout: 0.2568884531976355
================================================================================

[I 2025-10-29 15:57:45,763] Trial 2179 pruned. Pruned at step 11 with metric 0.6165
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2181 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 32
  Learning rate: 5.070564178329595e-05
  Dropout: 0.16824238654516466
================================================================================

[I 2025-10-29 16:00:50,089] Trial 2177 finished with value: 0.6592720735388895 and parameters: {'seed': 47629, 'model.name': 'roberta-base', 'tok.max_length': 288, 'tok.doc_stride': 64, 'tok.use_fast': False, 'train.batch_size': 8, 'train.grad_accum': 8, 'optim.name': 'adamw', 'optim.lr': 2.1401073794350178e-05, 'optim.weight_decay': 0.03153397181613537, 'optim.beta1': 0.8480306299164031, 'optim.beta2': 0.9684107853839129, 'optim.eps': 2.1889386709294505e-07, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.10581264751146535, 'sched.poly_power': 0.7558917003363091, 'train.clip_grad': 1.015203529747096, 'model.dropout': 0.28656263611683375, 'model.attn_dropout': 0.19405094597575762, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.9654637678878452, 'head.pooling': 'max', 'head.layers': 4, 'head.hidden': 1024, 'head.activation': 'silu', 'head.dropout': 0.37028117259635396, 'loss.cls.type': 'focal', 'loss.cls.gamma': 1.0395139764228944, 'loss.cls.alpha': 0.2458617708912595, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 27 (patience=20)

================================================================================
TRIAL 2182 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 16
  Learning rate: 1.589227950757525e-05
  Dropout: 0.4495791888433178
================================================================================

[I 2025-10-29 16:01:37,160] Trial 2180 pruned. Pruned at step 8 with metric 0.6038

================================================================================
TRIAL 2183 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 64
  Learning rate: 5.1520295472419225e-05
  Dropout: 0.2034159927198022
================================================================================

[I 2025-10-29 16:01:41,492] Trial 2181 pruned. OOM: roberta-base bs=32 len=128
[I 2025-10-29 16:01:41,651] Trial 2183 pruned. OOM: bert-base-uncased bs=64 len=192
[I 2025-10-29 16:01:42,814] Trial 2182 pruned. OOM: roberta-large bs=16 len=320
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

[OOM] Trial 2183 exceeded GPU memory:
  Model: bert-base-uncased
  Batch size: 64 (effective: 64 with grad_accum=1)
  Max length: 192
  Error: CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 78.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


[OOM] Trial 2181 exceeded GPU memory:
  Model: roberta-base
  Batch size: 32 (effective: 32 with grad_accum=1)
  Max length: 128
  Error: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 38.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2184 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 12
  Learning rate: 7.968484105657356e-06
  Dropout: 0.3735481257093981
================================================================================


[OOM] Trial 2182 exceeded GPU memory:
  Model: roberta-large
  Batch size: 16 (effective: 32 with grad_accum=2)
  Max length: 320
  Error: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 38.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2185 - Configuration:
  Model: {'name': 'xlm-roberta-base'}
  Batch size: 12
  Learning rate: 7.111514388892423e-05
  Dropout: 0.10173342680374624
================================================================================


================================================================================
TRIAL 2186 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 12
  Learning rate: 6.740015330630327e-06
  Dropout: 0.3470709030015782
================================================================================

[I 2025-10-29 16:08:00,753] Trial 2186 pruned. Pruned at step 9 with metric 0.6002

================================================================================
TRIAL 2187 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 48
  Learning rate: 3.4725685505465784e-05
  Dropout: 0.20786930881137747
================================================================================

[I 2025-10-29 16:23:22,660] Trial 2187 finished with value: 0.6702059202059202 and parameters: {'seed': 47506, 'model.name': 'bert-base-uncased', 'tok.max_length': 320, 'tok.doc_stride': 64, 'tok.use_fast': True, 'train.batch_size': 48, 'train.grad_accum': 1, 'optim.name': 'adamw', 'optim.lr': 3.4725685505465784e-05, 'optim.weight_decay': 0.0027171425644308663, 'optim.beta1': 0.9430015492959125, 'optim.beta2': 0.9708954223333328, 'optim.eps': 2.0803580744579252e-09, 'sched.name': 'cosine_restart', 'sched.warmup_ratio': 0.06795159422895901, 'sched.cosine_cycles': 1, 'train.clip_grad': 1.0373100952260228, 'model.dropout': 0.20786930881137747, 'model.attn_dropout': 0.10252264305971584, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 3, 'optim.layerwise_lr_decay': 0.925234006076666, 'head.pooling': 'cls', 'head.layers': 3, 'head.hidden': 512, 'head.activation': 'relu', 'head.dropout': 0.42172451688909174, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.047469356499196, 'loss.cls.alpha': 0.8763360330154222, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
[I 2025-10-29 16:23:23,091] Trial 2188 pruned. Pruned: Large model with bsz=24, accum=3 (effective_batch=72) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 42 (patience=20)

================================================================================
TRIAL 2189 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 8.250223365095106e-06
  Dropout: 0.08492466071088899
================================================================================

[I 2025-10-29 16:30:42,412] Trial 2189 pruned. Pruned at step 14 with metric 0.5845
[W 2025-10-29 16:30:42,816] The parameter `tok.doc_stride` in Trial#2190 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.

================================================================================
TRIAL 2190 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 7.113422203088254e-06
  Dropout: 0.2241426252029856
================================================================================

[I 2025-10-29 16:33:29,673] Trial 2190 pruned. Pruned at step 11 with metric 0.5884
[I 2025-10-29 16:33:30,116] Trial 2191 pruned. Pruned: Large model with bsz=64, accum=3 (effective_batch=192) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2192 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 1.4806147952982251e-05
  Dropout: 0.14384362650713645
================================================================================

[I 2025-10-29 16:38:13,929] Trial 2192 pruned. Pruned at step 11 with metric 0.6174
[I 2025-10-29 16:38:14,352] Trial 2193 pruned. Pruned: Large model with bsz=32, accum=8 (effective_batch=256) likely causes OOM (24GB GPU limit)
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2194 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 64
  Learning rate: 9.778069742430769e-06
  Dropout: 0.35614937741159525
================================================================================

[I 2025-10-29 16:38:19,218] Trial 2194 pruned. OOM: microsoft/deberta-v3-base bs=64 len=256
[W 2025-10-29 16:38:19,715] The parameter `tok.doc_stride` in Trial#2195 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2194 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 64 (effective: 256 with grad_accum=4)
  Max length: 256
  Error: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 68.12 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2195 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 4.055134568157858e-05
  Dropout: 0.3663806922935286
================================================================================

[I 2025-10-29 16:41:12,125] Trial 2195 pruned. Pruned at step 14 with metric 0.6053

================================================================================
TRIAL 2196 - Configuration:
  Model: {'name': 'bert-large-uncased'}
  Batch size: 8
  Learning rate: 3.375261731622335e-05
  Dropout: 0.01880476033720274
================================================================================

[I 2025-10-29 17:19:07,254] Trial 2196 finished with value: 0.4429347826086957 and parameters: {'seed': 13202, 'model.name': 'bert-large-uncased', 'tok.max_length': 352, 'tok.doc_stride': 48, 'tok.use_fast': False, 'train.batch_size': 8, 'train.grad_accum': 6, 'optim.name': 'adamw', 'optim.lr': 3.375261731622335e-05, 'optim.weight_decay': 0.0024085018895999904, 'optim.beta1': 0.9403904859178964, 'optim.beta2': 0.9862467112522888, 'optim.eps': 2.4340619985359787e-08, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.07287463551308368, 'sched.poly_power': 1.6050634557115342, 'train.clip_grad': 1.389045988642957, 'model.dropout': 0.01880476033720274, 'model.attn_dropout': 0.24869077401634673, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 3, 'optim.layerwise_lr_decay': 0.8542870180541521, 'head.pooling': 'mean', 'head.layers': 3, 'head.hidden': 768, 'head.activation': 'relu', 'head.dropout': 0.3437127924233773, 'loss.cls.type': 'ce', 'loss.cls.label_smoothing': 0.12980513335633762, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
[I 2025-10-29 17:19:07,696] Trial 2197 pruned. Pruned: Large model with bsz=24, accum=6 (effective_batch=144) likely causes OOM (24GB GPU limit)
[I 2025-10-29 17:19:08,121] Trial 2198 pruned. Pruned: Large model with bsz=32, accum=6 (effective_batch=192) likely causes OOM (24GB GPU limit)
[I 2025-10-29 17:19:08,566] Trial 2199 pruned. Pruned: Large model with bsz=32, accum=1 (effective_batch=32) likely causes OOM (24GB GPU limit)
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2200 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 16
  Learning rate: 7.809632527585665e-06
  Dropout: 0.38025374222029096
================================================================================

[I 2025-10-29 17:22:18,569] Trial 2185 finished with value: 0.4368131868131868 and parameters: {'seed': 37258, 'model.name': 'xlm-roberta-base', 'tok.max_length': 160, 'tok.doc_stride': 64, 'tok.use_fast': True, 'train.batch_size': 12, 'train.grad_accum': 4, 'optim.name': 'adamw', 'optim.lr': 7.111514388892423e-05, 'optim.weight_decay': 0.00555755698600844, 'optim.beta1': 0.8477168124370008, 'optim.beta2': 0.9732573808339076, 'optim.eps': 2.832609821196195e-07, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.10791959831195697, 'sched.poly_power': 1.8751671281376971, 'train.clip_grad': 0.5582617283338018, 'model.dropout': 0.10173342680374624, 'model.attn_dropout': 0.2918186318417606, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 3, 'optim.layerwise_lr_decay': 0.8160850013641681, 'head.pooling': 'max', 'head.layers': 3, 'head.hidden': 1536, 'head.activation': 'silu', 'head.dropout': 0.12140712671737636, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.4676567601662045, 'loss.cls.alpha': 0.7763546106550341, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2201 - Configuration:
  Model: {'name': 'bert-large-uncased'}
  Batch size: 8
  Learning rate: 1.3824941512263618e-05
  Dropout: 0.1449443430944175
================================================================================

[I 2025-10-29 17:33:11,100] Trial 2184 finished with value: 0.7103658536585367 and parameters: {'seed': 65351, 'model.name': 'microsoft/deberta-v3-base', 'tok.max_length': 128, 'tok.doc_stride': 32, 'tok.use_fast': True, 'train.batch_size': 12, 'train.grad_accum': 3, 'optim.name': 'adamw', 'optim.lr': 7.968484105657356e-06, 'optim.weight_decay': 1.5406140640990534e-05, 'optim.beta1': 0.8304119025629982, 'optim.beta2': 0.9857038731854565, 'optim.eps': 3.651584610964191e-08, 'sched.name': 'cosine', 'sched.warmup_ratio': 0.16794768575186253, 'train.clip_grad': 0.9783218876562868, 'model.dropout': 0.3735481257093981, 'model.attn_dropout': 0.0400266656800265, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 3, 'optim.layerwise_lr_decay': 0.9345415070653018, 'head.pooling': 'attn', 'head.layers': 4, 'head.hidden': 768, 'head.activation': 'relu', 'head.dropout': 0.4268501763641894, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.76730661515817, 'loss.cls.alpha': 0.11749604295113011, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
EarlyStopping triggered at epoch 35 (patience=20)

================================================================================
TRIAL 2202 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-large'}
  Batch size: 8
  Learning rate: 2.81644641438846e-05
  Dropout: 0.15333089966211946
================================================================================

[I 2025-10-29 17:33:20,106] Trial 2202 pruned. OOM: microsoft/deberta-v3-large bs=8 len=128
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2202 exceeded GPU memory:
  Model: microsoft/deberta-v3-large
  Batch size: 8 (effective: 16 with grad_accum=2)
  Max length: 128
  Error: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 54.12 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2203 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 12
  Learning rate: 1.0172299606224882e-05
  Dropout: 0.2030003344059459
================================================================================

[I 2025-10-29 17:39:29,742] Trial 2200 finished with value: 0.6855828220858895 and parameters: {'seed': 64873, 'model.name': 'microsoft/deberta-v3-base', 'tok.max_length': 256, 'tok.doc_stride': 64, 'tok.use_fast': False, 'train.batch_size': 16, 'train.grad_accum': 3, 'optim.name': 'adamw', 'optim.lr': 7.809632527585665e-06, 'optim.weight_decay': 0.002589216830439334, 'optim.beta1': 0.8596669397877807, 'optim.beta2': 0.9600366073862043, 'optim.eps': 1.352645646212128e-08, 'sched.name': 'cosine_restart', 'sched.warmup_ratio': 0.021717518968031084, 'sched.cosine_cycles': 2, 'train.clip_grad': 1.3357550699573244, 'model.dropout': 0.38025374222029096, 'model.attn_dropout': 0.24824812416447226, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 4, 'optim.layerwise_lr_decay': 0.9091288139039183, 'head.pooling': 'cls', 'head.layers': 2, 'head.hidden': 512, 'head.activation': 'silu', 'head.dropout': 0.25619599728580095, 'loss.cls.type': 'focal', 'loss.cls.gamma': 2.639085438964967, 'loss.cls.alpha': 0.8977490255943661, 'loss.cls.balance': 'weighted'}. Best is trial 1951 with value: 0.7883870967741935.
EarlyStopping triggered at epoch 25 (patience=20)

================================================================================
TRIAL 2204 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 5.802438446253578e-06
  Dropout: 0.3568501366118284
================================================================================

[I 2025-10-29 17:42:12,254] Trial 2203 pruned. Pruned at step 6 with metric 0.5521

================================================================================
TRIAL 2205 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 1.4432807403774327e-05
  Dropout: 0.11497182110980435
================================================================================

[I 2025-10-29 17:56:24,152] Trial 2205 pruned. Pruned at step 11 with metric 0.6250
[I 2025-10-29 17:56:24,578] Trial 2206 pruned. Pruned: Large model with bsz=48, accum=4 (effective_batch=192) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2207 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 5.927222823650847e-06
  Dropout: 0.4502391907841826
================================================================================

[I 2025-10-29 17:56:29,686] Trial 2207 pruned. OOM: roberta-base bs=64 len=192
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2207 exceeded GPU memory:
  Model: roberta-base
  Batch size: 64 (effective: 512 with grad_accum=8)
  Max length: 192
  Error: CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 110.31 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this pro
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2208 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 48
  Learning rate: 2.0556323642582414e-05
  Dropout: 0.4522891739779757
================================================================================

[I 2025-10-29 18:10:05,405] Trial 2204 finished with value: 0.6916792000325189 and parameters: {'seed': 39469, 'model.name': 'bert-base-uncased', 'tok.max_length': 352, 'tok.doc_stride': 80, 'tok.use_fast': False, 'train.batch_size': 24, 'train.grad_accum': 6, 'optim.name': 'adamw', 'optim.lr': 5.802438446253578e-06, 'optim.weight_decay': 1.4446672045357019e-05, 'optim.beta1': 0.8200168053951042, 'optim.beta2': 0.9623329395510083, 'optim.eps': 2.6211733061481428e-08, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.1674300726525304, 'sched.poly_power': 0.9223003128339575, 'train.clip_grad': 0.7592241165442545, 'model.dropout': 0.3568501366118284, 'model.attn_dropout': 0.03306535374291681, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 6, 'optim.layerwise_lr_decay': 0.9137787804286389, 'head.pooling': 'max', 'head.layers': 3, 'head.hidden': 768, 'head.activation': 'relu', 'head.dropout': 0.47653526561871273, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.5760247604751823, 'loss.cls.alpha': 0.4755452516163373, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
[I 2025-10-29 18:10:05,872] Trial 2209 pruned. Pruned: Large model with bsz=24, accum=3 (effective_batch=72) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 51 (patience=20)

================================================================================
TRIAL 2210 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 1.0421221426041882e-05
  Dropout: 0.46914479446072505
================================================================================

[I 2025-10-29 18:12:09,373] Trial 2208 finished with value: 0.7036827551533433 and parameters: {'seed': 24846, 'model.name': 'roberta-base', 'tok.max_length': 128, 'tok.doc_stride': 32, 'tok.use_fast': False, 'train.batch_size': 48, 'train.grad_accum': 1, 'optim.name': 'adamw', 'optim.lr': 2.0556323642582414e-05, 'optim.weight_decay': 0.06418199188627352, 'optim.beta1': 0.9421634910792003, 'optim.beta2': 0.9774768494896969, 'optim.eps': 5.720058651344791e-08, 'sched.name': 'cosine', 'sched.warmup_ratio': 0.11931130400152802, 'train.clip_grad': 0.47234458217184555, 'model.dropout': 0.4522891739779757, 'model.attn_dropout': 0.2964665627236344, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 4, 'optim.layerwise_lr_decay': 0.8486911013636662, 'head.pooling': 'mean', 'head.layers': 2, 'head.hidden': 512, 'head.activation': 'silu', 'head.dropout': 0.4443217166038537, 'loss.cls.type': 'focal', 'loss.cls.gamma': 1.000739359493046, 'loss.cls.alpha': 0.2139951599278365, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
EarlyStopping triggered at epoch 32 (patience=20)

================================================================================
TRIAL 2211 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 24
  Learning rate: 9.578788061641487e-06
  Dropout: 0.12454627430808113
================================================================================

[I 2025-10-29 18:12:34,986] Trial 2211 pruned. OOM: microsoft/deberta-v3-base bs=24 len=256

[OOM] Trial 2211 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 24 (effective: 72 with grad_accum=3)
  Max length: 256
  Error: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 52.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2212 - Configuration:
  Model: {'name': 'xlm-roberta-base'}
  Batch size: 12
  Learning rate: 1.1036076110550956e-05
  Dropout: 0.19653478206225192
================================================================================

[I 2025-10-29 18:19:27,987] Trial 2210 pruned. Pruned at step 11 with metric 0.5582
[I 2025-10-29 18:19:28,426] Trial 2213 pruned. Pruned: Large model with bsz=32, accum=6 (effective_batch=192) likely causes OOM (24GB GPU limit)
[I 2025-10-29 18:19:28,848] Trial 2214 pruned. Pruned: Large model with bsz=24, accum=4 (effective_batch=96) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2215 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 6.364823980562507e-06
  Dropout: 0.41185225768530365
================================================================================

[I 2025-10-29 18:27:20,591] Trial 2215 pruned. Pruned at step 16 with metric 0.6540
[I 2025-10-29 18:27:21,050] Trial 2216 pruned. Pruned: Large model with bsz=24, accum=3 (effective_batch=72) likely causes OOM (24GB GPU limit)
[W 2025-10-29 18:27:21,432] The parameter `tok.doc_stride` in Trial#2217 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.

================================================================================
TRIAL 2217 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 8.498070532966853e-06
  Dropout: 0.26593607602888647
================================================================================

[I 2025-10-29 18:31:11,039] Trial 2212 pruned. Pruned at step 14 with metric 0.5584
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2218 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 32
  Learning rate: 8.687748609546286e-06
  Dropout: 0.004708865523431062
================================================================================

[I 2025-10-29 18:36:40,602] Trial 2217 pruned. Pruned at step 27 with metric 0.5968
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2219 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-large'}
  Batch size: 16
  Learning rate: 3.142820148604826e-05
  Dropout: 0.10449474748895167
================================================================================

[I 2025-10-29 18:36:47,070] Trial 2218 pruned. OOM: microsoft/deberta-v3-base bs=32 len=128
[I 2025-10-29 18:36:47,660] Trial 2220 pruned. Pruned: Large model with bsz=24, accum=3 (effective_batch=72) likely causes OOM (24GB GPU limit)
[I 2025-10-29 18:36:48,105] Trial 2221 pruned. Pruned: Large model with bsz=48, accum=2 (effective_batch=96) likely causes OOM (24GB GPU limit)
[I 2025-10-29 18:36:49,687] Trial 2219 pruned. OOM: microsoft/deberta-v3-large bs=16 len=128
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[I 2025-10-29 18:36:50,349] Trial 2223 pruned. Pruned: Large model with bsz=48, accum=2 (effective_batch=96) likely causes OOM (24GB GPU limit)

[OOM] Trial 2218 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 32 (effective: 32 with grad_accum=1)
  Max length: 128
  Error: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 96.56 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2222 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 1.586751591720282e-05
  Dropout: 0.17896101462521702
================================================================================


[OOM] Trial 2219 exceeded GPU memory:
  Model: microsoft/deberta-v3-large
  Batch size: 16 (effective: 48 with grad_accum=3)
  Max length: 128
  Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 62.56 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.

[I 2025-10-29 18:36:51,427] Trial 2201 pruned. OOM: bert-large-uncased bs=8 len=288
[W 2025-10-29 18:36:52,205] The parameter `tok.doc_stride` in Trial#2225 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.

[OOM] Trial 2201 exceeded GPU memory:
  Model: bert-large-uncased
  Batch size: 8 (effective: 64 with grad_accum=8)
  Max length: 288
  Error: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 42.56 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2224 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 16
  Learning rate: 1.044012747182759e-05
  Dropout: 0.3591635496104607
================================================================================


================================================================================
TRIAL 2225 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 48
  Learning rate: 2.484779472552224e-05
  Dropout: 0.3828183058769755
================================================================================

[I 2025-10-29 18:37:02,813] Trial 2222 pruned. OOM: roberta-base bs=24 len=320
[I 2025-10-29 18:37:02,986] Trial 2224 pruned. OOM: microsoft/deberta-v3-base bs=16 len=352
[W 2025-10-29 18:37:03,613] The parameter `tok.doc_stride` in Trial#2226 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.
[I 2025-10-29 18:37:03,969] Trial 2227 pruned. Pruned: Large model with bsz=48, accum=3 (effective_batch=144) likely causes OOM (24GB GPU limit)
[W 2025-10-29 18:37:04,351] The parameter `tok.doc_stride` in Trial#2228 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.

[OOM] Trial 2224 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 16 (effective: 16 with grad_accum=1)
  Max length: 352
  Error: CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 122.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proc
  Pruning trial to allow Optuna to learn memory constraints.


[OOM] Trial 2222 exceeded GPU memory:
  Model: roberta-base
  Batch size: 24 (effective: 96 with grad_accum=4)
  Max length: 320
  Error: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 42.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2226 - Configuration:
  Model: {'name': 'xlm-roberta-base'}
  Batch size: 8
  Learning rate: 1.6448144042366436e-05
  Dropout: 0.46127654587203404
================================================================================


================================================================================
TRIAL 2228 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 48
  Learning rate: 1.3125208885768797e-05
  Dropout: 0.0876248121374868
================================================================================

[I 2025-10-29 18:39:44,387] Trial 2228 pruned. Pruned at step 13 with metric 0.6125
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2229 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 1.1352764340740942e-05
  Dropout: 0.016643910059973233
================================================================================

[I 2025-10-29 18:47:19,897] Trial 2229 pruned. Pruned at step 27 with metric 0.6299
[I 2025-10-29 18:47:20,337] Trial 2230 pruned. Pruned: Large model with bsz=12, accum=8 (effective_batch=96) likely causes OOM (24GB GPU limit)
[I 2025-10-29 18:47:20,759] Trial 2231 pruned. Pruned: Large model with bsz=48, accum=4 (effective_batch=192) likely causes OOM (24GB GPU limit)
[I 2025-10-29 18:47:21,214] Trial 2232 pruned. Pruned: Large model with bsz=24, accum=3 (effective_batch=72) likely causes OOM (24GB GPU limit)
[I 2025-10-29 18:47:21,637] Trial 2233 pruned. Pruned: Large model with bsz=32, accum=6 (effective_batch=192) likely causes OOM (24GB GPU limit)
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2234 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 12
  Learning rate: 4.884543434442975e-05
  Dropout: 0.04667099114211963
================================================================================

[I 2025-10-29 18:47:34,542] Trial 2234 pruned. OOM: microsoft/deberta-v3-base bs=12 len=160
[I 2025-10-29 18:47:35,728] Trial 2226 pruned. OOM: xlm-roberta-base bs=8 len=128
[I 2025-10-29 18:47:36,530] Trial 2236 pruned. Pruned: Large model with bsz=64, accum=2 (effective_batch=128) likely causes OOM (24GB GPU limit)

[OOM] Trial 2234 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 12 (effective: 72 with grad_accum=6)
  Max length: 160
  Error: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 54.19 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2235 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 32
  Learning rate: 1.7166164031233886e-05
  Dropout: 0.07611552282205246
================================================================================


[OOM] Trial 2226 exceeded GPU memory:
  Model: xlm-roberta-base
  Batch size: 8 (effective: 8 with grad_accum=1)
  Max length: 128
  Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 54.19 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.

Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2237 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 7.766555775134327e-06
  Dropout: 0.2982729514861379
================================================================================

[I 2025-10-29 18:51:06,884] Trial 2225 pruned. Pruned at step 10 with metric 0.6364

================================================================================
TRIAL 2238 - Configuration:
  Model: {'name': 'bert-large-uncased'}
  Batch size: 12
  Learning rate: 3.765104039425332e-05
  Dropout: 0.013219428190398078
================================================================================

[I 2025-10-29 18:57:58,167] Trial 2235 pruned. Pruned at step 27 with metric 0.6254
[W 2025-10-29 18:57:58,582] The parameter `tok.doc_stride` in Trial#2239 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2239 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 48
  Learning rate: 1.0210911814146093e-05
  Dropout: 0.09519447256214672
================================================================================

[I 2025-10-29 19:04:51,150] Trial 2239 pruned. Pruned at step 27 with metric 0.6338

================================================================================
TRIAL 2240 - Configuration:
  Model: {'name': 'xlm-roberta-base'}
  Batch size: 8
  Learning rate: 1.1258308708040625e-05
  Dropout: 0.372176936798399
================================================================================

[I 2025-10-29 19:06:56,102] Trial 2237 pruned. Pruned at step 14 with metric 0.5827

================================================================================
TRIAL 2241 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 32
  Learning rate: 3.015847880216827e-05
  Dropout: 0.10931773249687149
================================================================================

[I 2025-10-29 19:10:44,211] Trial 2241 pruned. Pruned at step 8 with metric 0.5958
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2242 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 0.00011384840809613203
  Dropout: 0.12361383685052338
================================================================================

[I 2025-10-29 19:13:09,560] Trial 2240 pruned. Pruned at step 8 with metric 0.5531
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2243 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 2.348422347050026e-05
  Dropout: 0.22480646858154177
================================================================================

[I 2025-10-29 19:16:31,402] Trial 2243 pruned. Pruned at step 6 with metric 0.5769
[W 2025-10-29 19:16:31,808] The parameter `tok.doc_stride` in Trial#2244 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2244 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 12
  Learning rate: 2.9392381014707983e-05
  Dropout: 0.20306459233226185
================================================================================

[I 2025-10-29 19:25:30,765] Trial 2242 finished with value: 0.43989071038251365 and parameters: {'seed': 60519, 'model.name': 'roberta-base', 'tok.max_length': 160, 'tok.doc_stride': 64, 'tok.use_fast': False, 'train.batch_size': 16, 'train.grad_accum': 3, 'optim.name': 'adamw', 'optim.lr': 0.00011384840809613203, 'optim.weight_decay': 0.003663048403255142, 'optim.beta1': 0.8776579945909705, 'optim.beta2': 0.9580811394691886, 'optim.eps': 3.2011151297123117e-07, 'sched.name': 'cosine', 'sched.warmup_ratio': 0.19097483566221107, 'train.clip_grad': 0.9268106553966104, 'model.dropout': 0.12361383685052338, 'model.attn_dropout': 0.19874166641360957, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.8883919094568282, 'head.pooling': 'mean', 'head.layers': 3, 'head.hidden': 768, 'head.activation': 'gelu', 'head.dropout': 0.21832867135166323, 'loss.cls.type': 'ce_label_smooth', 'loss.cls.label_smoothing': 0.14590862841956695, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2245 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 8
  Learning rate: 6.090580241920597e-06
  Dropout: 0.05617574161096546
================================================================================

[I 2025-10-29 19:28:37,738] Trial 2244 pruned. Pruned at step 27 with metric 0.5713
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2246 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 1.0668826008966953e-05
  Dropout: 0.29298553731677174
================================================================================

[I 2025-10-29 19:33:37,932] Trial 2238 pruned. Pruned at step 10 with metric 0.5769
[I 2025-10-29 19:33:38,384] Trial 2247 pruned. Pruned: Large model with bsz=32, accum=3 (effective_batch=96) likely causes OOM (24GB GPU limit)

================================================================================
TRIAL 2248 - Configuration:
  Model: {'name': 'xlm-roberta-base'}
  Batch size: 8
  Learning rate: 9.973088893484971e-06
  Dropout: 0.4404062914451796
================================================================================

[I 2025-10-29 19:33:59,615] Trial 2246 pruned. Pruned at step 9 with metric 0.6462

================================================================================
TRIAL 2249 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 48
  Learning rate: 8.126557183536343e-06
  Dropout: 0.12385644546738309
================================================================================

[I 2025-10-29 19:37:15,416] Trial 2249 pruned. Pruned at step 15 with metric 0.5695
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2250 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 9.270770031015014e-05
  Dropout: 0.07258754501810039
================================================================================

[I 2025-10-29 19:46:04,916] Trial 2250 finished with value: 0.4533333333333333 and parameters: {'seed': 44186, 'model.name': 'roberta-base', 'tok.max_length': 256, 'tok.doc_stride': 32, 'tok.use_fast': False, 'train.batch_size': 16, 'train.grad_accum': 3, 'optim.name': 'adamw', 'optim.lr': 9.270770031015014e-05, 'optim.weight_decay': 0.002123942481807763, 'optim.beta1': 0.9474656535065769, 'optim.beta2': 0.9799691391593129, 'optim.eps': 3.3052770158025025e-09, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.09711534946390692, 'sched.poly_power': 0.5003676310202296, 'train.clip_grad': 1.2943763937458532, 'model.dropout': 0.07258754501810039, 'model.attn_dropout': 0.245587695869679, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 1, 'optim.layerwise_lr_decay': 0.8151747870067688, 'head.pooling': 'mean', 'head.layers': 4, 'head.hidden': 768, 'head.activation': 'relu', 'head.dropout': 0.3680571399422439, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.771551950209582, 'loss.cls.alpha': 0.8695993711901797, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
[I 2025-10-29 19:46:05,369] Trial 2251 pruned. Pruned: Large model with bsz=24, accum=1 (effective_batch=24) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2252 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 1.1304720880659393e-05
  Dropout: 0.09967765978695445
================================================================================

[I 2025-10-29 19:51:37,790] Trial 2245 pruned. Pruned at step 18 with metric 0.5725
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2253 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 16
  Learning rate: 5.814591890240021e-06
  Dropout: 0.22156441042620392
================================================================================

[I 2025-10-29 20:00:51,549] Trial 2252 finished with value: 0.7025191548641746 and parameters: {'seed': 60101, 'model.name': 'roberta-base', 'tok.max_length': 160, 'tok.doc_stride': 48, 'tok.use_fast': True, 'train.batch_size': 24, 'train.grad_accum': 3, 'optim.name': 'adamw', 'optim.lr': 1.1304720880659393e-05, 'optim.weight_decay': 0.016830262814968723, 'optim.beta1': 0.8886622613183386, 'optim.beta2': 0.9942321646706916, 'optim.eps': 5.631517327924001e-07, 'sched.name': 'cosine', 'sched.warmup_ratio': 0.09685819087311007, 'train.clip_grad': 0.8538258404602126, 'model.dropout': 0.09967765978695445, 'model.attn_dropout': 0.13044437137140913, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 4, 'optim.layerwise_lr_decay': 0.9280621992505583, 'head.pooling': 'max', 'head.layers': 2, 'head.hidden': 768, 'head.activation': 'silu', 'head.dropout': 0.05024325811907565, 'loss.cls.type': 'ce', 'loss.cls.label_smoothing': 0.1134561105084018, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 46 (patience=20)

================================================================================
TRIAL 2254 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 3.1412793766100554e-05
  Dropout: 0.3803541265254082
================================================================================

[I 2025-10-29 20:00:58,556] Trial 2253 pruned. OOM: microsoft/deberta-v3-base bs=16 len=384
[I 2025-10-29 20:00:58,783] Trial 2254 pruned. OOM: roberta-base bs=24 len=288
[I 2025-10-29 20:00:59,284] Trial 2256 pruned. Pruned: Large model with bsz=64, accum=3 (effective_batch=192) likely causes OOM (24GB GPU limit)
[I 2025-10-29 20:00:59,542] Trial 2255 pruned. Pruned: Large model with bsz=24, accum=6 (effective_batch=144) likely causes OOM (24GB GPU limit)
[I 2025-10-29 20:00:59,674] Trial 2248 pruned. OOM: xlm-roberta-base bs=8 len=192
[I 2025-10-29 20:01:01,029] Trial 2257 pruned. Pruned: Large model with bsz=24, accum=4 (effective_batch=96) likely causes OOM (24GB GPU limit)
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2253 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 16 (effective: 128 with grad_accum=8)
  Max length: 384
  Error: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 90.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


[OOM] Trial 2254 exceeded GPU memory:
  Model: roberta-base
  Batch size: 24 (effective: 48 with grad_accum=2)
  Max length: 288
  Error: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 90.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


[OOM] Trial 2248 exceeded GPU memory:
  Model: xlm-roberta-base
  Batch size: 8 (effective: 8 with grad_accum=1)
  Max length: 192
  Error: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 70.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2258 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-large'}
  Batch size: 8
  Learning rate: 5.901469750921969e-05
  Dropout: 0.14707554613968288
================================================================================


================================================================================
TRIAL 2259 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 16
  Learning rate: 1.975895599122832e-05
  Dropout: 0.10980933286496074
================================================================================


================================================================================
TRIAL 2260 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 1.0696051636916669e-05
  Dropout: 0.3268492515935634
================================================================================

[I 2025-10-29 20:01:12,777] Trial 2260 pruned. OOM: roberta-base bs=24 len=288
[I 2025-10-29 20:01:12,943] Trial 2259 pruned. OOM: microsoft/deberta-v3-base bs=16 len=256
[I 2025-10-29 20:01:14,391] Trial 2258 pruned. OOM: microsoft/deberta-v3-large bs=8 len=352
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[I 2025-10-29 20:01:15,133] Trial 2263 pruned. Pruned: Large model with bsz=32, accum=6 (effective_batch=192) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2259 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 16 (effective: 128 with grad_accum=8)
  Max length: 256
  Error: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 40.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


[OOM] Trial 2260 exceeded GPU memory:
  Model: roberta-base
  Batch size: 24 (effective: 72 with grad_accum=3)
  Max length: 288
  Error: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 40.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2262 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 1.497998352859619e-05
  Dropout: 0.12813960677633315
================================================================================


================================================================================
TRIAL 2261 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 3.060026990114137e-05
  Dropout: 0.07157279540450516
================================================================================


[OOM] Trial 2258 exceeded GPU memory:
  Model: microsoft/deberta-v3-large
  Batch size: 8 (effective: 64 with grad_accum=8)
  Max length: 352
  Error: CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 40.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.

Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2264 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 1.5795359446575955e-05
  Dropout: 0.08175739339756874
================================================================================

[I 2025-10-29 20:06:25,543] Trial 2262 pruned. Pruned at step 10 with metric 0.5742
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2265 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 12
  Learning rate: 1.0694974012463167e-05
  Dropout: 0.042274638357201855
================================================================================

[I 2025-10-29 20:14:37,268] Trial 2264 pruned. Pruned at step 11 with metric 0.6027

================================================================================
TRIAL 2266 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 5.475756669674816e-06
  Dropout: 0.18202094991422607
================================================================================

[I 2025-10-29 20:38:35,551] Trial 2266 finished with value: 0.6450020264544416 and parameters: {'seed': 59068, 'model.name': 'bert-base-uncased', 'tok.max_length': 192, 'tok.doc_stride': 48, 'tok.use_fast': False, 'train.batch_size': 24, 'train.grad_accum': 8, 'optim.name': 'adamw', 'optim.lr': 5.475756669674816e-06, 'optim.weight_decay': 5.174693958540985e-06, 'optim.beta1': 0.8339494264087881, 'optim.beta2': 0.992888754038267, 'optim.eps': 9.294056088348898e-08, 'sched.name': 'one_cycle', 'sched.warmup_ratio': 0.1603347958667039, 'sched.cosine_cycles': 2, 'train.clip_grad': 0.5834933211094424, 'model.dropout': 0.18202094991422607, 'model.attn_dropout': 0.28544782757565074, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 2, 'optim.layerwise_lr_decay': 0.8302706449062148, 'head.pooling': 'max', 'head.layers': 4, 'head.hidden': 1024, 'head.activation': 'relu', 'head.dropout': 0.04301494146167281, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.677364175197528, 'loss.cls.alpha': 0.529357204586551, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 26 (patience=20)

================================================================================
TRIAL 2267 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 9.850229763783619e-06
  Dropout: 0.24995230487159809
================================================================================

[I 2025-10-29 21:08:21,898] Trial 2267 finished with value: 0.7189330674311354 and parameters: {'seed': 55922, 'model.name': 'roberta-base', 'tok.max_length': 256, 'tok.doc_stride': 80, 'tok.use_fast': True, 'train.batch_size': 24, 'train.grad_accum': 6, 'optim.name': 'adamw', 'optim.lr': 9.850229763783619e-06, 'optim.weight_decay': 0.003779557080831268, 'optim.beta1': 0.8701184562591066, 'optim.beta2': 0.9776578364307853, 'optim.eps': 3.0957958035656405e-09, 'sched.name': 'linear', 'sched.warmup_ratio': 0.18539893034171023, 'train.clip_grad': 0.5307909616384938, 'model.dropout': 0.24995230487159809, 'model.attn_dropout': 0.07111599752159413, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 4, 'optim.layerwise_lr_decay': 0.9409546676652596, 'head.pooling': 'cls', 'head.layers': 4, 'head.hidden': 1536, 'head.activation': 'relu', 'head.dropout': 0.14541794061096525, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.886747672751452, 'loss.cls.alpha': 0.43073521728284836, 'loss.cls.balance': 'weighted'}. Best is trial 1951 with value: 0.7883870967741935.
EarlyStopping triggered at epoch 30 (patience=20)

================================================================================
TRIAL 2268 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 2.6716499778434285e-05
  Dropout: 0.07128766790487331
================================================================================

[I 2025-10-29 21:22:51,325] Trial 2268 pruned. Pruned at step 14 with metric 0.6250
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2269 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 4.3183759736621714e-05
  Dropout: 0.05586720772648192
================================================================================

[I 2025-10-29 21:31:39,701] Trial 2265 finished with value: 0.7359848484848485 and parameters: {'seed': 49396, 'model.name': 'roberta-large', 'tok.max_length': 352, 'tok.doc_stride': 48, 'tok.use_fast': True, 'train.batch_size': 12, 'train.grad_accum': 2, 'optim.name': 'adamw', 'optim.lr': 1.0694974012463167e-05, 'optim.weight_decay': 0.1105861588723498, 'optim.beta1': 0.9456730910127654, 'optim.beta2': 0.9694327340554303, 'optim.eps': 3.5691800180025354e-08, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.15030193210981954, 'sched.poly_power': 0.6262519312108106, 'train.clip_grad': 1.087374958803795, 'model.dropout': 0.042274638357201855, 'model.attn_dropout': 0.20707453451567026, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 3, 'optim.layerwise_lr_decay': 0.859303498169011, 'head.pooling': 'cls', 'head.layers': 2, 'head.hidden': 512, 'head.activation': 'gelu', 'head.dropout': 0.3129778470190652, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.778747565316511, 'loss.cls.alpha': 0.49144485160044843, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 43 (patience=20)

================================================================================
TRIAL 2270 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 12
  Learning rate: 1.6284969119445526e-05
  Dropout: 0.06100064175160853
================================================================================

[I 2025-10-29 21:48:44,110] Trial 2269 pruned. Pruned at step 27 with metric 0.6159
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2271 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 12
  Learning rate: 1.9511820721945256e-05
  Dropout: 0.31042936688171585
================================================================================

[I 2025-10-29 22:08:44,524] Trial 2261 pruned. Pruned at step 27 with metric 0.6165
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2272 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 12
  Learning rate: 2.8414603965836388e-05
  Dropout: 0.08787403858188392
================================================================================

[I 2025-10-29 22:08:55,485] Trial 2270 pruned. OOM: roberta-large bs=12 len=352
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2270 exceeded GPU memory:
  Model: roberta-large
  Batch size: 12 (effective: 24 with grad_accum=2)
  Max length: 352
  Error: CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 50.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2273 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 12
  Learning rate: 1.036438781126513e-05
  Dropout: 0.043990765438206625
================================================================================

[I 2025-10-29 22:09:01,892] Trial 2273 pruned. OOM: roberta-large bs=12 len=352
[I 2025-10-29 22:09:02,064] Trial 2272 pruned. OOM: roberta-large bs=12 len=288
[I 2025-10-29 22:09:03,286] Trial 2271 pruned. OOM: roberta-base bs=12 len=128
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

[OOM] Trial 2272 exceeded GPU memory:
  Model: roberta-large
  Batch size: 12 (effective: 24 with grad_accum=2)
  Max length: 288
  Error: CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 90.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


[OOM] Trial 2273 exceeded GPU memory:
  Model: roberta-large
  Batch size: 12 (effective: 12 with grad_accum=1)
  Max length: 352
  Error: CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 110.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proc
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2275 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 6.9807854333426275e-06
  Dropout: 0.28985687367859053
================================================================================


[OOM] Trial 2271 exceeded GPU memory:
  Model: roberta-base
  Batch size: 12 (effective: 48 with grad_accum=4)
  Max length: 128
  Error: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 48.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2274 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 64
  Learning rate: 1.4881094871381262e-05
  Dropout: 0.07839972939991757
================================================================================


================================================================================
TRIAL 2276 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 12
  Learning rate: 2.8930995950086737e-05
  Dropout: 0.16011841733982873
================================================================================

Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[I 2025-10-29 22:09:09,443] Trial 2274 pruned. OOM: microsoft/deberta-v3-base bs=64 len=288
[I 2025-10-29 22:09:10,540] Trial 2275 pruned. OOM: bert-base-uncased bs=24 len=128
[I 2025-10-29 22:09:10,999] Trial 2278 pruned. Pruned: Large model with bsz=24, accum=2 (effective_batch=48) likely causes OOM (24GB GPU limit)
[I 2025-10-29 22:09:11,505] Trial 2279 pruned. Pruned: Large model with bsz=64, accum=2 (effective_batch=128) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2274 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 64 (effective: 512 with grad_accum=8)
  Max length: 288
  Error: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 40.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


[OOM] Trial 2275 exceeded GPU memory:
  Model: bert-base-uncased
  Batch size: 24 (effective: 144 with grad_accum=6)
  Max length: 128
  Error: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 40.81 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2277 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 8
  Learning rate: 9.156038923913948e-06
  Dropout: 0.40559699135513494
================================================================================


================================================================================
TRIAL 2280 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 4.135415143552843e-05
  Dropout: 0.02384069478591927
================================================================================

Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[I 2025-10-29 22:09:54,747] Trial 2276 pruned. OOM: roberta-large bs=12 len=384

[OOM] Trial 2276 exceeded GPU memory:
  Model: roberta-large
  Batch size: 12 (effective: 24 with grad_accum=2)
  Max length: 384
  Error: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 70.00 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2281 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 12
  Learning rate: 6.058699830814721e-05
  Dropout: 0.004590416589988008
================================================================================

[I 2025-10-29 22:18:59,954] Trial 2280 pruned. Pruned at step 16 with metric 0.4414
[I 2025-10-29 22:19:00,407] Trial 2282 pruned. Pruned: Large model with bsz=12, accum=8 (effective_batch=96) likely causes OOM (24GB GPU limit)

================================================================================
TRIAL 2283 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 32
  Learning rate: 2.0084486495533748e-05
  Dropout: 0.12391318041973012
================================================================================

[I 2025-10-29 22:23:13,705] Trial 2283 pruned. Pruned at step 13 with metric 0.6165
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2284 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 12
  Learning rate: 1.581429804299174e-05
  Dropout: 0.23897416275498046
================================================================================

[I 2025-10-29 22:27:05,853] Trial 2281 pruned. OOM: bert-base-uncased bs=12 len=384
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2281 exceeded GPU memory:
  Model: bert-base-uncased
  Batch size: 12 (effective: 24 with grad_accum=2)
  Max length: 384
  Error: CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 97.94 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2285 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 1.6258218452612695e-05
  Dropout: 0.05458197461325617
================================================================================

[I 2025-10-29 22:27:09,736] Trial 2285 pruned. OOM: roberta-base bs=64 len=256
[I 2025-10-29 22:27:11,308] Trial 2284 pruned. OOM: roberta-large bs=12 len=320
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
[I 2025-10-29 22:27:12,556] Trial 2287 pruned. Pruned: Large model with bsz=48, accum=6 (effective_batch=288) likely causes OOM (24GB GPU limit)

[OOM] Trial 2285 exceeded GPU memory:
  Model: roberta-base
  Batch size: 64 (effective: 192 with grad_accum=3)
  Max length: 256
  Error: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 49.94 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2286 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 24
  Learning rate: 9.352269958275025e-06
  Dropout: 0.47767464893766187
================================================================================


[OOM] Trial 2284 exceeded GPU memory:
  Model: roberta-large
  Batch size: 12 (effective: 12 with grad_accum=1)
  Max length: 320
  Error: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 49.94 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2288 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 12
  Learning rate: 5.974455108842971e-06
  Dropout: 0.1378646198729805
================================================================================

Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[I 2025-10-29 22:27:17,587] Trial 2286 pruned. OOM: microsoft/deberta-v3-base bs=24 len=288
[W 2025-10-29 22:27:18,180] The parameter `tok.doc_stride` in Trial#2289 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.
[I 2025-10-29 22:27:19,473] Trial 2288 pruned. OOM: roberta-large bs=12 len=384
[I 2025-10-29 22:27:19,964] Trial 2290 pruned. Pruned: Large model with bsz=48, accum=6 (effective_batch=288) likely causes OOM (24GB GPU limit)
[I 2025-10-29 22:27:20,391] Trial 2291 pruned. Pruned: Large model with bsz=32, accum=4 (effective_batch=128) likely causes OOM (24GB GPU limit)

[OOM] Trial 2286 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 24 (effective: 24 with grad_accum=1)
  Max length: 288
  Error: CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 133.94 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this pro
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2289 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 12
  Learning rate: 1.088582726616737e-05
  Dropout: 0.13348167007001094
================================================================================


[OOM] Trial 2288 exceeded GPU memory:
  Model: roberta-large
  Batch size: 12 (effective: 24 with grad_accum=2)
  Max length: 384
  Error: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 65.94 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.

[I 2025-10-29 22:27:21,698] Trial 2277 pruned. OOM: roberta-large bs=8 len=352
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2277 exceeded GPU memory:
  Model: roberta-large
  Batch size: 8 (effective: 16 with grad_accum=2)
  Max length: 352
  Error: CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 173.94 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this pro
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2292 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 12
  Learning rate: 1.6317020323284542e-05
  Dropout: 0.11030638914246751
================================================================================


================================================================================
TRIAL 2293 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 16
  Learning rate: 5.994781885820872e-06
  Dropout: 0.38131887381943935
================================================================================

[I 2025-10-29 23:00:15,076] Trial 2292 finished with value: 0.45478723404255317 and parameters: {'seed': 26608, 'model.name': 'roberta-large', 'tok.max_length': 320, 'tok.doc_stride': 48, 'tok.use_fast': True, 'train.batch_size': 12, 'train.grad_accum': 2, 'optim.name': 'adamw', 'optim.lr': 1.6317020323284542e-05, 'optim.weight_decay': 0.1131614676212919, 'optim.beta1': 0.8873665493977452, 'optim.beta2': 0.9700485410118499, 'optim.eps': 3.5980111079464727e-09, 'sched.name': 'cosine', 'sched.warmup_ratio': 0.17481998188483733, 'train.clip_grad': 1.063651444143772, 'model.dropout': 0.11030638914246751, 'model.attn_dropout': 0.18923828109636973, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 4, 'optim.layerwise_lr_decay': 0.846388934575392, 'head.pooling': 'cls', 'head.layers': 3, 'head.hidden': 512, 'head.activation': 'gelu', 'head.dropout': 0.3303565697326486, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.038457876357404, 'loss.cls.alpha': 0.5446682703203745, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2294 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 64
  Learning rate: 5.4681401701470145e-06
  Dropout: 0.473243821322961
================================================================================

[I 2025-10-29 23:07:39,280] Trial 2294 pruned. Pruned at step 31 with metric 0.6462
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2295 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 1.3937424313739781e-05
  Dropout: 0.08409644086754758
================================================================================

[I 2025-10-29 23:16:37,299] Trial 2295 finished with value: 0.7256109220237867 and parameters: {'seed': 60775, 'model.name': 'roberta-base', 'tok.max_length': 224, 'tok.doc_stride': 48, 'tok.use_fast': False, 'train.batch_size': 24, 'train.grad_accum': 4, 'optim.name': 'adamw', 'optim.lr': 1.3937424313739781e-05, 'optim.weight_decay': 0.00825442475121457, 'optim.beta1': 0.9269840203490366, 'optim.beta2': 0.9758635115896421, 'optim.eps': 6.398174260089528e-08, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.0837443776194257, 'sched.poly_power': 0.50598544509521, 'train.clip_grad': 0.9096268274992665, 'model.dropout': 0.08409644086754758, 'model.attn_dropout': 0.17938663051628362, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 4, 'optim.layerwise_lr_decay': 0.9033480504488538, 'head.pooling': 'mean', 'head.layers': 2, 'head.hidden': 512, 'head.activation': 'gelu', 'head.dropout': 0.44548194686216824, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.403281952831543, 'loss.cls.alpha': 0.5984340125427906, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
[I 2025-10-29 23:16:37,742] Trial 2296 pruned. Pruned: Large model with bsz=48, accum=1 (effective_batch=48) likely causes OOM (24GB GPU limit)
[I 2025-10-29 23:16:38,180] Trial 2297 pruned. Pruned: Large model with bsz=64, accum=3 (effective_batch=192) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 23 (patience=20)

================================================================================
TRIAL 2298 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 12
  Learning rate: 1.2834121674025535e-05
  Dropout: 0.2230182443275228
================================================================================

[I 2025-10-29 23:55:00,324] Trial 2298 finished with value: 0.45478723404255317 and parameters: {'seed': 44792, 'model.name': 'roberta-large', 'tok.max_length': 384, 'tok.doc_stride': 32, 'tok.use_fast': True, 'train.batch_size': 12, 'train.grad_accum': 2, 'optim.name': 'adamw', 'optim.lr': 1.2834121674025535e-05, 'optim.weight_decay': 0.029243428275779273, 'optim.beta1': 0.9092839011488252, 'optim.beta2': 0.9644070667812842, 'optim.eps': 7.694088171741051e-08, 'sched.name': 'one_cycle', 'sched.warmup_ratio': 0.11887793692002112, 'sched.cosine_cycles': 1, 'train.clip_grad': 1.298048742277923, 'model.dropout': 0.2230182443275228, 'model.attn_dropout': 0.2368264847849609, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.8815563125725516, 'head.pooling': 'cls', 'head.layers': 3, 'head.hidden': 768, 'head.activation': 'silu', 'head.dropout': 0.43933927660952543, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.591786901734408, 'loss.cls.alpha': 0.6800910890301849, 'loss.cls.balance': 'weighted'}. Best is trial 1951 with value: 0.7883870967741935.
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2299 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 32
  Learning rate: 2.9314966288240904e-05
  Dropout: 0.05087180516622569
================================================================================

[I 2025-10-29 23:55:05,758] Trial 2299 pruned. OOM: microsoft/deberta-v3-base bs=32 len=288
[I 2025-10-29 23:55:07,278] Trial 2289 pruned. OOM: bert-base-uncased bs=12 len=128
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2299 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 32 (effective: 128 with grad_accum=4)
  Max length: 288
  Error: CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 48.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proc
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2300 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 32
  Learning rate: 7.05819950837373e-06
  Dropout: 0.49021047723708694
================================================================================


[OOM] Trial 2289 exceeded GPU memory:
  Model: bert-base-uncased
  Batch size: 12 (effective: 72 with grad_accum=6)
  Max length: 128
  Error: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 48.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2301 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-large'}
  Batch size: 12
  Learning rate: 3.0474362622927142e-05
  Dropout: 0.0428664966996217
================================================================================

[I 2025-10-29 23:55:14,856] Trial 2301 pruned. OOM: microsoft/deberta-v3-large bs=12 len=320

[OOM] Trial 2301 exceeded GPU memory:
  Model: microsoft/deberta-v3-large
  Batch size: 12 (effective: 24 with grad_accum=2)
  Max length: 320
  Error: CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 48.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2302 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 12
  Learning rate: 1.4363186839690024e-05
  Dropout: 0.09424697926040648
================================================================================

[I 2025-10-29 23:59:26,174] Trial 2293 finished with value: 0.6699447369566164 and parameters: {'seed': 51646, 'model.name': 'bert-base-uncased', 'tok.max_length': 320, 'tok.doc_stride': 64, 'tok.use_fast': True, 'train.batch_size': 16, 'train.grad_accum': 2, 'optim.name': 'adamw', 'optim.lr': 5.994781885820872e-06, 'optim.weight_decay': 6.494427866012867e-05, 'optim.beta1': 0.8212609277142673, 'optim.beta2': 0.9775272562446863, 'optim.eps': 6.312210943590647e-09, 'sched.name': 'cosine_restart', 'sched.warmup_ratio': 0.19553443468275533, 'sched.cosine_cycles': 2, 'train.clip_grad': 0.011406130307132667, 'model.dropout': 0.38131887381943935, 'model.attn_dropout': 0.11640967850601662, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 6, 'optim.layerwise_lr_decay': 0.8621205643634777, 'head.pooling': 'max', 'head.layers': 3, 'head.hidden': 768, 'head.activation': 'relu', 'head.dropout': 0.4285601400057404, 'loss.cls.type': 'ce', 'loss.cls.label_smoothing': 0.11395976237799016, 'loss.cls.balance': 'weighted'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 25 (patience=20)

================================================================================
TRIAL 2303 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 12
  Learning rate: 3.776313728633954e-05
  Dropout: 0.45805157742041147
================================================================================

[I 2025-10-30 00:02:57,405] Trial 2300 pruned. Pruned at step 27 with metric 0.6067

================================================================================
TRIAL 2304 - Configuration:
  Model: {'name': 'xlm-roberta-base'}
  Batch size: 8
  Learning rate: 8.136474265724671e-05
  Dropout: 0.0689079439197455
================================================================================

[I 2025-10-30 00:20:38,424] Trial 2304 finished with value: 0.44594594594594594 and parameters: {'seed': 57425, 'model.name': 'xlm-roberta-base', 'tok.max_length': 160, 'tok.doc_stride': 64, 'tok.use_fast': True, 'train.batch_size': 8, 'train.grad_accum': 8, 'optim.name': 'adamw', 'optim.lr': 8.136474265724671e-05, 'optim.weight_decay': 0.05409887392936917, 'optim.beta1': 0.839970432633226, 'optim.beta2': 0.9634340682500847, 'optim.eps': 3.5135356341042256e-08, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.16094684006651586, 'sched.poly_power': 1.993526343288059, 'train.clip_grad': 0.3838243040552214, 'model.dropout': 0.0689079439197455, 'model.attn_dropout': 0.25552524467660054, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.8814648147624962, 'head.pooling': 'max', 'head.layers': 3, 'head.hidden': 512, 'head.activation': 'gelu', 'head.dropout': 0.2486195336132715, 'loss.cls.type': 'ce_label_smooth', 'loss.cls.label_smoothing': 0.1320791533647086, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
[I 2025-10-30 00:20:38,861] Trial 2305 pruned. Pruned: Large model with bsz=32, accum=8 (effective_batch=256) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2306 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 12
  Learning rate: 9.06608456982268e-06
  Dropout: 0.37065214207106023
================================================================================

[I 2025-10-30 00:24:13,615] Trial 2302 finished with value: 0.7049242424242425 and parameters: {'seed': 44765, 'model.name': 'bert-base-uncased', 'tok.max_length': 288, 'tok.doc_stride': 48, 'tok.use_fast': True, 'train.batch_size': 12, 'train.grad_accum': 2, 'optim.name': 'adamw', 'optim.lr': 1.4363186839690024e-05, 'optim.weight_decay': 0.06263600323843756, 'optim.beta1': 0.876838518045499, 'optim.beta2': 0.9874454568515761, 'optim.eps': 2.3377805954091505e-07, 'sched.name': 'cosine', 'sched.warmup_ratio': 0.17262149362280246, 'train.clip_grad': 0.08963040646603476, 'model.dropout': 0.09424697926040648, 'model.attn_dropout': 0.15486950395304128, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 3, 'optim.layerwise_lr_decay': 0.8371227691019809, 'head.pooling': 'max', 'head.layers': 4, 'head.hidden': 1536, 'head.activation': 'relu', 'head.dropout': 0.07823926747168608, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.598450429333223, 'loss.cls.alpha': 0.4482324171324663, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
EarlyStopping triggered at epoch 25 (patience=20)

================================================================================
TRIAL 2307 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 16
  Learning rate: 5.504799198616967e-06
  Dropout: 0.395023581529415
================================================================================

[I 2025-10-30 00:38:32,916] Trial 2303 pruned. Pruned at step 11 with metric 0.6297

================================================================================
TRIAL 2308 - Configuration:
  Model: {'name': 'xlm-roberta-base'}
  Batch size: 12
  Learning rate: 1.008827011173423e-05
  Dropout: 0.020381617554272393
================================================================================

[I 2025-10-30 00:44:34,532] Trial 2307 pruned. Pruned at step 13 with metric 0.4972
[W 2025-10-30 00:44:34,980] The parameter `tok.doc_stride` in Trial#2309 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.

================================================================================
TRIAL 2309 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 1.8353194652916634e-05
  Dropout: 0.10427972428329108
================================================================================

[I 2025-10-30 00:51:06,080] Trial 2306 pruned. Pruned at step 14 with metric 0.6434

================================================================================
TRIAL 2310 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 8.0246033746543e-06
  Dropout: 0.34944471721770964
================================================================================

[I 2025-10-30 00:58:46,795] Trial 2310 pruned. Pruned at step 20 with metric 0.6042
[I 2025-10-30 00:58:47,245] Trial 2311 pruned. Pruned: Large model with bsz=48, accum=3 (effective_batch=144) likely causes OOM (24GB GPU limit)
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2312 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-large'}
  Batch size: 8
  Learning rate: 1.7491355221494752e-05
  Dropout: 0.36219363556513573
================================================================================

[I 2025-10-30 00:58:54,182] Trial 2309 pruned. OOM: bert-base-uncased bs=24 len=160
[I 2025-10-30 00:58:55,133] Trial 2312 pruned. OOM: microsoft/deberta-v3-large bs=8 len=352
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

[OOM] Trial 2309 exceeded GPU memory:
  Model: bert-base-uncased
  Batch size: 24 (effective: 96 with grad_accum=4)
  Max length: 160
  Error: CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 42.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


[OOM] Trial 2312 exceeded GPU memory:
  Model: microsoft/deberta-v3-large
  Batch size: 8 (effective: 16 with grad_accum=2)
  Max length: 352
  Error: CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 42.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2313 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 12
  Learning rate: 1.2363036184809452e-05
  Dropout: 0.058808725752653127
================================================================================


================================================================================
TRIAL 2314 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 64
  Learning rate: 6.42661655539311e-06
  Dropout: 0.3233433713270519
================================================================================

[I 2025-10-30 00:59:01,697] Trial 2314 pruned. OOM: microsoft/deberta-v3-base bs=64 len=128
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2314 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 64 (effective: 192 with grad_accum=3)
  Max length: 128
  Error: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 204.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this pro
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2315 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 8
  Learning rate: 1.7619695266868653e-05
  Dropout: 0.3206711130175985
================================================================================

[I 2025-10-30 01:09:21,628] Trial 2313 pruned. Pruned at step 9 with metric 0.5521
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2316 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 5.3138778185160945e-06
  Dropout: 0.27550852786801605
================================================================================

[I 2025-10-30 01:26:05,326] Trial 2315 finished with value: 0.4489247311827957 and parameters: {'seed': 52342, 'model.name': 'roberta-large', 'tok.max_length': 128, 'tok.doc_stride': 32, 'tok.use_fast': True, 'train.batch_size': 8, 'train.grad_accum': 3, 'optim.name': 'adamw', 'optim.lr': 1.7619695266868653e-05, 'optim.weight_decay': 0.1307121754457984, 'optim.beta1': 0.8728421148655252, 'optim.beta2': 0.9609284481828696, 'optim.eps': 3.0010667747420273e-07, 'sched.name': 'cosine', 'sched.warmup_ratio': 0.1352175943978471, 'train.clip_grad': 1.2739294376091206, 'model.dropout': 0.3206711130175985, 'model.attn_dropout': 0.19070655405827308, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.8481706621200634, 'head.pooling': 'cls', 'head.layers': 3, 'head.hidden': 256, 'head.activation': 'silu', 'head.dropout': 0.28832319526762185, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.9507170053791074, 'loss.cls.alpha': 0.49438724261581696, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2317 - Configuration:
  Model: {'name': 'bert-large-uncased'}
  Batch size: 8
  Learning rate: 6.8231372190851645e-06
  Dropout: 0.3246831486716829
================================================================================

[I 2025-10-30 01:33:45,153] Trial 2308 pruned. Pruned at step 16 with metric 0.6602
[I 2025-10-30 01:33:45,863] Trial 2318 pruned. Pruned: Large model with bsz=24, accum=3 (effective_batch=72) likely causes OOM (24GB GPU limit)

================================================================================
TRIAL 2319 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 16
  Learning rate: 8.236071238545411e-06
  Dropout: 0.36222836867211883
================================================================================

[I 2025-10-30 01:36:10,176] Trial 2316 pruned. Pruned at step 11 with metric 0.6315
[W 2025-10-30 01:36:10,684] The parameter `tok.doc_stride` in Trial#2320 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.

================================================================================
TRIAL 2320 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 64
  Learning rate: 1.2542842941332412e-05
  Dropout: 0.03855589793471703
================================================================================

[I 2025-10-30 01:38:44,988] Trial 2320 pruned. Pruned at step 9 with metric 0.5629
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2321 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 7.661250077574488e-06
  Dropout: 0.13910533030158928
================================================================================

[I 2025-10-30 01:41:03,262] Trial 2317 pruned. Pruned at step 11 with metric 0.5341

================================================================================
TRIAL 2322 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 12
  Learning rate: 1.2123525550200942e-05
  Dropout: 0.034053973602120736
================================================================================

[I 2025-10-30 01:53:37,637] Trial 2322 finished with value: 0.6083492540953619 and parameters: {'seed': 27237, 'model.name': 'bert-base-uncased', 'tok.max_length': 288, 'tok.doc_stride': 80, 'tok.use_fast': True, 'train.batch_size': 12, 'train.grad_accum': 6, 'optim.name': 'adamw', 'optim.lr': 1.2123525550200942e-05, 'optim.weight_decay': 0.005568980062487069, 'optim.beta1': 0.9393353671386502, 'optim.beta2': 0.9705322051443149, 'optim.eps': 4.208028012562863e-09, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.1815637697289184, 'sched.poly_power': 0.638228204251742, 'train.clip_grad': 0.8723583468468827, 'model.dropout': 0.034053973602120736, 'model.attn_dropout': 0.22152489837768752, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 1, 'optim.layerwise_lr_decay': 0.8569157745703742, 'head.pooling': 'cls', 'head.layers': 2, 'head.hidden': 1536, 'head.activation': 'gelu', 'head.dropout': 0.3245452631967529, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.433585771169764, 'loss.cls.alpha': 0.4166321150547469, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 25 (patience=20)

================================================================================
TRIAL 2323 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 12
  Learning rate: 8.58412920344221e-06
  Dropout: 0.011113404888378337
================================================================================

[I 2025-10-30 02:01:17,864] Trial 2319 pruned. Pruned at step 11 with metric 0.5725
[I 2025-10-30 02:01:18,337] Trial 2324 pruned. Pruned: Large model with bsz=12, accum=6 (effective_batch=72) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2325 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 1.5911291879128218e-05
  Dropout: 0.3980079770891575
================================================================================

[I 2025-10-30 02:10:50,446] Trial 2323 pruned. Pruned at step 10 with metric 0.6117

================================================================================
TRIAL 2326 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 64
  Learning rate: 8.326640269318988e-06
  Dropout: 0.3748474661828198
================================================================================

[I 2025-10-30 02:15:47,818] Trial 2326 finished with value: 0.725609756097561 and parameters: {'seed': 31219, 'model.name': 'bert-base-uncased', 'tok.max_length': 128, 'tok.doc_stride': 48, 'tok.use_fast': True, 'train.batch_size': 64, 'train.grad_accum': 2, 'optim.name': 'adamw', 'optim.lr': 8.326640269318988e-06, 'optim.weight_decay': 0.0023166536620310325, 'optim.beta1': 0.8627403125975707, 'optim.beta2': 0.9721362967574462, 'optim.eps': 3.6492776194647233e-09, 'sched.name': 'cosine_restart', 'sched.warmup_ratio': 0.024283939369552844, 'sched.cosine_cycles': 1, 'train.clip_grad': 1.1301025139472334, 'model.dropout': 0.3748474661828198, 'model.attn_dropout': 0.2036525974449566, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 4, 'optim.layerwise_lr_decay': 0.8241814286171528, 'head.pooling': 'attn', 'head.layers': 1, 'head.hidden': 1024, 'head.activation': 'silu', 'head.dropout': 0.40691001961649087, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.9289285786944035, 'loss.cls.alpha': 0.44627129044718117, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
[I 2025-10-30 02:15:48,422] Trial 2327 pruned. Pruned: Large model with bsz=16, accum=6 (effective_batch=96) likely causes OOM (24GB GPU limit)
EarlyStopping triggered at epoch 33 (patience=20)

================================================================================
[GPU RESET] Performing periodic GPU reset after 50 successful trials
This prevents cumulative memory fragmentation during long HPO runs
================================================================================

[GPU RESET] Complete. Continuing HPO...

================================================================================
[GPU RESET] Performing periodic GPU reset after 50 successful trials
This prevents cumulative memory fragmentation during long HPO runs
================================================================================

[GPU RESET] Complete. Continuing HPO...

================================================================================
TRIAL 2328 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 16
  Learning rate: 1.7347392512680705e-05
  Dropout: 0.02495712810516561
================================================================================

[I 2025-10-30 02:27:40,232] Trial 2328 finished with value: 0.7254298642533936 and parameters: {'seed': 43454, 'model.name': 'bert-base-uncased', 'tok.max_length': 128, 'tok.doc_stride': 48, 'tok.use_fast': False, 'train.batch_size': 16, 'train.grad_accum': 6, 'optim.name': 'adamw', 'optim.lr': 1.7347392512680705e-05, 'optim.weight_decay': 0.1117774956250374, 'optim.beta1': 0.8752001356961452, 'optim.beta2': 0.9634490857204858, 'optim.eps': 3.192366109936223e-09, 'sched.name': 'one_cycle', 'sched.warmup_ratio': 0.10920753977124933, 'sched.cosine_cycles': 2, 'train.clip_grad': 0.722534848493871, 'model.dropout': 0.02495712810516561, 'model.attn_dropout': 0.24074778853875686, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.9571685473623025, 'head.pooling': 'attn', 'head.layers': 3, 'head.hidden': 1024, 'head.activation': 'silu', 'head.dropout': 0.0725507517245783, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.22886738993418, 'loss.cls.alpha': 0.5197134792759264, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
EarlyStopping triggered at epoch 45 (patience=20)

================================================================================
TRIAL 2329 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-large'}
  Batch size: 8
  Learning rate: 1.4633763315928606e-05
  Dropout: 0.14902149243117488
================================================================================

[I 2025-10-30 02:40:11,888] Trial 2325 pruned. Pruned at step 13 with metric 0.6398
[I 2025-10-30 02:40:12,360] Trial 2330 pruned. Pruned: Large model with bsz=64, accum=2 (effective_batch=128) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2331 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 64
  Learning rate: 1.2948199396232214e-05
  Dropout: 0.11860578238540795
================================================================================

[I 2025-10-30 02:48:05,470] Trial 2331 finished with value: 0.7007696390658174 and parameters: {'seed': 4898, 'model.name': 'roberta-base', 'tok.max_length': 160, 'tok.doc_stride': 64, 'tok.use_fast': False, 'train.batch_size': 64, 'train.grad_accum': 6, 'optim.name': 'adamw', 'optim.lr': 1.2948199396232214e-05, 'optim.weight_decay': 0.029537564604097705, 'optim.beta1': 0.8358182875790721, 'optim.beta2': 0.9713251713317846, 'optim.eps': 6.442083271084134e-07, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.16170230825048384, 'sched.poly_power': 0.783174390295054, 'train.clip_grad': 1.2442762572108197, 'model.dropout': 0.11860578238540795, 'model.attn_dropout': 0.22977971959116406, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 2, 'optim.layerwise_lr_decay': 0.8110192438534021, 'head.pooling': 'mean', 'head.layers': 3, 'head.hidden': 512, 'head.activation': 'silu', 'head.dropout': 0.029013208297184873, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.508067828383327, 'loss.cls.alpha': 0.5228038815374643, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
[I 2025-10-30 02:48:05,917] Trial 2332 pruned. Pruned: Large model with bsz=64, accum=8 (effective_batch=512) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 25 (patience=20)

================================================================================
TRIAL 2333 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 8.085390131536316e-05
  Dropout: 0.1636934163966644
================================================================================

[I 2025-10-30 02:57:52,386] Trial 2329 pruned. Pruned at step 13 with metric 0.6077
[I 2025-10-30 02:57:52,939] Trial 2334 pruned. Pruned: Large model with bsz=24, accum=8 (effective_batch=192) likely causes OOM (24GB GPU limit)
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2335 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 24
  Learning rate: 1.0438494154586659e-05
  Dropout: 0.365776565895526
================================================================================

[I 2025-10-30 03:04:04,985] Trial 2335 pruned. Pruned at step 13 with metric 0.6274
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2336 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 32
  Learning rate: 1.1502134550879076e-05
  Dropout: 0.013956979018376035
================================================================================

[I 2025-10-30 03:07:29,002] Trial 2336 pruned. Pruned at step 15 with metric 0.6407
[I 2025-10-30 03:07:29,456] Trial 2337 pruned. Pruned: Large model with bsz=48, accum=2 (effective_batch=96) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2338 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 12
  Learning rate: 6.02490305819038e-05
  Dropout: 0.03225251821245652
================================================================================

[I 2025-10-30 03:22:13,638] Trial 2333 finished with value: 0.450402144772118 and parameters: {'seed': 61060, 'model.name': 'roberta-base', 'tok.max_length': 256, 'tok.doc_stride': 48, 'tok.use_fast': False, 'train.batch_size': 16, 'train.grad_accum': 8, 'optim.name': 'adamw', 'optim.lr': 8.085390131536316e-05, 'optim.weight_decay': 0.1198681089529571, 'optim.beta1': 0.8749490484190711, 'optim.beta2': 0.9685932598384946, 'optim.eps': 1.3904427939082123e-07, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.18610735783356389, 'sched.poly_power': 0.5018120298206461, 'train.clip_grad': 1.1708387619795066, 'model.dropout': 0.1636934163966644, 'model.attn_dropout': 0.27626300999557013, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 5, 'optim.layerwise_lr_decay': 0.8285644862666872, 'head.pooling': 'max', 'head.layers': 3, 'head.hidden': 1536, 'head.activation': 'silu', 'head.dropout': 0.1567332095657013, 'loss.cls.type': 'ce', 'loss.cls.label_smoothing': 0.11480765055968373, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2339 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 1.2484952054301448e-05
  Dropout: 0.16588819602371574
================================================================================

[I 2025-10-30 03:32:21,640] Trial 2321 finished with value: 0.7128851540616246 and parameters: {'seed': 36432, 'model.name': 'microsoft/deberta-v3-base', 'tok.max_length': 128, 'tok.doc_stride': 48, 'tok.use_fast': True, 'train.batch_size': 8, 'train.grad_accum': 6, 'optim.name': 'adamw', 'optim.lr': 7.661250077574488e-06, 'optim.weight_decay': 0.08735721119722654, 'optim.beta1': 0.9343864733450903, 'optim.beta2': 0.9544169898674246, 'optim.eps': 1.3849968228606408e-08, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.18666545364583154, 'sched.poly_power': 0.5041290044958221, 'train.clip_grad': 0.6858944278161894, 'model.dropout': 0.13910533030158928, 'model.attn_dropout': 0.22028128471407507, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 4, 'optim.layerwise_lr_decay': 0.8650632502083493, 'head.pooling': 'cls', 'head.layers': 2, 'head.hidden': 512, 'head.activation': 'relu', 'head.dropout': 0.29282139382740363, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.524982518396065, 'loss.cls.alpha': 0.6925445676702751, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
EarlyStopping triggered at epoch 38 (patience=20)

================================================================================
TRIAL 2340 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 16
  Learning rate: 1.013862128436712e-05
  Dropout: 0.18253973371007387
================================================================================

[I 2025-10-30 03:37:44,828] Trial 2338 finished with value: 0.4368131868131868 and parameters: {'seed': 49883, 'model.name': 'roberta-large', 'tok.max_length': 288, 'tok.doc_stride': 32, 'tok.use_fast': True, 'train.batch_size': 12, 'train.grad_accum': 4, 'optim.name': 'adamw', 'optim.lr': 6.02490305819038e-05, 'optim.weight_decay': 9.635972285485128e-05, 'optim.beta1': 0.9482001278713797, 'optim.beta2': 0.9642886960579342, 'optim.eps': 7.052190738425266e-09, 'sched.name': 'cosine', 'sched.warmup_ratio': 0.05774434150396157, 'train.clip_grad': 1.0813984545878101, 'model.dropout': 0.03225251821245652, 'model.attn_dropout': 0.2651872714619395, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 1, 'optim.layerwise_lr_decay': 0.9039555016811756, 'head.pooling': 'attn', 'head.layers': 4, 'head.hidden': 768, 'head.activation': 'relu', 'head.dropout': 0.2726507887949106, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.115927858419069, 'loss.cls.alpha': 0.48750053582850916, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 21 (patience=20)

================================================================================
TRIAL 2341 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 32
  Learning rate: 1.5644175511114663e-05
  Dropout: 0.05323375025704351
================================================================================

[I 2025-10-30 03:43:17,342] Trial 2340 pruned. Pruned at step 7 with metric 0.5839
[I 2025-10-30 03:43:17,808] Trial 2342 pruned. Pruned: Large model with bsz=12, accum=8 (effective_batch=96) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2343 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 32
  Learning rate: 1.2118483923886545e-05
  Dropout: 0.42802495890738046
================================================================================

[I 2025-10-30 03:44:44,158] Trial 2341 pruned. Pruned at step 14 with metric 0.6315
[I 2025-10-30 03:44:44,613] Trial 2344 pruned. Pruned: Large model with bsz=24, accum=6 (effective_batch=144) likely causes OOM (24GB GPU limit)
[I 2025-10-30 03:44:45,035] Trial 2345 pruned. Pruned: Large model with bsz=24, accum=8 (effective_batch=192) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2346 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 3.70832669971493e-05
  Dropout: 0.05594058523571558
================================================================================

[I 2025-10-30 03:50:34,167] Trial 2339 pruned. Pruned at step 11 with metric 0.5477

================================================================================
TRIAL 2347 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 5.532169228931757e-05
  Dropout: 0.0714542266408887
================================================================================

[I 2025-10-30 03:50:37,317] Trial 2346 pruned. Pruned at step 10 with metric 0.5036

================================================================================
TRIAL 2348 - Configuration:
  Model: {'name': 'xlm-roberta-base'}
  Batch size: 16
  Learning rate: 2.5637296281718877e-05
  Dropout: 0.06319491572597757
================================================================================

[I 2025-10-30 03:54:45,697] Trial 2343 pruned. Pruned at step 14 with metric 0.5693
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2349 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 64
  Learning rate: 1.3981329994272346e-05
  Dropout: 0.2955316051502856
================================================================================

[I 2025-10-30 03:54:52,184] Trial 2349 pruned. OOM: microsoft/deberta-v3-base bs=64 len=256
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
[I 2025-10-30 03:54:55,248] Trial 2348 pruned. OOM: xlm-roberta-base bs=16 len=320

[OOM] Trial 2349 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 64 (effective: 64 with grad_accum=1)
  Max length: 256
  Error: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 166.00 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this pro
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2350 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 8
  Learning rate: 2.3281776641030132e-05
  Dropout: 0.0852222051093372
================================================================================


[OOM] Trial 2348 exceeded GPU memory:
  Model: xlm-roberta-base
  Batch size: 16 (effective: 32 with grad_accum=2)
  Max length: 320
  Error: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 626.00 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this pro
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2351 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 6.8695931160405156e-06
  Dropout: 0.03223196164463115
================================================================================

Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[I 2025-10-30 04:02:49,249] Trial 2347 pruned. Pruned at step 8 with metric 0.6250
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2352 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 8
  Learning rate: 7.91719871020651e-06
  Dropout: 0.1430469319879914
================================================================================

[I 2025-10-30 04:08:07,553] Trial 2351 finished with value: 0.7071428571428571 and parameters: {'seed': 64976, 'model.name': 'roberta-base', 'tok.max_length': 128, 'tok.doc_stride': 32, 'tok.use_fast': True, 'train.batch_size': 24, 'train.grad_accum': 4, 'optim.name': 'adamw', 'optim.lr': 6.8695931160405156e-06, 'optim.weight_decay': 0.06436610272830989, 'optim.beta1': 0.9404212019055687, 'optim.beta2': 0.9724889323662272, 'optim.eps': 8.98804466760435e-09, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.16555548307878423, 'sched.poly_power': 0.6535535468560335, 'train.clip_grad': 1.1830285340841273, 'model.dropout': 0.03223196164463115, 'model.attn_dropout': 0.1890361503260877, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 2, 'optim.layerwise_lr_decay': 0.855073953181439, 'head.pooling': 'cls', 'head.layers': 1, 'head.hidden': 512, 'head.activation': 'gelu', 'head.dropout': 0.32169457788126243, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.48620800411036, 'loss.cls.alpha': 0.8033839300363466, 'loss.cls.balance': 'effective_num'}. Best is trial 1951 with value: 0.7883870967741935.
[I 2025-10-30 04:08:08,038] Trial 2353 pruned. Pruned: Large model with bsz=24, accum=8 (effective_batch=192) likely causes OOM (24GB GPU limit)
EarlyStopping triggered at epoch 53 (patience=20)

================================================================================
TRIAL 2354 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 9.946189965079592e-06
  Dropout: 0.1922808730276294
================================================================================

[I 2025-10-30 04:17:54,943] Trial 2354 finished with value: 0.6506265664160401 and parameters: {'seed': 62375, 'model.name': 'bert-base-uncased', 'tok.max_length': 224, 'tok.doc_stride': 32, 'tok.use_fast': False, 'train.batch_size': 24, 'train.grad_accum': 3, 'optim.name': 'adamw', 'optim.lr': 9.946189965079592e-06, 'optim.weight_decay': 0.09893873438704384, 'optim.beta1': 0.9398041754454186, 'optim.beta2': 0.9626200989064913, 'optim.eps': 1.0614711553175141e-07, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.14878798368177487, 'sched.poly_power': 0.5030171339968725, 'train.clip_grad': 0.9061972334514183, 'model.dropout': 0.1922808730276294, 'model.attn_dropout': 0.26498719223044565, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 3, 'optim.layerwise_lr_decay': 0.8437198304408909, 'head.pooling': 'cls', 'head.layers': 2, 'head.hidden': 512, 'head.activation': 'gelu', 'head.dropout': 0.3490170528875032, 'loss.cls.type': 'focal', 'loss.cls.gamma': 4.632456015714069, 'loss.cls.alpha': 0.5288854192933524, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
EarlyStopping triggered at epoch 29 (patience=20)

================================================================================
TRIAL 2355 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 48
  Learning rate: 5.1226495213747275e-05
  Dropout: 0.10241648443248078
================================================================================

[I 2025-10-30 04:24:33,105] Trial 2355 finished with value: 0.6699447369566164 and parameters: {'seed': 65400, 'model.name': 'bert-base-uncased', 'tok.max_length': 192, 'tok.doc_stride': 80, 'tok.use_fast': True, 'train.batch_size': 48, 'train.grad_accum': 2, 'optim.name': 'adamw', 'optim.lr': 5.1226495213747275e-05, 'optim.weight_decay': 0.0007590996381207442, 'optim.beta1': 0.8805293324411663, 'optim.beta2': 0.9642260704475402, 'optim.eps': 7.2902782635460045e-09, 'sched.name': 'polynomial', 'sched.warmup_ratio': 0.16074721752732307, 'sched.poly_power': 0.942187930269961, 'train.clip_grad': 1.4283377588801363, 'model.dropout': 0.10241648443248078, 'model.attn_dropout': 0.25549434641002156, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 6, 'optim.layerwise_lr_decay': 0.8525458226423501, 'head.pooling': 'mean', 'head.layers': 4, 'head.hidden': 1536, 'head.activation': 'gelu', 'head.dropout': 0.29833754846094335, 'loss.cls.type': 'ce', 'loss.cls.label_smoothing': 0.06544343971557798, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
EarlyStopping triggered at epoch 28 (patience=20)

================================================================================
TRIAL 2356 - Configuration:
  Model: {'name': 'xlm-roberta-base'}
  Batch size: 12
  Learning rate: 1.759550718041164e-05
  Dropout: 0.1302021707430886
================================================================================


================================================================================
TRIAL 2351 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 6.8695931160405156e-06
  Dropout: 0.03223196164463115
================================================================================

[I 2025-10-30 04:24:40,485] Trial 2350 pruned. Pruned at step 7 with metric 0.6067
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2357 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 24
  Learning rate: 1.4594935832521634e-05
  Dropout: 0.35788315752770083
================================================================================

[I 2025-10-30 04:44:50,787] Trial 2356 pruned. Pruned at step 27 with metric 0.5807
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2358 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 1.4115122823007684e-05
  Dropout: 0.053064474512152716
================================================================================

[I 2025-10-30 04:53:00,155] Trial 2358 pruned. Pruned at step 10 with metric 0.5185
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2359 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 6.385146549549435e-06
  Dropout: 0.2782854203881296
================================================================================

[I 2025-10-30 04:58:19,720] Trial 2357 finished with value: 0.6916871752802844 and parameters: {'seed': 32495, 'model.name': 'microsoft/deberta-v3-base', 'tok.max_length': 128, 'tok.doc_stride': 32, 'tok.use_fast': True, 'train.batch_size': 24, 'train.grad_accum': 1, 'optim.name': 'adamw', 'optim.lr': 1.4594935832521634e-05, 'optim.weight_decay': 0.02430076217541622, 'optim.beta1': 0.9164741422197064, 'optim.beta2': 0.98263837499978, 'optim.eps': 2.7134940198726435e-08, 'sched.name': 'linear', 'sched.warmup_ratio': 0.07789790947677595, 'train.clip_grad': 0.5903595994886837, 'model.dropout': 0.35788315752770083, 'model.attn_dropout': 0.2694295015119394, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 3, 'optim.layerwise_lr_decay': 0.9338725404486922, 'head.pooling': 'cls', 'head.layers': 4, 'head.hidden': 1024, 'head.activation': 'silu', 'head.dropout': 0.4713522800861636, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.629071292536358, 'loss.cls.alpha': 0.4863395501838412, 'loss.cls.balance': 'none'}. Best is trial 1951 with value: 0.7883870967741935.
[I 2025-10-30 04:58:20,180] Trial 2360 pruned. Pruned: Large model with bsz=32, accum=3 (effective_batch=96) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EarlyStopping triggered at epoch 26 (patience=20)

================================================================================
TRIAL 2361 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 32
  Learning rate: 3.758797090679687e-05
  Dropout: 0.39647010808983163
================================================================================

[I 2025-10-30 04:59:46,927] Trial 2352 pruned. Pruned at step 6 with metric 0.6159
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2362 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 24
  Learning rate: 1.3622904876076058e-05
  Dropout: 0.24515193546017025
================================================================================

[I 2025-10-30 05:04:17,146] Trial 2359 pruned. Pruned at step 17 with metric 0.5486
[W 2025-10-30 05:04:17,570] The parameter `tok.doc_stride` in Trial#2363 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.

================================================================================
TRIAL 2363 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 24
  Learning rate: 9.09387367156055e-06
  Dropout: 0.01947091749200504
================================================================================

[I 2025-10-30 05:06:13,486] Trial 2361 pruned. Pruned at step 10 with metric 0.6095
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2364 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 24
  Learning rate: 1.0184240819128129e-05
  Dropout: 0.3289579281833459
================================================================================

[I 2025-10-30 05:06:18,862] Trial 2364 pruned. OOM: microsoft/deberta-v3-base bs=24 len=384

[OOM] Trial 2364 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 24 (effective: 192 with grad_accum=8)
  Max length: 384
  Error: CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 96.50 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proc
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2365 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-large'}
  Batch size: 8
  Learning rate: 2.7365136296194603e-05
  Dropout: 0.2355644296988259
================================================================================

[I 2025-10-30 05:08:11,241] Trial 2363 pruned. Pruned at step 10 with metric 0.5766
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2366 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 24
  Learning rate: 2.5774818059922623e-05
  Dropout: 0.24616558864078922
================================================================================

[I 2025-10-30 05:08:16,218] Trial 2366 pruned. OOM: microsoft/deberta-v3-base bs=24 len=320
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2366 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 24 (effective: 96 with grad_accum=4)
  Max length: 320
  Error: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 100.50 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this pro
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2367 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 8
  Learning rate: 6.991645758449548e-06
  Dropout: 0.12017368616355119
================================================================================

[I 2025-10-30 05:12:57,727] Trial 2362 pruned. Pruned at step 8 with metric 0.5593
[I 2025-10-30 05:12:58,205] Trial 2368 pruned. Pruned: Large model with bsz=24, accum=1 (effective_batch=24) likely causes OOM (24GB GPU limit)
/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

================================================================================
TRIAL 2369 - Configuration:
  Model: {'name': 'microsoft/deberta-v3-base'}
  Batch size: 12
  Learning rate: 1.015441249722252e-05
  Dropout: 0.2150276678029106
================================================================================

[I 2025-10-30 05:13:05,588] Trial 2369 pruned. OOM: microsoft/deberta-v3-base bs=12 len=320

[OOM] Trial 2369 exceeded GPU memory:
  Model: microsoft/deberta-v3-base
  Batch size: 12 (effective: 24 with grad_accum=2)
  Max length: 320
  Error: CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 63.31 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2370 - Configuration:
  Model: {'name': 'bert-base-uncased'}
  Batch size: 48
  Learning rate: 9.038185518856408e-06
  Dropout: 0.15409979944679594
================================================================================

[I 2025-10-30 05:13:09,625] Trial 2370 pruned. OOM: bert-base-uncased bs=48 len=288
[I 2025-10-30 05:13:10,119] Trial 2371 pruned. Pruned: Large model with bsz=32, accum=6 (effective_batch=192) likely causes OOM (24GB GPU limit)
[I 2025-10-30 05:13:11,273] Trial 2367 pruned. OOM: roberta-base bs=8 len=128
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2370 exceeded GPU memory:
  Model: bert-base-uncased
  Batch size: 48 (effective: 288 with grad_accum=6)
  Max length: 288
  Error: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 57.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2372 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 5.87851014219453e-06
  Dropout: 0.4996436872477403
================================================================================


[OOM] Trial 2367 exceeded GPU memory:
  Model: roberta-base
  Batch size: 8 (effective: 48 with grad_accum=6)
  Max length: 128
  Error: CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 137.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this pro
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2373 - Configuration:
  Model: {'name': 'bert-large-uncased'}
  Batch size: 12
  Learning rate: 8.894008461937065e-06
  Dropout: 0.4344446826736015
================================================================================

[I 2025-10-30 05:13:18,051] Trial 2372 pruned. OOM: roberta-base bs=16 len=192
[I 2025-10-30 05:13:19,769] Trial 2373 pruned. OOM: bert-large-uncased bs=12 len=256
[I 2025-10-30 05:13:19,941] Trial 2365 pruned. OOM: microsoft/deberta-v3-large bs=8 len=224
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

[OOM] Trial 2372 exceeded GPU memory:
  Model: roberta-base
  Batch size: 16 (effective: 128 with grad_accum=8)
  Max length: 192
  Error: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 43.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


================================================================================
TRIAL 2374 - Configuration:
  Model: {'name': 'roberta-base'}
  Batch size: 16
  Learning rate: 1.100820433281048e-05
  Dropout: 0.1428737115600323
================================================================================


[OOM] Trial 2365 exceeded GPU memory:
  Model: microsoft/deberta-v3-large
  Batch size: 8 (effective: 32 with grad_accum=4)
  Max length: 224
  Error: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 63.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.


[OOM] Trial 2373 exceeded GPU memory:
  Model: bert-large-uncased
  Batch size: 12 (effective: 12 with grad_accum=1)
  Max length: 256
  Error: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 43.62 MiB is free. Process 2565 has 258.00 MiB memory in use. Including non-PyTorch memory, this proce
  Pruning trial to allow Optuna to learn memory constraints.

[I 2025-10-30 05:13:20,832] Trial 2376 pruned. Pruned: Large model with bsz=64, accum=2 (effective_batch=128) likely causes OOM (24GB GPU limit)
[I 2025-10-30 05:13:21,076] Trial 2375 pruned. Pruned: Large model with bsz=64, accum=8 (effective_batch=512) likely causes OOM (24GB GPU limit)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

================================================================================
TRIAL 2377 - Configuration:
  Model: {'name': 'roberta-large'}
  Batch size: 8
  Learning rate: 1.1448995065159773e-05
  Dropout: 0.006076595286951932
================================================================================


================================================================================
TRIAL 2378 - Configuration:
  Model: {'name': 'bert-large-uncased'}
  Batch size: 12
  Learning rate: 3.041068743421911e-05
  Dropout: 0.37722305824666297
================================================================================

/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [64,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [65,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [66,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [67,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [68,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [69,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [70,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [71,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [72,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [73,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [74,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [75,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [76,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [77,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [78,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [79,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [80,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [81,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [82,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [83,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [84,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [85,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [86,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [87,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [88,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [89,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [90,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [91,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [92,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [93,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [94,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [28,0,0], thread: [95,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [192,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [193,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [194,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [195,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [196,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [197,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [198,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [199,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [200,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [201,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [202,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [203,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [204,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [205,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [206,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [207,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [208,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [209,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [210,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [211,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [212,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [213,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [214,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [215,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [216,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [217,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [218,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [219,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [220,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [221,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [222,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [48,0,0], thread: [223,0,0] Assertion `ind >=0 && ind < ind_dim_size && "vectorized gather kernel index out of bounds"` failed.
[W 2025-10-30 05:13:23,732] Trial 2378 failed with parameters: {'seed': 25686, 'model.name': 'bert-large-uncased', 'tok.max_length': 384, 'tok.doc_stride': 64, 'tok.use_fast': True, 'train.batch_size': 12, 'train.grad_accum': 1, 'optim.name': 'adamw', 'optim.lr': 3.041068743421911e-05, 'optim.weight_decay': 0.14153886872213806, 'optim.beta1': 0.8302933264027598, 'optim.beta2': 0.972849314293996, 'optim.eps': 3.7666546148202755e-07, 'sched.name': 'cosine_restart', 'sched.warmup_ratio': 0.11586317201810212, 'sched.cosine_cycles': 1, 'train.clip_grad': 0.760974503816059, 'model.dropout': 0.37722305824666297, 'model.attn_dropout': 0.20568695643004853, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 4, 'optim.layerwise_lr_decay': 0.9088823310840946, 'head.pooling': 'cls', 'head.layers': 4, 'head.hidden': 512, 'head.activation': 'silu', 'head.dropout': 0.3639834796002505, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.7544855675644633, 'loss.cls.alpha': 0.5423807874994488, 'loss.cls.balance': 'none'} because of the following error: RuntimeError('CUDA context corrupted after 3 consecutive failures. Process must restart.').
Traceback (most recent call last):
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py", line 1075, in _obj
    res = run_training_eval(cfg, {"on_epoch": _cb}, trial_number=trial.number)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py", line 739, in run_training_eval
    model = safe_to_device(model, device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py", line 726, in safe_to_device
    model = model.to(target_device)
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1371, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 930, in _apply
    module._apply(fn)
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 930, in _apply
    module._apply(fn)
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 930, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 957, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1357, in convert
    return t.to(
           ^^^^^
torch.AcceleratorError: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/optuna/study/_optimize.py", line 201, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py", line 1163, in _obj
    raise RuntimeError(
RuntimeError: CUDA context corrupted after 3 consecutive failures. Process must restart.
[W 2025-10-30 05:13:23,735] Trial 2378 failed with value None.
[W 2025-10-30 05:13:23,980] Trial 2377 failed with parameters: {'seed': 45337, 'model.name': 'roberta-large', 'tok.max_length': 384, 'tok.doc_stride': 48, 'tok.use_fast': False, 'train.batch_size': 8, 'train.grad_accum': 4, 'optim.name': 'adamw', 'optim.lr': 1.1448995065159773e-05, 'optim.weight_decay': 0.014683690932177225, 'optim.beta1': 0.8756275433247855, 'optim.beta2': 0.994806759364473, 'optim.eps': 1.2921588910736095e-07, 'sched.name': 'one_cycle', 'sched.warmup_ratio': 0.059446420802758984, 'sched.cosine_cycles': 2, 'train.clip_grad': 0.7161699148492133, 'model.dropout': 0.006076595286951932, 'model.attn_dropout': 0.2735950178747434, 'train.grad_checkpointing': False, 'train.freeze_encoder_layers': 2, 'optim.layerwise_lr_decay': 0.8940564512322537, 'head.pooling': 'attn', 'head.layers': 3, 'head.hidden': 1024, 'head.activation': 'relu', 'head.dropout': 0.08423179481917394, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.6613158240096384, 'loss.cls.alpha': 0.3899546534037879, 'loss.cls.balance': 'effective_num'} because of the following error: RuntimeError('CUDA context corrupted after 3 consecutive failures. Process must restart.').
Traceback (most recent call last):
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py", line 1075, in _obj
    res = run_training_eval(cfg, {"on_epoch": _cb}, trial_number=trial.number)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py", line 809, in run_training_eval
    logits = model(input_ids, attention_mask)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/src/Project/Criteria/models/model.py", line 119, in forward
    outputs = self.encoder(
              ^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py", line 798, in forward
    embedding_output = self.embeddings(
                       ^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py", line 111, in forward
    token_type_embeddings = self.token_type_embeddings(token_type_ids)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.AcceleratorError: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/optuna/study/_optimize.py", line 201, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py", line 1163, in _obj
    raise RuntimeError(
RuntimeError: CUDA context corrupted after 3 consecutive failures. Process must restart.
[W 2025-10-30 05:13:23,983] Trial 2377 failed with value None.
[W 2025-10-30 05:13:24,151] Trial 2374 failed with parameters: {'seed': 44703, 'model.name': 'roberta-base', 'tok.max_length': 224, 'tok.doc_stride': 48, 'tok.use_fast': True, 'train.batch_size': 16, 'train.grad_accum': 2, 'optim.name': 'adamw', 'optim.lr': 1.100820433281048e-05, 'optim.weight_decay': 0.16146627624075402, 'optim.beta1': 0.902330870541269, 'optim.beta2': 0.9576326689512595, 'optim.eps': 1.4060973700518806e-07, 'sched.name': 'linear', 'sched.warmup_ratio': 0.15034948031971693, 'train.clip_grad': 1.1310675485172816, 'model.dropout': 0.1428737115600323, 'model.attn_dropout': 0.2801957887217173, 'train.grad_checkpointing': True, 'train.freeze_encoder_layers': 6, 'optim.layerwise_lr_decay': 0.8715642848010372, 'head.pooling': 'cls', 'head.layers': 3, 'head.hidden': 512, 'head.activation': 'silu', 'head.dropout': 0.3761331487966894, 'loss.cls.type': 'focal', 'loss.cls.gamma': 3.871536488996851, 'loss.cls.alpha': 0.4689508746731482, 'loss.cls.balance': 'none'} because of the following error: RuntimeError('CUDA context corrupted after 3 consecutive failures. Process must restart.').
Traceback (most recent call last):
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py", line 1075, in _obj
    res = run_training_eval(cfg, {"on_epoch": _cb}, trial_number=trial.number)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py", line 809, in run_training_eval
    logits = model(input_ids, attention_mask)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/src/Project/Criteria/models/model.py", line 119, in forward
    outputs = self.encoder(
              ^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py", line 862, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py", line 606, in forward
    layer_outputs = layer_module(
                    ^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py", line 513, in forward
    self_attention_outputs = self.attention(
                             ^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py", line 449, in forward
    attention_output = self.output(self_outputs[0], hidden_states)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py", line 388, in forward
    hidden_states = self.dropout(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/dropout.py", line 73, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/functional.py", line 1418, in dropout
    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.AcceleratorError: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/optuna/study/_optimize.py", line 201, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py", line 1163, in _obj
    raise RuntimeError(
RuntimeError: CUDA context corrupted after 3 consecutive failures. Process must restart.
[W 2025-10-30 05:13:24,158] Trial 2374 failed with value None.
Warning: Error during model cleanup: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Warning: Error during CUDA cleanup: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Warning: Error during model cleanup: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Warning: Error during CUDA cleanup: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


[CUDA ERROR] Trial 2378 encountered CUDA error (consecutive failures: 3):
  Error Type: AcceleratorError
  Model: bert-large-uncased
  Batch size: 12
  Learning rate: 3.041068743421911e-05
  Dropout: 0.37722305824666297
  Error: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



================================================================================
FATAL: 3 consecutive CUDA failures detected!
This indicates CUDA context corruption that cannot be recovered.
Raising fatal error to trigger process restart...
================================================================================


[CUDA ERROR] Trial 2374 encountered CUDA error (consecutive failures: 3):
  Error Type: AcceleratorError
  Model: roberta-base
  Batch size: 16
  Learning rate: 1.100820433281048e-05
  Dropout: 0.1428737115600323
  Error: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



================================================================================
FATAL: 3 consecutive CUDA failures detected!
This indicates CUDA context corruption that cannot be recovered.
Raising fatal error to trigger process restart...
================================================================================


[CUDA ERROR] Trial 2377 encountered CUDA error (consecutive failures: 3):
  Error Type: AcceleratorError
  Model: roberta-large
  Batch size: 8
  Learning rate: 1.1448995065159773e-05
  Dropout: 0.006076595286951932
  Error: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



================================================================================
FATAL: 3 consecutive CUDA failures detected!
This indicates CUDA context corruption that cannot be recovered.
Raising fatal error to trigger process restart...
================================================================================

Traceback (most recent call last):
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py", line 1075, in _obj
    res = run_training_eval(cfg, {"on_epoch": _cb}, trial_number=trial.number)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py", line 739, in run_training_eval
    model = safe_to_device(model, device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py", line 726, in safe_to_device
    model = model.to(target_device)
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1371, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 930, in _apply
    module._apply(fn)
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 930, in _apply
    module._apply(fn)
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 930, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 957, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1357, in convert
    return t.to(
           ^^^^^
torch.AcceleratorError: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py", line 1618, in <module>
    main()
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py", line 1567, in main
    study.optimize(
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/optuna/study/study.py", line 490, in optimize
    _optimize(
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/optuna/study/_optimize.py", line 100, in _optimize
    f.result()
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial_id = _run_trial(study, func, catch)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/optuna/study/_optimize.py", line 258, in _run_trial
    raise func_err
  File "/home/user/miniforge3/envs/llmhe/lib/python3.12/site-packages/optuna/study/_optimize.py", line 201, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/media/user/SSD1/YuNing/NoAug_Criteria_Evidence/scripts/tune_max.py", line 1163, in _obj
    raise RuntimeError(
RuntimeError: CUDA context corrupted after 3 consecutive failures. Process must restart.
[W1030 05:14:05.641786618 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
make[1]: *** [Makefile:368: tune-criteria-supermax] Error 1
make[1]: Leaving directory '/media/user/SSD1/YuNing/NoAug_Criteria_Evidence'
make: *** [Makefile:413: tune-all-supermax] Error 2
