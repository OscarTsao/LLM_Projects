num_epochs: 100
batch_size: 24
eval_batch_size: 24
learning_rate: 8.6e-06
weight_decay: 3.9e-04
warmup_ratio: 0.168
adam_eps: 7.8e-09
adam_beta1: 0.846
adam_beta2: 0.974
gradient_accumulation_steps: 3
max_grad_norm: 0.51
layerwise_lr_decay: 0.897
freeze_encoder_layers: 6
early_stopping_patience: 10
metric_for_best: f1_macro
use_amp: true
auto_resume: true
resume_checkpoint: null
num_workers: 10
prefetch_factor: 4
persistent_workers: true
scheduler_type: cosine_with_restarts
scheduler_num_cycles: 2
enable_tf32: true
float32_matmul_precision: high
cudnn_benchmark: true
non_blocking_transfers: true
pin_memory_device: null
torch_compile: false
torch_compile_mode: max-autotune
torch_compile_backend: null
torch_compile_dynamic: null
torch_compile_fullgraph: null
