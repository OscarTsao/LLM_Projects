# Training defaults for NO-AUG pipeline

num_epochs: 10
batch_size: 16
eval_batch_size: 32
learning_rate: 2.0e-5
weight_decay: 0.01
max_length: 512
gradient_clip: 1.0
gradient_accumulation_steps: 1

scheduler:
  type: "cosine"
  warmup_ratio: 0.06

optimizer:
  name: "adamw"
  betas: [0.9, 0.999]
  eps: 1.0e-8

amp:
  enabled: true
  dtype: "float16"

early_stopping:
  metric: "val_f1_macro"
  mode: "max"
  patience: 3
  min_delta: 0.0001

logging_steps: 100
eval_steps: 500

num_workers: 4
pin_memory: true
prefetch_factor: 2
