# Training configuration tuned for larger real-world datasets.
task: criteria_ranker
lr: 1e-5
weight_decay: 0.01
batch_size_per_device: 8
max_steps: 2000
warmup_ratio: 0.1
scheduler: cosine
eval_every_steps: 200
save_every_steps: 500
metric: map@10
early_stop_patience: 5
save_top_k: 2
margin: 0.0
benchmark_steps: 200
