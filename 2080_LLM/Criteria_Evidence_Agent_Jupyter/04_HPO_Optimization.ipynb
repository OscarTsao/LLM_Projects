{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization (HPO) Notebook\n",
    "\n",
    "This notebook provides comprehensive hyperparameter optimization using Optuna with auto-resume capabilities,\n",
    "enhanced progress tracking, and visualization. It replaces the original hpo.py script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Import all necessary libraries for HPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, List, Tuple\n",
    "from dataclasses import asdict\n",
    "from datetime import datetime\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Add src to path\n",
    "if 'src' not in sys.path:\n",
    "    sys.path.append('src')\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"Optuna version: {optuna.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dependencies\n",
    "\n",
    "Load configuration and checkpoint managers from other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration and checkpoint managers\n",
    "%run 01_Configuration_Management.ipynb\n",
    "%run 02_Enhanced_Checkpoint_System.ipynb\n",
    "\n",
    "# Import training function from main training notebook\n",
    "# We'll define a simplified version here for HPO\n",
    "from src.train import train_loop\n",
    "\n",
    "print(\"‚úÖ Dependencies loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO Configuration and Search Space\n",
    "\n",
    "Define the search space and HPO configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPOSearchSpace:\n",
    "    \"\"\"Defines the hyperparameter search space for optimization.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def suggest_hyperparameters(trial: optuna.Trial, base_config: ExperimentConfig) -> ExperimentConfig:\n",
    "        \"\"\"Suggest hyperparameters for a trial.\"\"\"\n",
    "        \n",
    "        # Create a copy of the base configuration\n",
    "        config = ExperimentConfig(\n",
    "            seed=base_config.seed,\n",
    "            data=base_config.data,\n",
    "            model=base_config.model,\n",
    "            training=base_config.training,\n",
    "            hpo=base_config.hpo,\n",
    "            mlflow=base_config.mlflow\n",
    "        )\n",
    "        \n",
    "        # Model hyperparameters\n",
    "        config.model.encoder.type = trial.suggest_categorical(\n",
    "            \"model.encoder.type\", [\"roberta\", \"bert\", \"deberta\"]\n",
    "        )\n",
    "        \n",
    "        # Update model name based on type\n",
    "        model_mapping = {\n",
    "            \"roberta\": \"roberta-base\",\n",
    "            \"bert\": \"bert-base-uncased\",\n",
    "            \"deberta\": \"microsoft/deberta-base\"\n",
    "        }\n",
    "        config.model.encoder.pretrained_model_name_or_path = model_mapping[config.model.encoder.type]\n",
    "        \n",
    "        config.model.encoder.freeze_encoder = trial.suggest_categorical(\n",
    "            \"model.encoder.freeze_encoder\", [False, True]\n",
    "        )\n",
    "        \n",
    "        config.model.encoder.pooling = trial.suggest_categorical(\n",
    "            \"model.encoder.pooling\", [\"cls\", \"mean\"]\n",
    "        )\n",
    "        \n",
    "        config.model.encoder.output_dropout = trial.suggest_float(\n",
    "            \"model.encoder.output_dropout\", 0.0, 0.5\n",
    "        )\n",
    "        \n",
    "        config.model.encoder.gradient_checkpointing = trial.suggest_categorical(\n",
    "            \"model.encoder.gradient_checkpointing\", [False, True]\n",
    "        )\n",
    "        \n",
    "        # LoRA hyperparameters\n",
    "        config.model.encoder.lora.enabled = trial.suggest_categorical(\n",
    "            \"model.encoder.lora.enabled\", [False, True]\n",
    "        )\n",
    "        \n",
    "        if config.model.encoder.lora.enabled:\n",
    "            config.model.encoder.lora.r = trial.suggest_categorical(\n",
    "                \"model.encoder.lora.r\", [8, 16, 32]\n",
    "            )\n",
    "            config.model.encoder.lora.alpha = trial.suggest_categorical(\n",
    "                \"model.encoder.lora.alpha\", [16, 32, 64]\n",
    "            )\n",
    "            config.model.encoder.lora.dropout = trial.suggest_float(\n",
    "                \"model.encoder.lora.dropout\", 0.0, 0.2\n",
    "            )\n",
    "        \n",
    "        # Training hyperparameters\n",
    "        config.training.batch_size = trial.suggest_categorical(\n",
    "            \"training.batch_size\", [8, 16, 32, 64]\n",
    "        )\n",
    "        \n",
    "        config.training.gradient_accumulation_steps = trial.suggest_categorical(\n",
    "            \"training.gradient_accumulation_steps\", [1, 2, 4]\n",
    "        )\n",
    "        \n",
    "        config.training.max_grad_norm = trial.suggest_float(\n",
    "            \"training.max_grad_norm\", 0.5, 5.0\n",
    "        )\n",
    "        \n",
    "        # Optimizer hyperparameters\n",
    "        config.training.optimizer.name = trial.suggest_categorical(\n",
    "            \"training.optimizer.name\", [\"adamw\", \"lamb\", \"adafactor\"]\n",
    "        )\n",
    "        \n",
    "        config.training.optimizer.learning_rate = trial.suggest_float(\n",
    "            \"training.optimizer.learning_rate\", 1e-6, 5e-5, log=True\n",
    "        )\n",
    "        \n",
    "        config.training.optimizer.weight_decay = trial.suggest_float(\n",
    "            \"training.optimizer.weight_decay\", 1e-5, 1e-1, log=True\n",
    "        )\n",
    "        \n",
    "        config.training.optimizer.layerwise_lr_decay = trial.suggest_float(\n",
    "            \"training.optimizer.layerwise_lr_decay\", 0.8, 1.0\n",
    "        )\n",
    "        \n",
    "        # Scheduler hyperparameters\n",
    "        config.training.scheduler.name = trial.suggest_categorical(\n",
    "            \"training.scheduler.name\", [\"linear\", \"cosine\", \"onecycle\", \"plateau\"]\n",
    "        )\n",
    "        \n",
    "        config.training.scheduler.warmup_ratio = trial.suggest_float(\n",
    "            \"training.scheduler.warmup_ratio\", 0.0, 0.2\n",
    "        )\n",
    "        \n",
    "        if config.training.scheduler.name == \"cosine\":\n",
    "            config.training.scheduler.cosine_cycles = trial.suggest_float(\n",
    "                \"training.scheduler.cosine_cycles\", 0.25, 1.0\n",
    "            )\n",
    "        elif config.training.scheduler.name == \"onecycle\":\n",
    "            config.training.scheduler.onecycle_max_lr = trial.suggest_float(\n",
    "                \"training.scheduler.onecycle_max_lr\", 1e-5, 1e-4, log=True\n",
    "            )\n",
    "            config.training.scheduler.onecycle_pct_start = trial.suggest_float(\n",
    "                \"training.scheduler.onecycle_pct_start\", 0.1, 0.5\n",
    "            )\n",
    "        elif config.training.scheduler.name == \"plateau\":\n",
    "            config.training.scheduler.plateau_patience = trial.suggest_categorical(\n",
    "                \"training.scheduler.plateau_patience\", [1, 2, 3, 5]\n",
    "            )\n",
    "        \n",
    "        # Focal loss hyperparameters\n",
    "        config.training.focal.initial_gamma = trial.suggest_float(\n",
    "            \"training.focal.initial_gamma\", 1.0, 5.0\n",
    "        )\n",
    "        \n",
    "        config.training.focal.alpha = trial.suggest_float(\n",
    "            \"training.focal.alpha\", 0.1, 0.5\n",
    "        )\n",
    "        \n",
    "        # EMA hyperparameter\n",
    "        config.training.ema_decay = trial.suggest_float(\n",
    "            \"training.ema_decay\", 0.0, 0.9999\n",
    "        )\n",
    "        \n",
    "        # Data hyperparameters\n",
    "        config.data.max_length = trial.suggest_categorical(\n",
    "            \"data.max_length\", [128, 256, 384, 512]\n",
    "        )\n",
    "        \n",
    "        # Model head hyperparameters\n",
    "        config.model.heads.symptom_labels.layers.activation = trial.suggest_categorical(\n",
    "            \"model.heads.symptom_labels.layers.activation\", \n",
    "            [\"tanh\", \"gelu\", \"leakyrelu\", \"relu\", \"silu\", \"mish\", \"elu\"]\n",
    "        )\n",
    "        \n",
    "        config.model.heads.symptom_labels.layers.dropout = trial.suggest_float(\n",
    "            \"model.heads.symptom_labels.layers.dropout\", 0.0, 0.5\n",
    "        )\n",
    "        \n",
    "        config.model.heads.symptom_labels.classifier_dropout = trial.suggest_float(\n",
    "            \"model.heads.symptom_labels.classifier_dropout\", 0.0, 0.5\n",
    "        )\n",
    "        \n",
    "        config.model.heads.symptom_labels.label_smoothing = trial.suggest_float(\n",
    "            \"model.heads.symptom_labels.label_smoothing\", 0.0, 0.2\n",
    "        )\n",
    "        \n",
    "        # Suggest thresholds for each symptom\n",
    "        for symptom in config.data.multi_label_fields:\n",
    "            config.model.heads.symptom_labels.thresholds[symptom] = trial.suggest_float(\n",
    "                f\"model.heads.symptom_labels.thresholds.{symptom}\", 0.2, 0.8\n",
    "            )\n",
    "        \n",
    "        return config\n",
    "\n",
    "print(\"‚úÖ HPO search space defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced HPO Manager\n",
    "\n",
    "Comprehensive HPO management with auto-resume and progress tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedHPOManager:\n",
    "    \"\"\"Enhanced HPO manager with auto-resume and comprehensive tracking.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_config: ExperimentConfig, study_name: str = None):\n",
    "        self.base_config = base_config\n",
    "        self.study_name = study_name or base_config.hpo.study_name\n",
    "        self.hpo_checkpoint_manager = HPOCheckpointManager()\n",
    "        self.study = None\n",
    "        self.progress_callback = None\n",
    "        \n",
    "    def create_or_load_study(self) -> optuna.Study:\n",
    "        \"\"\"Create a new study or load existing one.\"\"\"\n",
    "        \n",
    "        # Check for auto-resume\n",
    "        if self.base_config.hpo.auto_resume:\n",
    "            if self.hpo_checkpoint_manager.should_resume_hpo(self.study_name, asdict(self.base_config)):\n",
    "                print(f\"üîÑ Resuming HPO study: {self.study_name}\")\n",
    "                try:\n",
    "                    hpo_state, _ = self.hpo_checkpoint_manager.load_hpo_state(self.study_name)\n",
    "                    print(f\"   Resuming from {hpo_state.n_trials_completed} completed trials\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   Warning: Could not load HPO state: {e}\")\n",
    "                    print(f\"   Starting fresh study\")\n",
    "        \n",
    "        # Create sampler and pruner\n",
    "        sampler = TPESampler(\n",
    "            seed=self.base_config.hpo.sampler.seed,\n",
    "            multivariate=self.base_config.hpo.sampler.multivariate\n",
    "        )\n",
    "        \n",
    "        pruner = MedianPruner(\n",
    "            n_startup_trials=self.base_config.hpo.pruner.n_startup_trials,\n",
    "            n_warmup_steps=self.base_config.hpo.pruner.n_warmup_steps\n",
    "        )\n",
    "        \n",
    "        # Create or load study\n",
    "        self.study = optuna.create_study(\n",
    "            study_name=self.study_name,\n",
    "            storage=self.base_config.hpo.storage,\n",
    "            load_if_exists=True,\n",
    "            direction=self.base_config.hpo.direction,\n",
    "            sampler=sampler,\n",
    "            pruner=pruner,\n",
    "        )\n",
    "        \n",
    "        print(f\"üìä Study: {self.study_name}\")\n",
    "        print(f\"   Direction: {self.base_config.hpo.direction}\")\n",
    "        print(f\"   Storage: {self.base_config.hpo.storage}\")\n",
    "        print(f\"   Existing trials: {len(self.study.trials)}\")\n",
    "        \n",
    "        return self.study\n",
    "    \n",
    "    def objective(self, trial: optuna.Trial) -> float:\n",
    "        \"\"\"Objective function for optimization.\"\"\"\n",
    "        \n",
    "        # Generate trial configuration\n",
    "        trial_config = HPOSearchSpace.suggest_hyperparameters(trial, self.base_config)\n",
    "        \n",
    "        # Adjust settings for HPO (shorter training)\n",
    "        trial_config.mlflow.nested = True\n",
    "        trial_config.training.early_stopping.patience = max(\n",
    "            2, trial_config.training.early_stopping.patience // 2\n",
    "        )\n",
    "        trial_config.training.max_epochs = min(\n",
    "            trial_config.training.max_epochs, 20  # Limit epochs for HPO\n",
    "        )\n",
    "        \n",
    "        # Disable auto-resume for individual trials\n",
    "        trial_config.training.auto_resume = False\n",
    "        \n",
    "        # Run training with trial configuration\n",
    "        with mlflow.start_run(run_name=f\"trial_{trial.number}\", nested=True):\n",
    "            try:\n",
    "                # Convert to dict for train_loop\n",
    "                config_dict = asdict(trial_config)\n",
    "                \n",
    "                # Use simplified training for HPO\n",
    "                result = train_loop(trial_config)\n",
    "                metric = result[\"best_metric\"]\n",
    "                \n",
    "                # Log trial results\n",
    "                mlflow.log_metric(\"objective\", metric, step=trial.number)\n",
    "                mlflow.log_params({f\"trial_{k}\": v for k, v in trial.params.items()})\n",
    "                \n",
    "                # Report intermediate values for pruning\n",
    "                trial.report(metric, step=trial_config.training.max_epochs)\n",
    "                \n",
    "                # Check if trial should be pruned\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.TrialPruned()\n",
    "                \n",
    "                return metric\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Trial {trial.number} failed: {e}\")\n",
    "                # Return a poor score for failed trials\n",
    "                return -1.0 if self.base_config.hpo.direction == \"maximize\" else 1.0\n",
    "    \n",
    "    def run_optimization(self, n_trials: int = None, timeout: int = None) -> optuna.Study:\n",
    "        \"\"\"Run the optimization process.\"\"\"\n",
    "        \n",
    "        if self.study is None:\n",
    "            self.create_or_load_study()\n",
    "        \n",
    "        n_trials = n_trials or self.base_config.hpo.n_trials\n",
    "        timeout = timeout or self.base_config.hpo.timeout\n",
    "        \n",
    "        # Calculate remaining trials\n",
    "        completed_trials = len(self.study.trials)\n",
    "        remaining_trials = max(0, n_trials - completed_trials)\n",
    "        \n",
    "        if remaining_trials == 0:\n",
    "            print(f\"‚úÖ Study already completed ({completed_trials}/{n_trials} trials)\")\n",
    "            return self.study\n",
    "        \n",
    "        print(f\"üöÄ Starting HPO optimization\")\n",
    "        print(f\"   Remaining trials: {remaining_trials}\")\n",
    "        print(f\"   Timeout: {timeout} seconds\" if timeout else \"   No timeout\")\n",
    "        \n",
    "        # Setup MLflow\n",
    "        mlflow.set_tracking_uri(self.base_config.mlflow.tracking_uri)\n",
    "        mlflow.set_experiment(self.base_config.mlflow.experiment_name)\n",
    "        \n",
    "        # Progress tracking\n",
    "        self.progress_callback = TqdmCallback(\n",
    "            n_trials=remaining_trials,\n",
    "            desc=f\"HPO ({self.study_name})\"\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            with mlflow.start_run(run_name=f\"hpo_{self.study_name}\"):\n",
    "                # Log HPO configuration\n",
    "                hpo_params = {\n",
    "                    \"study_name\": self.study_name,\n",
    "                    \"n_trials\": n_trials,\n",
    "                    \"direction\": self.base_config.hpo.direction,\n",
    "                    \"sampler\": \"TPESampler\",\n",
    "                    \"pruner\": \"MedianPruner\"\n",
    "                }\n",
    "                mlflow.log_params(hpo_params)\n",
    "                \n",
    "                # Run optimization\n",
    "                self.study.optimize(\n",
    "                    self.objective,\n",
    "                    n_trials=remaining_trials,\n",
    "                    timeout=timeout,\n",
    "                    n_jobs=self.base_config.hpo.n_jobs,\n",
    "                    callbacks=[self.progress_callback],\n",
    "                )\n",
    "                \n",
    "                # Log final results\n",
    "                if self.study.best_trial:\n",
    "                    mlflow.log_metric(\"best_value\", self.study.best_value)\n",
    "                    mlflow.log_params({f\"best_{k}\": v for k, v in self.study.best_params.items()})\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n‚èπÔ∏è  HPO interrupted by user\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå HPO failed: {e}\")\n",
    "        finally:\n",
    "            if self.progress_callback:\n",
    "                self.progress_callback.close()\n",
    "            \n",
    "            # Save HPO state\n",
    "            self.hpo_checkpoint_manager.save_hpo_state(\n",
    "                self.study, asdict(self.base_config), \n",
    "                notes=f\"HPO run completed with {len(self.study.trials)} trials\"\n",
    "            )\n",
    "        \n",
    "        return self.study\n",
    "\n",
    "print(\"‚úÖ Enhanced HPO manager defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress Tracking\n",
    "\n",
    "Enhanced progress tracking for HPO with real-time updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TqdmCallback:\n",
    "    \"\"\"Callback for progress tracking with tqdm.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_trials: int, desc: str = \"HPO\"):\n",
    "        self.n_trials = n_trials\n",
    "        self.desc = desc\n",
    "        self.pbar = None\n",
    "        self.best_value = None\n",
    "        \n",
    "    def __call__(self, study: optuna.Study, trial: optuna.Trial):\n",
    "        \"\"\"Called after each trial.\"\"\"\n",
    "        if self.pbar is None:\n",
    "            self.pbar = tqdm(total=self.n_trials, desc=self.desc)\n",
    "        \n",
    "        # Update progress\n",
    "        self.pbar.update(1)\n",
    "        \n",
    "        # Update best value\n",
    "        if study.best_trial:\n",
    "            self.best_value = study.best_value\n",
    "            \n",
    "            # Update progress bar description\n",
    "            status = {\n",
    "                \"trial\": trial.number,\n",
    "                \"best\": f\"{self.best_value:.4f}\",\n",
    "                \"state\": trial.state.name\n",
    "            }\n",
    "            \n",
    "            if trial.value is not None:\n",
    "                status[\"current\"] = f\"{trial.value:.4f}\"\n",
    "            \n",
    "            self.pbar.set_postfix(status)\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close the progress bar.\"\"\"\n",
    "        if self.pbar:\n",
    "            self.pbar.close()\n",
    "\n",
    "print(\"‚úÖ Progress tracking defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO Configuration Selection\n",
    "\n",
    "Interactive selection of HPO configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hpo_config_selector():\n",
    "    \"\"\"Create an interactive HPO configuration selector.\"\"\"\n",
    "    \n",
    "    available_configs = config_manager.list_configs()\n",
    "    \n",
    "    if not available_configs:\n",
    "        print(\"No configurations found. Please run the Configuration Management notebook first.\")\n",
    "        return None\n",
    "    \n",
    "    config_dropdown = widgets.Dropdown(\n",
    "        options=available_configs,\n",
    "        value=available_configs[0] if available_configs else None,\n",
    "        description='Base Config:'\n",
    "    )\n",
    "    \n",
    "    study_name = widgets.Text(\n",
    "        value='hpo_study',\n",
    "        description='Study Name:'\n",
    "    )\n",
    "    \n",
    "    n_trials = widgets.IntSlider(\n",
    "        value=100,\n",
    "        min=10,\n",
    "        max=1000,\n",
    "        step=10,\n",
    "        description='Trials:'\n",
    "    )\n",
    "    \n",
    "    n_jobs = widgets.IntSlider(\n",
    "        value=1,\n",
    "        min=1,\n",
    "        max=8,\n",
    "        step=1,\n",
    "        description='Parallel Jobs:'\n",
    "    )\n",
    "    \n",
    "    timeout = widgets.IntText(\n",
    "        value=None,\n",
    "        description='Timeout (s):',\n",
    "        placeholder='None'\n",
    "    )\n",
    "    \n",
    "    auto_resume = widgets.Checkbox(\n",
    "        value=True,\n",
    "        description='Auto Resume'\n",
    "    )\n",
    "    \n",
    "    load_button = widgets.Button(\n",
    "        description='Setup HPO',\n",
    "        button_style='success'\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_load_clicked(b):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            \n",
    "            try:\n",
    "                # Load base configuration\n",
    "                base_config = config_manager.load_config(config_dropdown.value)\n",
    "                \n",
    "                # Update HPO settings\n",
    "                base_config.hpo.study_name = study_name.value\n",
    "                base_config.hpo.n_trials = n_trials.value\n",
    "                base_config.hpo.n_jobs = n_jobs.value\n",
    "                base_config.hpo.timeout = timeout.value if timeout.value else None\n",
    "                base_config.hpo.auto_resume = auto_resume.value\n",
    "                \n",
    "                # Store in global variable\n",
    "                global current_hpo_config, current_hpo_manager\n",
    "                current_hpo_config = base_config\n",
    "                current_hpo_manager = EnhancedHPOManager(base_config, study_name.value)\n",
    "                \n",
    "                print(f\"‚úÖ HPO configuration setup complete!\")\n",
    "                print(f\"   Base config: {config_dropdown.value}\")\n",
    "                print(f\"   Study name: {study_name.value}\")\n",
    "                print(f\"   Trials: {n_trials.value}\")\n",
    "                print(f\"   Parallel jobs: {n_jobs.value}\")\n",
    "                print(f\"   Auto-resume: {auto_resume.value}\")\n",
    "                \n",
    "                # Check for existing study\n",
    "                existing_studies = hpo_checkpoint_manager.list_hpo_studies()\n",
    "                if not existing_studies.empty:\n",
    "                    matching_studies = existing_studies[existing_studies['study_name'] == study_name.value]\n",
    "                    if not matching_studies.empty:\n",
    "                        study_info = matching_studies.iloc[0]\n",
    "                        print(f\"\\nüîÑ Found existing study:\")\n",
    "                        print(f\"   Completed trials: {study_info['n_trials']}\")\n",
    "                        print(f\"   Best value: {study_info['best_value']:.4f}\" if study_info['best_value'] else \"   No best value yet\")\n",
    "                        print(f\"   Last updated: {study_info['last_updated']}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error setting up HPO: {e}\")\n",
    "    \n",
    "    load_button.on_click(on_load_clicked)\n",
    "    \n",
    "    layout = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>HPO Configuration</h3>\"),\n",
    "        config_dropdown,\n",
    "        study_name,\n",
    "        widgets.HBox([n_trials, n_jobs]),\n",
    "        widgets.HBox([timeout, auto_resume]),\n",
    "        load_button,\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    return layout\n",
    "\n",
    "# Display HPO configuration selector\n",
    "hpo_config_selector = create_hpo_config_selector()\n",
    "if hpo_config_selector:\n",
    "    display(hpo_config_selector)\n",
    "else:\n",
    "    # Fallback: create default HPO configuration\n",
    "    current_hpo_config = ExperimentConfig()\n",
    "    current_hpo_manager = EnhancedHPOManager(current_hpo_config)\n",
    "    print(\"Using default HPO configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO Execution\n",
    "\n",
    "Execute the hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_hpo_optimization():\n",
    "    \"\"\"Start the HPO optimization process.\"\"\"\n",
    "    \n",
    "    # Check if HPO configuration is loaded\n",
    "    if 'current_hpo_manager' not in globals() or current_hpo_manager is None:\n",
    "        print(\"‚ùå No HPO configuration loaded. Please run the HPO configuration selection cell first.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\nüöÄ Starting HPO optimization\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Create or load study\n",
    "        study = current_hpo_manager.create_or_load_study()\n",
    "        \n",
    "        # Run optimization\n",
    "        study = current_hpo_manager.run_optimization()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üéâ HPO optimization completed!\")\n",
    "        \n",
    "        # Display results\n",
    "        if study.best_trial:\n",
    "            print(f\"\\nüèÜ Best Trial Results:\")\n",
    "            print(f\"   Trial number: {study.best_trial.number}\")\n",
    "            print(f\"   Best value: {study.best_value:.4f}\")\n",
    "            print(f\"   Best parameters:\")\n",
    "            for key, value in study.best_params.items():\n",
    "                print(f\"     {key}: {value}\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è  No successful trials completed\")\n",
    "        \n",
    "        # Display study statistics\n",
    "        print(f\"\\nüìä Study Statistics:\")\n",
    "        print(f\"   Total trials: {len(study.trials)}\")\n",
    "        \n",
    "        # Count trials by state\n",
    "        from collections import Counter\n",
    "        state_counts = Counter([trial.state for trial in study.trials])\n",
    "        for state, count in state_counts.items():\n",
    "            print(f\"   {state.name}: {count}\")\n",
    "        \n",
    "        return study\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚èπÔ∏è  HPO interrupted by user\")\n",
    "        print(\"   Study state has been saved and can be resumed\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå HPO failed with error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Create HPO execution button\n",
    "hpo_button = widgets.Button(\n",
    "    description='üîç Start HPO',\n",
    "    button_style='warning',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "def on_hpo_clicked(b):\n",
    "    start_hpo_optimization()\n",
    "\n",
    "hpo_button.on_click(on_hpo_clicked)\n",
    "\n",
    "print(\"Click the button below to start HPO:\")\n",
    "display(hpo_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO Visualization and Analysis\n",
    "\n",
    "Comprehensive visualization and analysis of HPO results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hpo_analysis_dashboard():\n",
    "    \"\"\"Create an interactive HPO analysis dashboard.\"\"\"\n",
    "    \n",
    "    # Get available HPO studies\n",
    "    studies_df = hpo_checkpoint_manager.list_hpo_studies()\n",
    "    \n",
    "    if studies_df.empty:\n",
    "        print(\"No HPO studies found. Run HPO optimization first.\")\n",
    "        return\n",
    "    \n",
    "    study_names = studies_df['study_name'].tolist()\n",
    "    \n",
    "    study_dropdown = widgets.Dropdown(\n",
    "        options=study_names,\n",
    "        value=study_names[0],\n",
    "        description='Study:'\n",
    "    )\n",
    "    \n",
    "    plot_button = widgets.Button(\n",
    "        description='üìä Show Results',\n",
    "        button_style='info'\n",
    "    )\n",
    "    \n",
    "    export_button = widgets.Button(\n",
    "        description='üíæ Export Best Config',\n",
    "        button_style='success'\n",
    "    )\n",
    "    \n",
    "    studies_button = widgets.Button(\n",
    "        description='üìã Show Studies',\n",
    "        button_style='info'\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_plot_clicked(b):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            try:\n",
    "                hpo_state, config = hpo_checkpoint_manager.load_hpo_state(study_dropdown.value)\n",
    "                \n",
    "                print(f\"üìä HPO Results for {study_dropdown.value}:\")\n",
    "                print(f\"   Total trials: {hpo_state.n_trials_completed}\")\n",
    "                print(f\"   Best value: {hpo_state.best_value:.4f}\" if hpo_state.best_value else \"   No best value\")\n",
    "                \n",
    "                if hpo_state.best_trial:\n",
    "                    print(f\"\\nüèÜ Best Trial Parameters:\")\n",
    "                    best_params = hpo_state.best_trial.get('params', {})\n",
    "                    for key, value in best_params.items():\n",
    "                        print(f\"   {key}: {value}\")\n",
    "                \n",
    "                # Show trial statistics\n",
    "                if hpo_state.trials_history:\n",
    "                    completed_trials = [t for t in hpo_state.trials_history if t.get('value') is not None]\n",
    "                    failed_trials = [t for t in hpo_state.trials_history if t.get('state') == 'FAIL']\n",
    "                    pruned_trials = [t for t in hpo_state.trials_history if t.get('state') == 'PRUNED']\n",
    "                    \n",
    "                    print(f\"\\nüìà Trial Statistics:\")\n",
    "                    print(f\"   Completed: {len(completed_trials)}\")\n",
    "                    print(f\"   Failed: {len(failed_trials)}\")\n",
    "                    print(f\"   Pruned: {len(pruned_trials)}\")\n",
    "                    \n",
    "                    if completed_trials:\n",
    "                        values = [t['value'] for t in completed_trials]\n",
    "                        print(f\"   Best value: {max(values):.4f}\")\n",
    "                        print(f\"   Worst value: {min(values):.4f}\")\n",
    "                        print(f\"   Mean value: {np.mean(values):.4f}\")\n",
    "                        print(f\"   Std value: {np.std(values):.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading HPO results: {e}\")\n",
    "    \n",
    "    def on_export_clicked(b):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            try:\n",
    "                hpo_state, config = hpo_checkpoint_manager.load_hpo_state(study_dropdown.value)\n",
    "                \n",
    "                if hpo_state.best_trial:\n",
    "                    # Create configuration with best parameters\n",
    "                    best_config = ExperimentConfig(**config)\n",
    "                    \n",
    "                    print(f\"‚úÖ Best configuration from {study_dropdown.value}:\")\n",
    "                    print(f\"   Best value: {hpo_state.best_value:.4f}\")\n",
    "                    \n",
    "                    # Save as new configuration\n",
    "                    config_name = f\"hpo_best_{study_dropdown.value}\"\n",
    "                    config_manager.save_config(best_config, config_name)\n",
    "                    print(f\"\\nüíæ Saved as configuration: {config_name}\")\n",
    "                    \n",
    "                    # Display best parameters\n",
    "                    best_params = hpo_state.best_trial.get('params', {})\n",
    "                    print(f\"\\nüèÜ Best parameters:\")\n",
    "                    for key, value in best_params.items():\n",
    "                        print(f\"   {key}: {value}\")\n",
    "                else:\n",
    "                    print(\"No best trial found in study\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error exporting configuration: {e}\")\n",
    "    \n",
    "    def on_studies_clicked(b):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            print(\"Available HPO Studies:\")\n",
    "            display(studies_df)\n",
    "    \n",
    "    plot_button.on_click(on_plot_clicked)\n",
    "    export_button.on_click(on_export_clicked)\n",
    "    studies_button.on_click(on_studies_clicked)\n",
    "    \n",
    "    dashboard = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>HPO Analysis Dashboard</h3>\"),\n",
    "        study_dropdown,\n",
    "        widgets.HBox([plot_button, export_button, studies_button]),\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    return dashboard\n",
    "\n",
    "# Display HPO analysis dashboard\n",
    "print(\"\\nHPO Analysis Dashboard:\")\n",
    "hpo_analysis_dashboard = create_hpo_analysis_dashboard()\n",
    "if hpo_analysis_dashboard:\n",
    "    display(hpo_analysis_dashboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO Utilities\n",
    "\n",
    "Additional utilities for HPO management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_hpo_studies(study_names: List[str]):\n",
    "    \"\"\"Compare multiple HPO studies.\"\"\"\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    for study_name in study_names:\n",
    "        try:\n",
    "            hpo_state, config = hpo_checkpoint_manager.load_hpo_state(study_name)\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'study_name': study_name,\n",
    "                'n_trials': hpo_state.n_trials_completed,\n",
    "                'best_value': hpo_state.best_value,\n",
    "                'created_at': hpo_state.created_at,\n",
    "                'last_updated': hpo_state.last_updated\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading study {study_name}: {e}\")\n",
    "    \n",
    "    if comparison_data:\n",
    "        df = pd.DataFrame(comparison_data)\n",
    "        df = df.sort_values('best_value', ascending=False)\n",
    "        \n",
    "        print(\"üèÜ HPO Studies Comparison:\")\n",
    "        display(df)\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        print(\"No valid studies found for comparison\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def cleanup_hpo_studies(keep_best_n: int = 3):\n",
    "    \"\"\"Clean up old HPO studies, keeping only the best N.\"\"\"\n",
    "    \n",
    "    studies_df = hpo_checkpoint_manager.list_hpo_studies()\n",
    "    \n",
    "    if studies_df.empty:\n",
    "        print(\"No HPO studies to clean up\")\n",
    "        return\n",
    "    \n",
    "    # Sort by best value and keep top N\n",
    "    studies_df = studies_df.sort_values('best_value', ascending=False)\n",
    "    \n",
    "    if len(studies_df) > keep_best_n:\n",
    "        to_delete = studies_df.iloc[keep_best_n:]\n",
    "        \n",
    "        print(f\"\\nüßπ Cleaning up HPO studies (keeping best {keep_best_n}):\")\n",
    "        for _, study in to_delete.iterrows():\n",
    "            hpo_checkpoint_manager.delete_hpo_study(study['study_name'])\n",
    "            print(f\"   Deleted: {study['study_name']}\")\n",
    "    else:\n",
    "        print(f\"Only {len(studies_df)} studies found, no cleanup needed\")\n",
    "\n",
    "print(\"\\n‚úÖ HPO notebook setup complete!\")\n",
    "print(\"\\nTo run HPO:\")\n",
    "print(\"1. Select a base configuration using the HPO configuration selector above\")\n",
    "print(\"2. Click the 'Start HPO' button\")\n",
    "print(\"3. Monitor progress and analyze results using the analysis dashboard\")\n",
    "print(\"\\nHPO will automatically resume from previous studies if interrupted.\")"
   ]
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": "3"
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.8.0"
 },
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 }
}