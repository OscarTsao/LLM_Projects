{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Checkpoint System\n",
    "\n",
    "This notebook implements a comprehensive checkpoint system with auto-resume capabilities for training and HPO.\n",
    "It saves complete training state including model, optimizer, scheduler, and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import shutil\n",
    "import torch\n",
    "import optuna\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, List, Tuple\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint Data Structures\n",
    "\n",
    "Define comprehensive data structures for storing training state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingMetrics:\n",
    "    \"\"\"Training metrics for a specific epoch.\"\"\"\n",
    "    epoch: int\n",
    "    train_loss: float\n",
    "    val_loss: float\n",
    "    val_metrics: Dict[str, float]\n",
    "    learning_rate: float\n",
    "    timestamp: str\n",
    "    \n",
    "@dataclass\n",
    "class CheckpointMetadata:\n",
    "    \"\"\"Metadata for a checkpoint.\"\"\"\n",
    "    checkpoint_id: str\n",
    "    experiment_name: str\n",
    "    model_type: str\n",
    "    created_at: str\n",
    "    epoch: int\n",
    "    step: int\n",
    "    best_metric: float\n",
    "    best_epoch: int\n",
    "    total_epochs: int\n",
    "    config_hash: str\n",
    "    git_commit: Optional[str] = None\n",
    "    notes: str = \"\"\n",
    "    \n",
    "@dataclass\n",
    "class TrainingState:\n",
    "    \"\"\"Complete training state.\"\"\"\n",
    "    epoch: int\n",
    "    step: int\n",
    "    best_metric: float\n",
    "    best_epoch: int\n",
    "    epochs_without_improve: int\n",
    "    training_history: List[TrainingMetrics]\n",
    "    random_state: Dict[str, Any]\n",
    "    scaler_state: Optional[Dict[str, Any]] = None\n",
    "    ema_state: Optional[Dict[str, Any]] = None\n",
    "\n",
    "@dataclass\n",
    "class HPOState:\n",
    "    \"\"\"HPO study state.\"\"\"\n",
    "    study_name: str\n",
    "    n_trials_completed: int\n",
    "    best_trial: Optional[Dict[str, Any]]\n",
    "    best_value: Optional[float]\n",
    "    trials_history: List[Dict[str, Any]]\n",
    "    created_at: str\n",
    "    last_updated: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Checkpoint Manager\n",
    "\n",
    "A comprehensive checkpoint manager with versioning and metadata tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedCheckpointManager:\n",
    "    \"\"\"Enhanced checkpoint manager with comprehensive state saving and auto-resume.\"\"\"\n",
    "    \n",
    "    def __init__(self, checkpoint_dir: str = \"./checkpoints\", max_checkpoints: int = 5):\n",
    "        self.checkpoint_dir = Path(checkpoint_dir)\n",
    "        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.max_checkpoints = max_checkpoints\n",
    "        self.metadata_file = self.checkpoint_dir / \"metadata.json\"\n",
    "        self.training_log = self.checkpoint_dir / \"training_log.json\"\n",
    "        \n",
    "        # Initialize metadata if not exists\n",
    "        if not self.metadata_file.exists():\n",
    "            self._save_metadata({})\n",
    "    \n",
    "    def _generate_checkpoint_id(self) -> str:\n",
    "        \"\"\"Generate unique checkpoint ID.\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        return f\"checkpoint_{timestamp}\"\n",
    "    \n",
    "    def _get_config_hash(self, config: Dict[str, Any]) -> str:\n",
    "        \"\"\"Generate hash for configuration to detect changes.\"\"\"\n",
    "        import hashlib\n",
    "        config_str = json.dumps(config, sort_keys=True)\n",
    "        return hashlib.md5(config_str.encode()).hexdigest()[:8]\n",
    "    \n",
    "    def _save_metadata(self, metadata: Dict[str, Any]) -> None:\n",
    "        \"\"\"Save checkpoint metadata.\"\"\"\n",
    "        with open(self.metadata_file, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    def _load_metadata(self) -> Dict[str, Any]:\n",
    "        \"\"\"Load checkpoint metadata.\"\"\"\n",
    "        if self.metadata_file.exists():\n",
    "            with open(self.metadata_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "    \n",
    "    def _cleanup_old_checkpoints(self) -> None:\n",
    "        \"\"\"Remove old checkpoints to maintain max_checkpoints limit.\"\"\"\n",
    "        metadata = self._load_metadata()\n",
    "        checkpoints = list(metadata.keys())\n",
    "        \n",
    "        if len(checkpoints) > self.max_checkpoints:\n",
    "            # Sort by creation time and remove oldest\n",
    "            checkpoints.sort(key=lambda x: metadata[x].get('created_at', ''))\n",
    "            to_remove = checkpoints[:-self.max_checkpoints]\n",
    "            \n",
    "            for checkpoint_id in to_remove:\n",
    "                checkpoint_path = self.checkpoint_dir / checkpoint_id\n",
    "                if checkpoint_path.exists():\n",
    "                    shutil.rmtree(checkpoint_path)\n",
    "                del metadata[checkpoint_id]\n",
    "            \n",
    "            self._save_metadata(metadata)\n",
    "    \n",
    "    def save_checkpoint(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        scheduler: Any,\n",
    "        training_state: TrainingState,\n",
    "        config: Dict[str, Any],\n",
    "        experiment_name: str = \"default\",\n",
    "        notes: str = \"\",\n",
    "        is_best: bool = False\n",
    "    ) -> str:\n",
    "        \"\"\"Save complete training checkpoint.\"\"\"\n",
    "        \n",
    "        checkpoint_id = self._generate_checkpoint_id()\n",
    "        checkpoint_path = self.checkpoint_dir / checkpoint_id\n",
    "        checkpoint_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save model state\n",
    "        torch.save(model.state_dict(), checkpoint_path / \"model.pt\")\n",
    "        \n",
    "        # Save optimizer state\n",
    "        torch.save(optimizer.state_dict(), checkpoint_path / \"optimizer.pt\")\n",
    "        \n",
    "        # Save scheduler state\n",
    "        if hasattr(scheduler, 'state_dict'):\n",
    "            torch.save(scheduler.state_dict(), checkpoint_path / \"scheduler.pt\")\n",
    "        \n",
    "        # Save training state\n",
    "        with open(checkpoint_path / \"training_state.json\", 'w') as f:\n",
    "            json.dump(asdict(training_state), f, indent=2, default=str)\n",
    "        \n",
    "        # Save configuration\n",
    "        with open(checkpoint_path / \"config.json\", 'w') as f:\n",
    "            json.dump(config, f, indent=2, default=str)\n",
    "        \n",
    "        # Create checkpoint metadata\n",
    "        metadata = CheckpointMetadata(\n",
    "            checkpoint_id=checkpoint_id,\n",
    "            experiment_name=experiment_name,\n",
    "            model_type=config.get('model', {}).get('encoder', {}).get('type', 'unknown'),\n",
    "            created_at=datetime.now().isoformat(),\n",
    "            epoch=training_state.epoch,\n",
    "            step=training_state.step,\n",
    "            best_metric=training_state.best_metric,\n",
    "            best_epoch=training_state.best_epoch,\n",
    "            total_epochs=config.get('training', {}).get('max_epochs', 0),\n",
    "            config_hash=self._get_config_hash(config),\n",
    "            notes=notes\n",
    "        )\n",
    "        \n",
    "        # Save metadata\n",
    "        with open(checkpoint_path / \"metadata.json\", 'w') as f:\n",
    "            json.dump(asdict(metadata), f, indent=2)\n",
    "        \n",
    "        # Update global metadata\n",
    "        global_metadata = self._load_metadata()\n",
    "        global_metadata[checkpoint_id] = asdict(metadata)\n",
    "        self._save_metadata(global_metadata)\n",
    "        \n",
    "        # Create best checkpoint symlink\n",
    "        if is_best:\n",
    "            best_link = self.checkpoint_dir / \"best_checkpoint\"\n",
    "            if best_link.exists():\n",
    "                best_link.unlink()\n",
    "            best_link.symlink_to(checkpoint_id)\n",
    "        \n",
    "        # Cleanup old checkpoints\n",
    "        self._cleanup_old_checkpoints()\n",
    "        \n",
    "        print(f\"âœ… Checkpoint saved: {checkpoint_id}\")\n",
    "        print(f\"   Epoch: {training_state.epoch}\")\n",
    "        print(f\"   Best metric: {training_state.best_metric:.4f}\")\n",
    "        print(f\"   Path: {checkpoint_path}\")\n",
    "        \n",
    "        return checkpoint_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_checkpoint(\n",
    "        self,\n",
    "        checkpoint_id: str,\n",
    "        model: torch.nn.Module,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        scheduler: Any,\n",
    "        device: torch.device\n",
    "    ) -> Tuple[TrainingState, Dict[str, Any]]:\n",
    "        \"\"\"Load complete training checkpoint.\"\"\"\n",
    "        \n",
    "        checkpoint_path = self.checkpoint_dir / checkpoint_id\n",
    "        if not checkpoint_path.exists():\n",
    "            raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "        \n",
    "        # Load model state\n",
    "        model_path = checkpoint_path / \"model.pt\"\n",
    "        if model_path.exists():\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            print(f\"âœ… Loaded model state from {checkpoint_id}\")\n",
    "        \n",
    "        # Load optimizer state\n",
    "        optimizer_path = checkpoint_path / \"optimizer.pt\"\n",
    "        if optimizer_path.exists():\n",
    "            optimizer.load_state_dict(torch.load(optimizer_path, map_location=device))\n",
    "            print(f\"âœ… Loaded optimizer state from {checkpoint_id}\")\n",
    "        \n",
    "        # Load scheduler state\n",
    "        scheduler_path = checkpoint_path / \"scheduler.pt\"\n",
    "        if scheduler_path.exists() and hasattr(scheduler, 'load_state_dict'):\n",
    "            scheduler.load_state_dict(torch.load(scheduler_path, map_location=device))\n",
    "            print(f\"âœ… Loaded scheduler state from {checkpoint_id}\")\n",
    "        \n",
    "        # Load training state\n",
    "        training_state_path = checkpoint_path / \"training_state.json\"\n",
    "        with open(training_state_path, 'r') as f:\n",
    "            training_state_dict = json.load(f)\n",
    "        \n",
    "        # Convert back to TrainingState object\n",
    "        training_state = TrainingState(**training_state_dict)\n",
    "        \n",
    "        # Load configuration\n",
    "        config_path = checkpoint_path / \"config.json\"\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        # Restore random states\n",
    "        if training_state.random_state:\n",
    "            torch.set_rng_state(torch.tensor(training_state.random_state['torch']))\n",
    "            np.random.set_state(tuple(training_state.random_state['numpy']))\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.set_rng_state(torch.tensor(training_state.random_state['cuda']))\n",
    "        \n",
    "        print(f\"âœ… Loaded training state from {checkpoint_id}\")\n",
    "        print(f\"   Resuming from epoch: {training_state.epoch}\")\n",
    "        print(f\"   Best metric so far: {training_state.best_metric:.4f}\")\n",
    "        \n",
    "        return training_state, config\n",
    "    \n",
    "    def find_latest_checkpoint(self, experiment_name: Optional[str] = None) -> Optional[str]:\n",
    "        \"\"\"Find the latest checkpoint for an experiment.\"\"\"\n",
    "        metadata = self._load_metadata()\n",
    "        \n",
    "        if not metadata:\n",
    "            return None\n",
    "        \n",
    "        # Filter by experiment name if provided\n",
    "        if experiment_name:\n",
    "            filtered_metadata = {\n",
    "                k: v for k, v in metadata.items() \n",
    "                if v.get('experiment_name') == experiment_name\n",
    "            }\n",
    "        else:\n",
    "            filtered_metadata = metadata\n",
    "        \n",
    "        if not filtered_metadata:\n",
    "            return None\n",
    "        \n",
    "        # Find latest by creation time\n",
    "        latest_checkpoint = max(\n",
    "            filtered_metadata.keys(),\n",
    "            key=lambda x: filtered_metadata[x].get('created_at', '')\n",
    "        )\n",
    "        \n",
    "        return latest_checkpoint\n",
    "    \n",
    "    def find_best_checkpoint(self, experiment_name: Optional[str] = None) -> Optional[str]:\n",
    "        \"\"\"Find the best checkpoint for an experiment.\"\"\"\n",
    "        metadata = self._load_metadata()\n",
    "        \n",
    "        if not metadata:\n",
    "            return None\n",
    "        \n",
    "        # Filter by experiment name if provided\n",
    "        if experiment_name:\n",
    "            filtered_metadata = {\n",
    "                k: v for k, v in metadata.items() \n",
    "                if v.get('experiment_name') == experiment_name\n",
    "            }\n",
    "        else:\n",
    "            filtered_metadata = metadata\n",
    "        \n",
    "        if not filtered_metadata:\n",
    "            return None\n",
    "        \n",
    "        # Find best by metric\n",
    "        best_checkpoint = max(\n",
    "            filtered_metadata.keys(),\n",
    "            key=lambda x: filtered_metadata[x].get('best_metric', -float('inf'))\n",
    "        )\n",
    "        \n",
    "        return best_checkpoint\n",
    "    \n",
    "    def list_checkpoints(self, experiment_name: Optional[str] = None) -> pd.DataFrame:\n",
    "        \"\"\"List all checkpoints as a DataFrame.\"\"\"\n",
    "        metadata = self._load_metadata()\n",
    "        \n",
    "        if not metadata:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Filter by experiment name if provided\n",
    "        if experiment_name:\n",
    "            filtered_metadata = {\n",
    "                k: v for k, v in metadata.items() \n",
    "                if v.get('experiment_name') == experiment_name\n",
    "            }\n",
    "        else:\n",
    "            filtered_metadata = metadata\n",
    "        \n",
    "        if not filtered_metadata:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df_data = []\n",
    "        for checkpoint_id, meta in filtered_metadata.items():\n",
    "            df_data.append({\n",
    "                'checkpoint_id': checkpoint_id,\n",
    "                'experiment': meta.get('experiment_name', ''),\n",
    "                'model_type': meta.get('model_type', ''),\n",
    "                'epoch': meta.get('epoch', 0),\n",
    "                'best_metric': meta.get('best_metric', 0.0),\n",
    "                'created_at': meta.get('created_at', ''),\n",
    "                'notes': meta.get('notes', '')\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(df_data)\n",
    "        if not df.empty:\n",
    "            df = df.sort_values('created_at', ascending=False)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def delete_checkpoint(self, checkpoint_id: str) -> None:\n",
    "        \"\"\"Delete a specific checkpoint.\"\"\"\n",
    "        checkpoint_path = self.checkpoint_dir / checkpoint_id\n",
    "        if checkpoint_path.exists():\n",
    "            shutil.rmtree(checkpoint_path)\n",
    "        \n",
    "        # Update metadata\n",
    "        metadata = self._load_metadata()\n",
    "        if checkpoint_id in metadata:\n",
    "            del metadata[checkpoint_id]\n",
    "            self._save_metadata(metadata)\n",
    "        \n",
    "        print(f\"ğŸ—‘ï¸  Deleted checkpoint: {checkpoint_id}\")\n",
    "    \n",
    "    def get_checkpoint_info(self, checkpoint_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get detailed information about a checkpoint.\"\"\"\n",
    "        checkpoint_path = self.checkpoint_dir / checkpoint_id\n",
    "        if not checkpoint_path.exists():\n",
    "            raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "        \n",
    "        # Load metadata\n",
    "        metadata_path = checkpoint_path / \"metadata.json\"\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        \n",
    "        # Load training state\n",
    "        training_state_path = checkpoint_path / \"training_state.json\"\n",
    "        with open(training_state_path, 'r') as f:\n",
    "            training_state = json.load(f)\n",
    "        \n",
    "        # Calculate checkpoint size\n",
    "        total_size = sum(f.stat().st_size for f in checkpoint_path.rglob('*') if f.is_file())\n",
    "        \n",
    "        return {\n",
    "            'metadata': metadata,\n",
    "            'training_state': training_state,\n",
    "            'size_mb': total_size / (1024 * 1024),\n",
    "            'files': [f.name for f in checkpoint_path.iterdir() if f.is_file()]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-Resume Functionality\n",
    "\n",
    "Automatic detection and resumption of interrupted training sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoResumeManager:\n",
    "    \"\"\"Manages automatic resumption of training and HPO sessions.\"\"\"\n",
    "    \n",
    "    def __init__(self, checkpoint_manager: EnhancedCheckpointManager):\n",
    "        self.checkpoint_manager = checkpoint_manager\n",
    "    \n",
    "    def should_resume_training(\n",
    "        self, \n",
    "        experiment_name: str, \n",
    "        config: Dict[str, Any]\n",
    "    ) -> Tuple[bool, Optional[str]]:\n",
    "        \"\"\"Check if training should be resumed.\"\"\"\n",
    "        \n",
    "        latest_checkpoint = self.checkpoint_manager.find_latest_checkpoint(experiment_name)\n",
    "        \n",
    "        if not latest_checkpoint:\n",
    "            return False, None\n",
    "        \n",
    "        # Check if configuration matches\n",
    "        try:\n",
    "            checkpoint_info = self.checkpoint_manager.get_checkpoint_info(latest_checkpoint)\n",
    "            checkpoint_config_hash = checkpoint_info['metadata']['config_hash']\n",
    "            current_config_hash = self.checkpoint_manager._get_config_hash(config)\n",
    "            \n",
    "            if checkpoint_config_hash != current_config_hash:\n",
    "                print(f\"âš ï¸  Configuration changed since last checkpoint\")\n",
    "                print(f\"   Checkpoint config hash: {checkpoint_config_hash}\")\n",
    "                print(f\"   Current config hash: {current_config_hash}\")\n",
    "                return False, None\n",
    "            \n",
    "            # Check if training is already complete\n",
    "            training_state = checkpoint_info['training_state']\n",
    "            max_epochs = config.get('training', {}).get('max_epochs', 100)\n",
    "            \n",
    "            if training_state['epoch'] >= max_epochs:\n",
    "                print(f\"âœ… Training already complete ({training_state['epoch']}/{max_epochs} epochs)\")\n",
    "                return False, None\n",
    "            \n",
    "            print(f\"ğŸ”„ Found resumable checkpoint: {latest_checkpoint}\")\n",
    "            print(f\"   Experiment: {experiment_name}\")\n",
    "            print(f\"   Epoch: {training_state['epoch']}/{max_epochs}\")\n",
    "            print(f\"   Best metric: {training_state['best_metric']:.4f}\")\n",
    "            \n",
    "            return True, latest_checkpoint\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error checking checkpoint: {e}\")\n",
    "            return False, None\n",
    "    \n",
    "    def resume_training(\n",
    "        self,\n",
    "        checkpoint_id: str,\n",
    "        model: torch.nn.Module,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        scheduler: Any,\n",
    "        device: torch.device\n",
    "    ) -> Tuple[TrainingState, Dict[str, Any]]:\n",
    "        \"\"\"Resume training from checkpoint.\"\"\"\n",
    "        \n",
    "        print(f\"ğŸ”„ Resuming training from checkpoint: {checkpoint_id}\")\n",
    "        \n",
    "        training_state, config = self.checkpoint_manager.load_checkpoint(\n",
    "            checkpoint_id, model, optimizer, scheduler, device\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Training resumed successfully\")\n",
    "        print(f\"   Starting from epoch: {training_state.epoch + 1}\")\n",
    "        print(f\"   Best metric so far: {training_state.best_metric:.4f}\")\n",
    "        print(f\"   Training history: {len(training_state.training_history)} epochs\")\n",
    "        \n",
    "        return training_state, config\n",
    "    \n",
    "    def create_training_state(\n",
    "        self,\n",
    "        epoch: int = 0,\n",
    "        step: int = 0,\n",
    "        best_metric: float = -float('inf'),\n",
    "        best_epoch: int = -1\n",
    "    ) -> TrainingState:\n",
    "        \"\"\"Create a new training state for fresh training.\"\"\"\n",
    "        \n",
    "        # Capture random states\n",
    "        random_state = {\n",
    "            'torch': torch.get_rng_state().tolist(),\n",
    "            'numpy': list(np.random.get_state()),\n",
    "        }\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            random_state['cuda'] = torch.cuda.get_rng_state().tolist()\n",
    "        \n",
    "        return TrainingState(\n",
    "            epoch=epoch,\n",
    "            step=step,\n",
    "            best_metric=best_metric,\n",
    "            best_epoch=best_epoch,\n",
    "            epochs_without_improve=0,\n",
    "            training_history=[],\n",
    "            random_state=random_state\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO Checkpoint Manager\n",
    "\n",
    "Specialized checkpoint management for Optuna HPO studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPOCheckpointManager:\n",
    "    \"\"\"Manages checkpoints for HPO studies with auto-resume capabilities.\"\"\"\n",
    "    \n",
    "    def __init__(self, hpo_dir: str = \"./hpo_checkpoints\"):\n",
    "        self.hpo_dir = Path(hpo_dir)\n",
    "        self.hpo_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def save_hpo_state(\n",
    "        self,\n",
    "        study: optuna.Study,\n",
    "        config: Dict[str, Any],\n",
    "        notes: str = \"\"\n",
    "    ) -> None:\n",
    "        \"\"\"Save HPO study state.\"\"\"\n",
    "        \n",
    "        study_name = study.study_name\n",
    "        study_dir = self.hpo_dir / study_name\n",
    "        study_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Get study statistics\n",
    "        trials = study.trials\n",
    "        best_trial = study.best_trial if trials else None\n",
    "        best_value = study.best_value if trials else None\n",
    "        \n",
    "        # Create HPO state\n",
    "        hpo_state = HPOState(\n",
    "            study_name=study_name,\n",
    "            n_trials_completed=len(trials),\n",
    "            best_trial=best_trial.__dict__ if best_trial else None,\n",
    "            best_value=best_value,\n",
    "            trials_history=[trial.__dict__ for trial in trials],\n",
    "            created_at=datetime.now().isoformat(),\n",
    "            last_updated=datetime.now().isoformat()\n",
    "        )\n",
    "        \n",
    "        # Save HPO state\n",
    "        with open(study_dir / \"hpo_state.json\", 'w') as f:\n",
    "            json.dump(asdict(hpo_state), f, indent=2, default=str)\n",
    "        \n",
    "        # Save configuration\n",
    "        with open(study_dir / \"config.json\", 'w') as f:\n",
    "            json.dump(config, f, indent=2, default=str)\n",
    "        \n",
    "        # Save study object (pickle)\n",
    "        with open(study_dir / \"study.pkl\", 'wb') as f:\n",
    "            pickle.dump(study, f)\n",
    "        \n",
    "        print(f\"ğŸ’¾ HPO state saved for study: {study_name}\")\n",
    "        print(f\"   Trials completed: {len(trials)}\")\n",
    "        if best_value is not None:\n",
    "            print(f\"   Best value: {best_value:.4f}\")\n",
    "    \n",
    "    def load_hpo_state(self, study_name: str) -> Tuple[HPOState, Dict[str, Any]]:\n",
    "        \"\"\"Load HPO study state.\"\"\"\n",
    "        \n",
    "        study_dir = self.hpo_dir / study_name\n",
    "        if not study_dir.exists():\n",
    "            raise FileNotFoundError(f\"HPO state not found for study: {study_name}\")\n",
    "        \n",
    "        # Load HPO state\n",
    "        with open(study_dir / \"hpo_state.json\", 'r') as f:\n",
    "            hpo_state_dict = json.load(f)\n",
    "        \n",
    "        hpo_state = HPOState(**hpo_state_dict)\n",
    "        \n",
    "        # Load configuration\n",
    "        with open(study_dir / \"config.json\", 'r') as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        return hpo_state, config\n",
    "    \n",
    "    def should_resume_hpo(self, study_name: str, config: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Check if HPO study should be resumed.\"\"\"\n",
    "        \n",
    "        study_dir = self.hpo_dir / study_name\n",
    "        if not study_dir.exists():\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            hpo_state, saved_config = self.load_hpo_state(study_name)\n",
    "            \n",
    "            # Check if study is complete\n",
    "            max_trials = config.get('hpo', {}).get('n_trials', 100)\n",
    "            if hpo_state.n_trials_completed >= max_trials:\n",
    "                print(f\"âœ… HPO study already complete ({hpo_state.n_trials_completed}/{max_trials} trials)\")\n",
    "                return False\n",
    "            \n",
    "            print(f\"ğŸ”„ Found resumable HPO study: {study_name}\")\n",
    "            print(f\"   Trials completed: {hpo_state.n_trials_completed}/{max_trials}\")\n",
    "            if hpo_state.best_value is not None:\n",
    "                print(f\"   Best value so far: {hpo_state.best_value:.4f}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error checking HPO state: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def list_hpo_studies(self) -> pd.DataFrame:\n",
    "        \"\"\"List all HPO studies.\"\"\"\n",
    "        \n",
    "        studies = []\n",
    "        for study_dir in self.hpo_dir.iterdir():\n",
    "            if study_dir.is_dir():\n",
    "                try:\n",
    "                    hpo_state, _ = self.load_hpo_state(study_dir.name)\n",
    "                    studies.append({\n",
    "                        'study_name': hpo_state.study_name,\n",
    "                        'n_trials': hpo_state.n_trials_completed,\n",
    "                        'best_value': hpo_state.best_value,\n",
    "                        'last_updated': hpo_state.last_updated\n",
    "                    })\n",
    "                except Exception:\n",
    "                    continue\n",
    "        \n",
    "        if studies:\n",
    "            df = pd.DataFrame(studies)\n",
    "            df = df.sort_values('last_updated', ascending=False)\n",
    "            return df\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def delete_hpo_study(self, study_name: str) -> None:\n",
    "        \"\"\"Delete HPO study data.\"\"\"\n",
    "        study_dir = self.hpo_dir / study_name\n",
    "        if study_dir.exists():\n",
    "            shutil.rmtree(study_dir)\n",
    "            print(f\"ğŸ—‘ï¸  Deleted HPO study: {study_name}\")\n",
    "        else:\n",
    "            print(f\"âŒ HPO study not found: {study_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint Utilities\n",
    "\n",
    "Utility functions for checkpoint management and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize checkpoint managers\n",
    "checkpoint_manager = EnhancedCheckpointManager()\n",
    "auto_resume_manager = AutoResumeManager(checkpoint_manager)\n",
    "hpo_checkpoint_manager = HPOCheckpointManager()\n",
    "\n",
    "def display_checkpoint_summary():\n",
    "    \"\"\"Display a summary of all checkpoints.\"\"\"\n",
    "    print(\"ğŸ“Š Checkpoint Summary\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Training checkpoints\n",
    "    training_checkpoints = checkpoint_manager.list_checkpoints()\n",
    "    if not training_checkpoints.empty:\n",
    "        print(\"\\nğŸ¯ Training Checkpoints:\")\n",
    "        display(training_checkpoints)\n",
    "    else:\n",
    "        print(\"\\nğŸ¯ No training checkpoints found\")\n",
    "    \n",
    "    # HPO studies\n",
    "    hpo_studies = hpo_checkpoint_manager.list_hpo_studies()\n",
    "    if not hpo_studies.empty:\n",
    "        print(\"\\nğŸ” HPO Studies:\")\n",
    "        display(hpo_studies)\n",
    "    else:\n",
    "        print(\"\\nğŸ” No HPO studies found\")\n",
    "\n",
    "def cleanup_old_checkpoints(keep_best_n: int = 3):\n",
    "    \"\"\"Clean up old checkpoints, keeping only the best N.\"\"\"\n",
    "    checkpoints_df = checkpoint_manager.list_checkpoints()\n",
    "    \n",
    "    if checkpoints_df.empty:\n",
    "        print(\"No checkpoints to clean up\")\n",
    "        return\n",
    "    \n",
    "    # Group by experiment and keep best N for each\n",
    "    experiments = checkpoints_df['experiment'].unique()\n",
    "    \n",
    "    for experiment in experiments:\n",
    "        exp_checkpoints = checkpoints_df[checkpoints_df['experiment'] == experiment]\n",
    "        exp_checkpoints = exp_checkpoints.sort_values('best_metric', ascending=False)\n",
    "        \n",
    "        if len(exp_checkpoints) > keep_best_n:\n",
    "            to_delete = exp_checkpoints.iloc[keep_best_n:]\n",
    "            \n",
    "            print(f\"\\nğŸ§¹ Cleaning up experiment: {experiment}\")\n",
    "            for _, checkpoint in to_delete.iterrows():\n",
    "                checkpoint_manager.delete_checkpoint(checkpoint['checkpoint_id'])\n",
    "\n",
    "def export_checkpoint_info(checkpoint_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"Export detailed checkpoint information.\"\"\"\n",
    "    try:\n",
    "        info = checkpoint_manager.get_checkpoint_info(checkpoint_id)\n",
    "        print(f\"ğŸ“‹ Checkpoint Information: {checkpoint_id}\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Experiment: {info['metadata']['experiment_name']}\")\n",
    "        print(f\"Model: {info['metadata']['model_type']}\")\n",
    "        print(f\"Epoch: {info['metadata']['epoch']}\")\n",
    "        print(f\"Best Metric: {info['metadata']['best_metric']:.4f}\")\n",
    "        print(f\"Size: {info['size_mb']:.2f} MB\")\n",
    "        print(f\"Files: {', '.join(info['files'])}\")\n",
    "        print(f\"Created: {info['metadata']['created_at']}\")\n",
    "        if info['metadata']['notes']:\n",
    "            print(f\"Notes: {info['metadata']['notes']}\")\n",
    "        \n",
    "        return info\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"âŒ {e}\")\n",
    "        return {}\n",
    "\n",
    "# Display initial summary\n",
    "display_checkpoint_summary()\n",
    "\n",
    "print(\"\\nâœ… Enhanced Checkpoint System Ready!\")\n",
    "print(\"\\nKey Features:\")\n",
    "print(\"  ğŸ”„ Auto-resume training from interruptions\")\n",
    "print(\"  ğŸ’¾ Complete state saving (model, optimizer, scheduler, metadata)\")\n",
    "print(\"  ğŸ” HPO study checkpointing and resumption\")\n",
    "print(\"  ğŸ“Š Checkpoint visualization and management\")\n",
    "print(\"  ğŸ§¹ Automatic cleanup of old checkpoints\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}